<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SpringBoot全局配置参考]]></title>
    <url>%2F2018%2F06%2F02%2FSpringBoot%E5%85%A8%E5%B1%80%E9%85%8D%E7%BD%AE%E5%8F%82%E8%80%83%2F</url>
    <content type="text"><![CDATA[Spring Boot 常用应用程序属性详见:Common application properties 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060106110621063106410651066106710681069107010711072107310741075107610771078107910801081108210831084108510861087108810891090109110921093109410951096109710981099110011011102110311041105110611071108110911101111111211131114111511161117111811191120112111221123112411251126112711281129113011311132113311341135113611371138113911401141114211431144114511461147114811491150115111521153115411551156115711581159116011611162116311641165116611671168116911701171117211731174117511761177117811791180118111821183118411851186118711881189119011911192119311941195119611971198119912001201120212031204120512061207120812091210121112121213121412151216121712181219122012211222122312241225122612271228122912301231123212331234123512361237123812391240124112421243124412451246124712481249125012511252125312541255125612571258125912601261126212631264126512661267126812691270127112721273127412751276127712781279128012811282128312841285128612871288128912901291129212931294129512961297129812991300130113021303130413051306130713081309131013111312131313141315131613171318131913201321132213231324132513261327132813291330133113321333133413351336133713381339134013411342134313441345134613471348134913501351135213531354135513561357135813591360136113621363136413651366136713681369137013711372137313741375137613771378137913801381138213831384138513861387138813891390139113921393139413951396139713981399140014011402140314041405140614071408140914101411141214131414141514161417141814191420142114221423142414251426142714281429143014311432143314341435143614371438143914401441144214431444144514461447144814491450145114521453145414551456# ===================================================================# COMMON SPRING BOOT PROPERTIES## This sample file is provided as a guideline. Do NOT copy it in its# entirety to your own application. ^^^# ===================================================================# ----------------------------------------# CORE PROPERTIES# ----------------------------------------debug=false # Enable debug logs.trace=false # Enable trace logs.# LOGGINGlogging.config= # Location of the logging configuration file. For instance, `classpath:logback.xml` for Logback.logging.exception-conversion-word=%wEx # Conversion word used when logging exceptions.logging.file= # Log file name (for instance, `myapp.log`). Names can be an exact location or relative to the current directory.logging.file.max-history=0 # Maximum of archive log files to keep. Only supported with the default logback setup.logging.file.max-size=10MB # Maximum log file size. Only supported with the default logback setup.logging.level.*= # Log levels severity mapping. For instance, `logging.level.org.springframework=DEBUG`.logging.path= # Location of the log file. For instance, `/var/log`.logging.pattern.console= # Appender pattern for output to the console. Supported only with the default Logback setup.logging.pattern.dateformat=yyyy-MM-dd HH:mm:ss.SSS # Appender pattern for log date format. Supported only with the default Logback setup.logging.pattern.file= # Appender pattern for output to a file. Supported only with the default Logback setup.logging.pattern.level=%5p # Appender pattern for log level. Supported only with the default Logback setup.logging.register-shutdown-hook=false # Register a shutdown hook for the logging system when it is initialized.# AOPspring.aop.auto=true # Add @EnableAspectJAutoProxy.spring.aop.proxy-target-class=true # Whether subclass-based (CGLIB) proxies are to be created (true), as opposed to standard Java interface-based proxies (false).# IDENTITY (ContextIdApplicationContextInitializer)spring.application.name= # Application name.# ADMIN (SpringApplicationAdminJmxAutoConfiguration)spring.application.admin.enabled=false # Whether to enable admin features for the application.spring.application.admin.jmx-name=org.springframework.boot:type=Admin,name=SpringApplication # JMX name of the application admin MBean.# AUTO-CONFIGURATIONspring.autoconfigure.exclude= # Auto-configuration classes to exclude.# BANNERspring.banner.charset=UTF-8 # Banner file encoding.spring.banner.location=classpath:banner.txt # Banner text resource location.spring.banner.image.location=classpath:banner.gif # Banner image file location (jpg or png can also be used).spring.banner.image.width=76 # Width of the banner image in chars.spring.banner.image.height= # Height of the banner image in chars (default based on image height).spring.banner.image.margin=2 # Left hand image margin in chars.spring.banner.image.invert=false # Whether images should be inverted for dark terminal themes.# SPRING COREspring.beaninfo.ignore=true # Whether to skip search of BeanInfo classes.# SPRING CACHE (CacheProperties)spring.cache.cache-names= # Comma-separated list of cache names to create if supported by the underlying cache manager.spring.cache.caffeine.spec= # The spec to use to create caches. See CaffeineSpec for more details on the spec format.spring.cache.couchbase.expiration=0ms # Entry expiration. By default the entries never expire. Note that this value is ultimately converted to seconds.spring.cache.ehcache.config= # The location of the configuration file to use to initialize EhCache.spring.cache.infinispan.config= # The location of the configuration file to use to initialize Infinispan.spring.cache.jcache.config= # The location of the configuration file to use to initialize the cache manager.spring.cache.jcache.provider= # Fully qualified name of the CachingProvider implementation to use to retrieve the JSR-107 compliant cache manager. Needed only if more than one JSR-107 implementation is available on the classpath.spring.cache.redis.cache-null-values=true # Allow caching null values.spring.cache.redis.key-prefix= # Key prefix.spring.cache.redis.time-to-live=0ms # Entry expiration. By default the entries never expire.spring.cache.redis.use-key-prefix=true # Whether to use the key prefix when writing to Redis.spring.cache.type= # Cache type. By default, auto-detected according to the environment.# SPRING CONFIG - using environment property only (ConfigFileApplicationListener)spring.config.additional-location= # Config file locations used in addition to the defaults.spring.config.location= # Config file locations that replace the defaults.spring.config.name=application # Config file name.# HAZELCAST (HazelcastProperties)spring.hazelcast.config= # The location of the configuration file to use to initialize Hazelcast.# PROJECT INFORMATION (ProjectInfoProperties)spring.info.build.location=classpath:META-INF/build-info.properties # Location of the generated build-info.properties file.spring.info.git.location=classpath:git.properties # Location of the generated git.properties file.# JMXspring.jmx.default-domain= # JMX domain name.spring.jmx.enabled=true # Expose management beans to the JMX domain.spring.jmx.server=mbeanServer # MBeanServer bean name.# Email (MailProperties)spring.mail.default-encoding=UTF-8 # Default MimeMessage encoding.spring.mail.host= # SMTP server host. For instance, `smtp.example.com`.spring.mail.jndi-name= # Session JNDI name. When set, takes precedence over other Session settings.spring.mail.password= # Login password of the SMTP server.spring.mail.port= # SMTP server port.spring.mail.properties.*= # Additional JavaMail Session properties.spring.mail.protocol=smtp # Protocol used by the SMTP server.spring.mail.test-connection=false # Whether to test that the mail server is available on startup.spring.mail.username= # Login user of the SMTP server.# APPLICATION SETTINGS (SpringApplication)spring.main.banner-mode=console # Mode used to display the banner when the application runs.spring.main.sources= # Sources (class names, package names, or XML resource locations) to include in the ApplicationContext.spring.main.web-application-type= # Flag to explicitly request a specific type of web application. If not set, auto-detected based on the classpath.# FILE ENCODING (FileEncodingApplicationListener)spring.mandatory-file-encoding= # Expected character encoding the application must use.# INTERNATIONALIZATION (MessageSourceProperties)spring.messages.always-use-message-format=false # Whether to always apply the MessageFormat rules, parsing even messages without arguments.spring.messages.basename=messages # Comma-separated list of basenames (essentially a fully-qualified classpath location), each following the ResourceBundle convention with relaxed support for slash based locations.spring.messages.cache-duration= # Loaded resource bundle files cache duration. When not set, bundles are cached forever. If a duration suffix is not specified, seconds will be used.spring.messages.encoding=UTF-8 # Message bundles encoding.spring.messages.fallback-to-system-locale=true # Whether to fall back to the system Locale if no files for a specific Locale have been found.spring.messages.use-code-as-default-message=false # Whether to use the message code as the default message instead of throwing a "NoSuchMessageException". Recommended during development only.# OUTPUTspring.output.ansi.enabled=detect # Configures the ANSI output.# PID FILE (ApplicationPidFileWriter)spring.pid.fail-on-write-error= # Fails if ApplicationPidFileWriter is used but it cannot write the PID file.spring.pid.file= # Location of the PID file to write (if ApplicationPidFileWriter is used).# PROFILESspring.profiles.active= # Comma-separated list of active profiles. Can be overridden by a command line switch.spring.profiles.include= # Unconditionally activate the specified comma-separated list of profiles (or list of profiles if using YAML).# QUARTZ SCHEDULER (QuartzProperties)spring.quartz.jdbc.comment-prefix=-- # Prefix for single-line comments in SQL initialization scripts.spring.quartz.jdbc.initialize-schema=embedded # Database schema initialization mode.spring.quartz.jdbc.schema=classpath:org/quartz/impl/jdbcjobstore/tables_@@platform@@.sql # Path to the SQL file to use to initialize the database schema.spring.quartz.job-store-type=memory # Quartz job store type.spring.quartz.properties.*= # Additional Quartz Scheduler properties.# REACTOR (ReactorCoreProperties)spring.reactor.stacktrace-mode.enabled=false # Whether Reactor should collect stacktrace information at runtime.# SENDGRID (SendGridAutoConfiguration)spring.sendgrid.api-key= # SendGrid API key.spring.sendgrid.proxy.host= # SendGrid proxy host.spring.sendgrid.proxy.port= # SendGrid proxy port.# ----------------------------------------# WEB PROPERTIES# ----------------------------------------# EMBEDDED SERVER CONFIGURATION (ServerProperties)server.address= # Network address to which the server should bind.server.compression.enabled=false # Whether response compression is enabled.server.compression.excluded-user-agents= # List of user-agents to exclude from compression.server.compression.mime-types=text/html,text/xml,text/plain,text/css,text/javascript,application/javascript # Comma-separated list of MIME types that should be compressed.server.compression.min-response-size=2048 # Minimum "Content-Length" value that is required for compression to be performed.server.connection-timeout= # Time that connectors wait for another HTTP request before closing the connection. When not set, the connector's container-specific default is used. Use a value of -1 to indicate no (that is, an infinite) timeout.server.error.include-exception=false # Include the "exception" attribute.server.error.include-stacktrace=never # When to include a "stacktrace" attribute.server.error.path=/error # Path of the error controller.server.error.whitelabel.enabled=true # Whether to enable the default error page displayed in browsers in case of a server error.server.http2.enabled=false # Whether to enable HTTP/2 support, if the current environment supports it.server.jetty.acceptors= # Number of acceptor threads to use.server.jetty.accesslog.append=false # Append to log.server.jetty.accesslog.date-format=dd/MMM/yyyy:HH:mm:ss Z # Timestamp format of the request log.server.jetty.accesslog.enabled=false # Enable access log.server.jetty.accesslog.extended-format=false # Enable extended NCSA format.server.jetty.accesslog.file-date-format= # Date format to place in log file name.server.jetty.accesslog.filename= # Log filename. If not specified, logs redirect to "System.err".server.jetty.accesslog.locale= # Locale of the request log.server.jetty.accesslog.log-cookies=false # Enable logging of the request cookies.server.jetty.accesslog.log-latency=false # Enable logging of request processing time.server.jetty.accesslog.log-server=false # Enable logging of the request hostname.server.jetty.accesslog.retention-period=31 # Number of days before rotated log files are deleted.server.jetty.accesslog.time-zone=GMT # Timezone of the request log.server.jetty.max-http-post-size=0 # Maximum size, in bytes, of the HTTP post or put content.server.jetty.selectors= # Number of selector threads to use.server.max-http-header-size=0 # Maximum size, in bytes, of the HTTP message header.server.port=8080 # Server HTTP port.server.server-header= # Value to use for the Server response header (if empty, no header is sent).server.use-forward-headers= # Whether X-Forwarded-* headers should be applied to the HttpRequest.server.servlet.context-parameters.*= # Servlet context init parameters.server.servlet.context-path= # Context path of the application.server.servlet.application-display-name=application # Display name of the application.server.servlet.jsp.class-name=org.apache.jasper.servlet.JspServlet # The class name of the JSP servlet.server.servlet.jsp.init-parameters.*= # Init parameters used to configure the JSP servlet.server.servlet.jsp.registered=true # Whether the JSP servlet is registered.server.servlet.session.cookie.comment= # Comment for the session cookie.server.servlet.session.cookie.domain= # Domain for the session cookie.server.servlet.session.cookie.http-only= # "HttpOnly" flag for the session cookie.server.servlet.session.cookie.max-age= # Maximum age of the session cookie. If a duration suffix is not specified, seconds will be used.server.servlet.session.cookie.name= # Session cookie name.server.servlet.session.cookie.path= # Path of the session cookie.server.servlet.session.cookie.secure= # "Secure" flag for the session cookie.server.servlet.session.persistent=false # Whether to persist session data between restarts.server.servlet.session.store-dir= # Directory used to store session data.server.servlet.session.timeout= # Session timeout. If a duration suffix is not specified, seconds will be used.server.servlet.session.tracking-modes= # Session tracking modes (one or more of the following: "cookie", "url", "ssl").server.ssl.ciphers= # Supported SSL ciphers.server.ssl.client-auth= # Whether client authentication is wanted ("want") or needed ("need"). Requires a trust store.server.ssl.enabled= # Enable SSL support.server.ssl.enabled-protocols= # Enabled SSL protocols.server.ssl.key-alias= # Alias that identifies the key in the key store.server.ssl.key-password= # Password used to access the key in the key store.server.ssl.key-store= # Path to the key store that holds the SSL certificate (typically a jks file).server.ssl.key-store-password= # Password used to access the key store.server.ssl.key-store-provider= # Provider for the key store.server.ssl.key-store-type= # Type of the key store.server.ssl.protocol=TLS # SSL protocol to use.server.ssl.trust-store= # Trust store that holds SSL certificates.server.ssl.trust-store-password= # Password used to access the trust store.server.ssl.trust-store-provider= # Provider for the trust store.server.ssl.trust-store-type= # Type of the trust store.server.tomcat.accept-count=0 # Maximum queue length for incoming connection requests when all possible request processing threads are in use.server.tomcat.accesslog.buffered=true # Whether to buffer output such that it is flushed only periodically.server.tomcat.accesslog.directory=logs # Directory in which log files are created. Can be absolute or relative to the Tomcat base dir.server.tomcat.accesslog.enabled=false # Enable access log.server.tomcat.accesslog.file-date-format=.yyyy-MM-dd # Date format to place in the log file name.server.tomcat.accesslog.pattern=common # Format pattern for access logs.server.tomcat.accesslog.prefix=access_log # Log file name prefix.server.tomcat.accesslog.rename-on-rotate=false # Whether to defer inclusion of the date stamp in the file name until rotate time.server.tomcat.accesslog.request-attributes-enabled=false # Set request attributes for the IP address, Hostname, protocol, and port used for the request.server.tomcat.accesslog.rotate=true # Whether to enable access log rotation.server.tomcat.accesslog.suffix=.log # Log file name suffix.server.tomcat.additional-tld-skip-patterns= # Comma-separated list of additional patterns that match jars to ignore for TLD scanning.server.tomcat.background-processor-delay=30s # Delay between the invocation of backgroundProcess methods. If a duration suffix is not specified, seconds will be used.server.tomcat.basedir= # Tomcat base directory. If not specified, a temporary directory is used.server.tomcat.internal-proxies=10\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 192\\.168\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 169\\.254\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 127\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 172\\.1[6-9]&#123;1&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 172\\.2[0-9]&#123;1&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 172\\.3[0-1]&#123;1&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125; # Regular expression matching trusted IP addresses.server.tomcat.max-connections=0 # Maximum number of connections that the server accepts and processes at any given time.server.tomcat.max-http-header-size=0 # Maximum size, in bytes, of the HTTP message header.server.tomcat.max-http-post-size=0 # Maximum size, in bytes, of the HTTP post content.server.tomcat.max-threads=0 # Maximum number of worker threads.server.tomcat.min-spare-threads=0 # Minimum number of worker threads.server.tomcat.port-header=X-Forwarded-Port # Name of the HTTP header used to override the original port value.server.tomcat.protocol-header= # Header that holds the incoming protocol, usually named "X-Forwarded-Proto".server.tomcat.protocol-header-https-value=https # Value of the protocol header indicating whether the incoming request uses SSL.server.tomcat.redirect-context-root= # Whether requests to the context root should be redirected by appending a / to the path.server.tomcat.remote-ip-header= # Name of the HTTP header from which the remote IP is extracted. For instance, `X-FORWARDED-FOR`.server.tomcat.resource.cache-ttl= # Time-to-live of the static resource cache.server.tomcat.uri-encoding=UTF-8 # Character encoding to use to decode the URI.server.tomcat.use-relative-redirects= # Whether HTTP 1.1 and later location headers generated by a call to sendRedirect will use relative or absolute redirects.server.undertow.accesslog.dir= # Undertow access log directory.server.undertow.accesslog.enabled=false # Whether to enable the access log.server.undertow.accesslog.pattern=common # Format pattern for access logs.server.undertow.accesslog.prefix=access_log. # Log file name prefix.server.undertow.accesslog.rotate=true # Whether to enable access log rotation.server.undertow.accesslog.suffix=log # Log file name suffix.server.undertow.buffer-size= # Size of each buffer, in bytes.server.undertow.direct-buffers= # Whether to allocate buffers outside the Java heap.server.undertow.io-threads= # Number of I/O threads to create for the worker.server.undertow.eager-filter-init=true # Whether servlet filters should be initialized on startup.server.undertow.max-http-post-size=0 # Maximum size, in bytes, of the HTTP post content.server.undertow.worker-threads= # Number of worker threads.# FREEMARKER (FreeMarkerProperties)spring.freemarker.allow-request-override=false # Whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.spring.freemarker.allow-session-override=false # Whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.spring.freemarker.cache=false # Whether to enable template caching.spring.freemarker.charset=UTF-8 # Template encoding.spring.freemarker.check-template-location=true # Whether to check that the templates location exists.spring.freemarker.content-type=text/html # Content-Type value.spring.freemarker.enabled=true # Whether to enable MVC view resolution for this technology.spring.freemarker.expose-request-attributes=false # Whether all request attributes should be added to the model prior to merging with the template.spring.freemarker.expose-session-attributes=false # Whether all HttpSession attributes should be added to the model prior to merging with the template.spring.freemarker.expose-spring-macro-helpers=true # Whether to expose a RequestContext for use by Spring's macro library, under the name "springMacroRequestContext".spring.freemarker.prefer-file-system-access=true # Whether to prefer file system access for template loading. File system access enables hot detection of template changes.spring.freemarker.prefix= # Prefix that gets prepended to view names when building a URL.spring.freemarker.request-context-attribute= # Name of the RequestContext attribute for all views.spring.freemarker.settings.*= # Well-known FreeMarker keys which are passed to FreeMarker's Configuration.spring.freemarker.suffix=.ftl # Suffix that gets appended to view names when building a URL.spring.freemarker.template-loader-path=classpath:/templates/ # Comma-separated list of template paths.spring.freemarker.view-names= # White list of view names that can be resolved.# GROOVY TEMPLATES (GroovyTemplateProperties)spring.groovy.template.allow-request-override=false # Whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.spring.groovy.template.allow-session-override=false # Whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.spring.groovy.template.cache=false # Whether to enable template caching.spring.groovy.template.charset=UTF-8 # Template encoding.spring.groovy.template.check-template-location=true # Whether to check that the templates location exists.spring.groovy.template.configuration.*= # See GroovyMarkupConfigurerspring.groovy.template.content-type=text/html # Content-Type value.spring.groovy.template.enabled=true # Whether to enable MVC view resolution for this technology.spring.groovy.template.expose-request-attributes=false # Whether all request attributes should be added to the model prior to merging with the template.spring.groovy.template.expose-session-attributes=false # Whether all HttpSession attributes should be added to the model prior to merging with the template.spring.groovy.template.expose-spring-macro-helpers=true # Whether to expose a RequestContext for use by Spring's macro library, under the name "springMacroRequestContext".spring.groovy.template.prefix= # Prefix that gets prepended to view names when building a URL.spring.groovy.template.request-context-attribute= # Name of the RequestContext attribute for all views.spring.groovy.template.resource-loader-path=classpath:/templates/ # Template path.spring.groovy.template.suffix=.tpl # Suffix that gets appended to view names when building a URL.spring.groovy.template.view-names= # White list of view names that can be resolved.# SPRING HATEOAS (HateoasProperties)spring.hateoas.use-hal-as-default-json-media-type=true # Whether application/hal+json responses should be sent to requests that accept application/json.# HTTP message conversionspring.http.converters.preferred-json-mapper= # Preferred JSON mapper to use for HTTP message conversion. By default, auto-detected according to the environment.# HTTP encoding (HttpEncodingProperties)spring.http.encoding.charset=UTF-8 # Charset of HTTP requests and responses. Added to the "Content-Type" header if not set explicitly.spring.http.encoding.enabled=true # Whether to enable http encoding support.spring.http.encoding.force= # Whether to force the encoding to the configured charset on HTTP requests and responses.spring.http.encoding.force-request= # Whether to force the encoding to the configured charset on HTTP requests. Defaults to true when "force" has not been specified.spring.http.encoding.force-response= # Whether to force the encoding to the configured charset on HTTP responses.spring.http.encoding.mapping= # Locale in which to encode mapping.# MULTIPART (MultipartProperties)spring.servlet.multipart.enabled=true # Whether to enable support of multipart uploads.spring.servlet.multipart.file-size-threshold=0 # Threshold after which files are written to disk. Values can use the suffixes "MB" or "KB" to indicate megabytes or kilobytes, respectively.spring.servlet.multipart.location= # Intermediate location of uploaded files.spring.servlet.multipart.max-file-size=1MB # Max file size. Values can use the suffixes "MB" or "KB" to indicate megabytes or kilobytes, respectively.spring.servlet.multipart.max-request-size=10MB # Max request size. Values can use the suffixes "MB" or "KB" to indicate megabytes or kilobytes, respectively.spring.servlet.multipart.resolve-lazily=false # Whether to resolve the multipart request lazily at the time of file or parameter access.# JACKSON (JacksonProperties)spring.jackson.date-format= # Date format string or a fully-qualified date format class name. For instance, `yyyy-MM-dd HH:mm:ss`.spring.jackson.default-property-inclusion= # Controls the inclusion of properties during serialization. Configured with one of the values in Jackson's JsonInclude.Include enumeration.spring.jackson.deserialization.*= # Jackson on/off features that affect the way Java objects are deserialized.spring.jackson.generator.*= # Jackson on/off features for generators.spring.jackson.joda-date-time-format= # Joda date time format string. If not configured, "date-format" is used as a fallback if it is configured with a format string.spring.jackson.locale= # Locale used for formatting.spring.jackson.mapper.*= # Jackson general purpose on/off features.spring.jackson.parser.*= # Jackson on/off features for parsers.spring.jackson.property-naming-strategy= # One of the constants on Jackson's PropertyNamingStrategy. Can also be a fully-qualified class name of a PropertyNamingStrategy subclass.spring.jackson.serialization.*= # Jackson on/off features that affect the way Java objects are serialized.spring.jackson.time-zone= # Time zone used when formatting dates. For instance, "America/Los_Angeles" or "GMT+10".# GSON (GsonProperties)spring.gson.date-format= # Format to use when serializing Date objects.spring.gson.disable-html-escaping= # Whether to disable the escaping of HTML characters such as '&lt;', '&gt;', etc.spring.gson.disable-inner-class-serialization= # Whether to exclude inner classes during serialization.spring.gson.enable-complex-map-key-serialization= # Whether to enable serialization of complex map keys (i.e. non-primitives).spring.gson.exclude-fields-without-expose-annotation= # Whether to exclude all fields from consideration for serialization or deserialization that do not have the "Expose" annotation.spring.gson.field-naming-policy= # Naming policy that should be applied to an object's field during serialization and deserialization.spring.gson.generate-non-executable-json= # Whether to generate non executable JSON by prefixing the output with some special text.spring.gson.lenient= # Whether to be lenient about parsing JSON that doesn't conform to RFC 4627.spring.gson.long-serialization-policy= # Serialization policy for Long and long types.spring.gson.pretty-printing= # Whether to output serialized JSON that fits in a page for pretty printing.spring.gson.serialize-nulls= # Whether to serialize null fields.# JERSEY (JerseyProperties)spring.jersey.application-path= # Path that serves as the base URI for the application. If specified, overrides the value of "@ApplicationPath".spring.jersey.filter.order=0 # Jersey filter chain order.spring.jersey.init.*= # Init parameters to pass to Jersey through the servlet or filter.spring.jersey.servlet.load-on-startup=-1 # Load on startup priority of the Jersey servlet.spring.jersey.type=servlet # Jersey integration type.# SPRING LDAP (LdapProperties)spring.ldap.anonymous-read-only=false # Whether read-only operations should use an anonymous environment.spring.ldap.base= # Base suffix from which all operations should originate.spring.ldap.base-environment.*= # LDAP specification settings.spring.ldap.password= # Login password of the server.spring.ldap.urls= # LDAP URLs of the server.spring.ldap.username= # Login username of the server.# EMBEDDED LDAP (EmbeddedLdapProperties)spring.ldap.embedded.base-dn= # List of base DNs.spring.ldap.embedded.credential.username= # Embedded LDAP username.spring.ldap.embedded.credential.password= # Embedded LDAP password.spring.ldap.embedded.ldif=classpath:schema.ldif # Schema (LDIF) script resource reference.spring.ldap.embedded.port=0 # Embedded LDAP port.spring.ldap.embedded.validation.enabled=true # Whether to enable LDAP schema validation.spring.ldap.embedded.validation.schema= # Path to the custom schema.# MUSTACHE TEMPLATES (MustacheAutoConfiguration)spring.mustache.allow-request-override=false # Whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.spring.mustache.allow-session-override=false # Whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.spring.mustache.cache=false # Whether to enable template caching.spring.mustache.charset=UTF-8 # Template encoding.spring.mustache.check-template-location=true # Whether to check that the templates location exists.spring.mustache.content-type=text/html # Content-Type value.spring.mustache.enabled=true # Whether to enable MVC view resolution for this technology.spring.mustache.expose-request-attributes=false # Whether all request attributes should be added to the model prior to merging with the template.spring.mustache.expose-session-attributes=false # Whether all HttpSession attributes should be added to the model prior to merging with the template.spring.mustache.expose-spring-macro-helpers=true # Whether to expose a RequestContext for use by Spring's macro library, under the name "springMacroRequestContext".spring.mustache.prefix=classpath:/templates/ # Prefix to apply to template names.spring.mustache.request-context-attribute= # Name of the RequestContext attribute for all views.spring.mustache.suffix=.mustache # Suffix to apply to template names.spring.mustache.view-names= # White list of view names that can be resolved.# SPRING MVC (WebMvcProperties)spring.mvc.async.request-timeout= # Amount of time before asynchronous request handling times out.spring.mvc.contentnegotiation.favor-parameter=false # Whether a request parameter ("format" by default) should be used to determine the requested media type.spring.mvc.contentnegotiation.favor-path-extension=false # Whether the path extension in the URL path should be used to determine the requested media type.spring.mvc.contentnegotiation.media-types.*= # Map file extensions to media types for content negotiation. For instance, yml to text/yaml.spring.mvc.contentnegotiation.parameter-name= # Query parameter name to use when "favor-parameter" is enabled.spring.mvc.date-format= # Date format to use. For instance, `dd/MM/yyyy`.spring.mvc.dispatch-trace-request=false # Whether to dispatch TRACE requests to the FrameworkServlet doService method.spring.mvc.dispatch-options-request=true # Whether to dispatch OPTIONS requests to the FrameworkServlet doService method.spring.mvc.favicon.enabled=true # Whether to enable resolution of favicon.ico.spring.mvc.formcontent.putfilter.enabled=true # Whether to enable Spring's HttpPutFormContentFilter.spring.mvc.ignore-default-model-on-redirect=true # Whether the content of the "default" model should be ignored during redirect scenarios.spring.mvc.locale= # Locale to use. By default, this locale is overridden by the "Accept-Language" header.spring.mvc.locale-resolver=accept-header # Define how the locale should be resolved.spring.mvc.log-resolved-exception=false # Whether to enable warn logging of exceptions resolved by a "HandlerExceptionResolver".spring.mvc.message-codes-resolver-format= # Formatting strategy for message codes. For instance, `PREFIX_ERROR_CODE`.spring.mvc.pathmatch.use-registered-suffix-pattern=false # Whether suffix pattern matching should work only against extensions registered with "spring.mvc.contentnegotiation.media-types.*".spring.mvc.pathmatch.use-suffix-pattern=false # Whether to use suffix pattern match (".*") when matching patterns to requests.spring.mvc.servlet.load-on-startup=-1 # Load on startup priority of the dispatcher servlet.spring.mvc.servlet.path=/ # Path of the dispatcher servlet.spring.mvc.static-path-pattern=/** # Path pattern used for static resources.spring.mvc.throw-exception-if-no-handler-found=false # Whether a "NoHandlerFoundException" should be thrown if no Handler was found to process a request.spring.mvc.view.prefix= # Spring MVC view prefix.spring.mvc.view.suffix= # Spring MVC view suffix.# SPRING RESOURCES HANDLING (ResourceProperties)spring.resources.add-mappings=true # Whether to enable default resource handling.spring.resources.cache.cachecontrol.cache-private= # Indicate that the response message is intended for a single user and must not be stored by a shared cache.spring.resources.cache.cachecontrol.cache-public= # Indicate that any cache may store the response.spring.resources.cache.cachecontrol.max-age= # Maximum time the response should be cached, in seconds if no duration suffix is not specified.spring.resources.cache.cachecontrol.must-revalidate= # Indicate that once it has become stale, a cache must not use the response without re-validating it with the server.spring.resources.cache.cachecontrol.no-cache= # Indicate that the cached response can be reused only if re-validated with the server.spring.resources.cache.cachecontrol.no-store= # Indicate to not cache the response in any case.spring.resources.cache.cachecontrol.no-transform= # Indicate intermediaries (caches and others) that they should not transform the response content.spring.resources.cache.cachecontrol.proxy-revalidate= # Same meaning as the "must-revalidate" directive, except that it does not apply to private caches.spring.resources.cache.cachecontrol.s-max-age= # Maximum time the response should be cached by shared caches, in seconds if no duration suffix is not specified.spring.resources.cache.cachecontrol.stale-if-error= # Maximum time the response may be used when errors are encountered, in seconds if no duration suffix is not specified.spring.resources.cache.cachecontrol.stale-while-revalidate= # Maximum time the response can be served after it becomes stale, in seconds if no duration suffix is not specified.spring.resources.cache.period= # Cache period for the resources served by the resource handler. If a duration suffix is not specified, seconds will be used.spring.resources.chain.cache=true # Whether to enable caching in the Resource chain.spring.resources.chain.enabled= # Whether to enable the Spring Resource Handling chain. By default, disabled unless at least one strategy has been enabled.spring.resources.chain.gzipped=false # Whether to enable resolution of already gzipped resources.spring.resources.chain.html-application-cache=false # Whether to enable HTML5 application cache manifest rewriting.spring.resources.chain.strategy.content.enabled=false # Whether to enable the content Version Strategy.spring.resources.chain.strategy.content.paths=/** # Comma-separated list of patterns to apply to the content Version Strategy.spring.resources.chain.strategy.fixed.enabled=false # Whether to enable the fixed Version Strategy.spring.resources.chain.strategy.fixed.paths=/** # Comma-separated list of patterns to apply to the fixed Version Strategy.spring.resources.chain.strategy.fixed.version= # Version string to use for the fixed Version Strategy.spring.resources.static-locations=classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/ # Locations of static resources.# SPRING SESSION (SessionProperties)spring.session.store-type= # Session store type.spring.session.timeout= # Session timeout. If a duration suffix is not specified, seconds will be used.spring.session.servlet.filter-order=-2147483598 # Session repository filter order.spring.session.servlet.filter-dispatcher-types=async,error,request # Session repository filter dispatcher types.# SPRING SESSION HAZELCAST (HazelcastSessionProperties)spring.session.hazelcast.flush-mode=on-save # Sessions flush mode.spring.session.hazelcast.map-name=spring:session:sessions # Name of the map used to store sessions.# SPRING SESSION JDBC (JdbcSessionProperties)spring.session.jdbc.cleanup-cron=0 * * * * * # Cron expression for expired session cleanup job.spring.session.jdbc.initialize-schema=embedded # Database schema initialization mode.spring.session.jdbc.schema=classpath:org/springframework/session/jdbc/schema-@@platform@@.sql # Path to the SQL file to use to initialize the database schema.spring.session.jdbc.table-name=SPRING_SESSION # Name of the database table used to store sessions.# SPRING SESSION MONGODB (MongoSessionProperties)spring.session.mongodb.collection-name=sessions # Collection name used to store sessions.# SPRING SESSION REDIS (RedisSessionProperties)spring.session.redis.cleanup-cron=0 * * * * * # Cron expression for expired session cleanup job.spring.session.redis.flush-mode=on-save # Sessions flush mode.spring.session.redis.namespace=spring:session # Namespace for keys used to store sessions.# THYMELEAF (ThymeleafAutoConfiguration)spring.thymeleaf.cache=true # Whether to enable template caching.spring.thymeleaf.check-template=true # Whether to check that the template exists before rendering it.spring.thymeleaf.check-template-location=true # Whether to check that the templates location exists.spring.thymeleaf.enabled=true # Whether to enable Thymeleaf view resolution for Web frameworks.spring.thymeleaf.enable-spring-el-compiler=false # Enable the SpringEL compiler in SpringEL expressions.spring.thymeleaf.encoding=UTF-8 # Template files encoding.spring.thymeleaf.excluded-view-names= # Comma-separated list of view names (patterns allowed) that should be excluded from resolution.spring.thymeleaf.mode=HTML # Template mode to be applied to templates. See also Thymeleaf's TemplateMode enum.spring.thymeleaf.prefix=classpath:/templates/ # Prefix that gets prepended to view names when building a URL.spring.thymeleaf.reactive.chunked-mode-view-names= # Comma-separated list of view names (patterns allowed) that should be the only ones executed in CHUNKED mode when a max chunk size is set.spring.thymeleaf.reactive.full-mode-view-names= # Comma-separated list of view names (patterns allowed) that should be executed in FULL mode even if a max chunk size is set.spring.thymeleaf.reactive.max-chunk-size=0 # Maximum size of data buffers used for writing to the response, in bytes.spring.thymeleaf.reactive.media-types= # Media types supported by the view technology.spring.thymeleaf.servlet.content-type=text/html # Content-Type value written to HTTP responses.spring.thymeleaf.suffix=.html # Suffix that gets appended to view names when building a URL.spring.thymeleaf.template-resolver-order= # Order of the template resolver in the chain.spring.thymeleaf.view-names= # Comma-separated list of view names (patterns allowed) that can be resolved.# SPRING WEBFLUX (WebFluxProperties)spring.webflux.date-format= # Date format to use. For instance, `dd/MM/yyyy`.spring.webflux.static-path-pattern=/** # Path pattern used for static resources.# SPRING WEB SERVICES (WebServicesProperties)spring.webservices.path=/services # Path that serves as the base URI for the services.spring.webservices.servlet.init= # Servlet init parameters to pass to Spring Web Services.spring.webservices.servlet.load-on-startup=-1 # Load on startup priority of the Spring Web Services servlet.spring.webservices.wsdl-locations= # Comma-separated list of locations of WSDLs and accompanying XSDs to be exposed as beans.# ----------------------------------------# SECURITY PROPERTIES# ----------------------------------------# SECURITY (SecurityProperties)spring.security.filter.order=-100 # Security filter chain order.spring.security.filter.dispatcher-types=async,error,request # Security filter chain dispatcher types.spring.security.user.name=user # Default user name.spring.security.user.password= # Password for the default user name.spring.security.user.roles= # Granted roles for the default user name.# SECURITY OAUTH2 CLIENT (OAuth2ClientProperties)spring.security.oauth2.client.provider.*= # OAuth provider details.spring.security.oauth2.client.registration.*= # OAuth client registrations.# ----------------------------------------# DATA PROPERTIES# ----------------------------------------# FLYWAY (FlywayProperties)spring.flyway.baseline-description= #spring.flyway.baseline-on-migrate= #spring.flyway.baseline-version=1 # Version to start migrationspring.flyway.check-location=true # Whether to check that migration scripts location exists.spring.flyway.clean-disabled= #spring.flyway.clean-on-validation-error= #spring.flyway.dry-run-output= #spring.flyway.enabled=true # Whether to enable flyway.spring.flyway.encoding= #spring.flyway.error-handlers= #spring.flyway.group= #spring.flyway.ignore-future-migrations= #spring.flyway.ignore-missing-migrations= #spring.flyway.init-sqls= # SQL statements to execute to initialize a connection immediately after obtaining it.spring.flyway.installed-by= #spring.flyway.locations=classpath:db/migration # The locations of migrations scripts.spring.flyway.mixed= #spring.flyway.out-of-order= #spring.flyway.password= # JDBC password to use if you want Flyway to create its own DataSource.spring.flyway.placeholder-prefix= #spring.flyway.placeholder-replacement= #spring.flyway.placeholder-suffix= #spring.flyway.placeholders.*= #spring.flyway.repeatable-sql-migration-prefix= #spring.flyway.schemas= # schemas to updatespring.flyway.skip-default-callbacks= #spring.flyway.skip-default-resolvers= #spring.flyway.sql-migration-prefix=V #spring.flyway.sql-migration-separator= #spring.flyway.sql-migration-suffix=.sql #spring.flyway.sql-migration-suffixes= #spring.flyway.table= #spring.flyway.target= #spring.flyway.undo-sql-migration-prefix= #spring.flyway.url= # JDBC url of the database to migrate. If not set, the primary configured data source is used.spring.flyway.user= # Login user of the database to migrate.spring.flyway.validate-on-migrate= ## LIQUIBASE (LiquibaseProperties)spring.liquibase.change-log=classpath:/db/changelog/db.changelog-master.yaml # Change log configuration path.spring.liquibase.check-change-log-location=true # Whether to check that the change log location exists.spring.liquibase.contexts= # Comma-separated list of runtime contexts to use.spring.liquibase.default-schema= # Default database schema.spring.liquibase.drop-first=false # Whether to first drop the database schema.spring.liquibase.enabled=true # Whether to enable Liquibase support.spring.liquibase.labels= # Comma-separated list of runtime labels to use.spring.liquibase.parameters.*= # Change log parameters.spring.liquibase.password= # Login password of the database to migrate.spring.liquibase.rollback-file= # File to which rollback SQL is written when an update is performed.spring.liquibase.test-rollback-on-update=false # Whether rollback should be tested before update is performed.spring.liquibase.url= # JDBC URL of the database to migrate. If not set, the primary configured data source is used.spring.liquibase.user= # Login user of the database to migrate.# COUCHBASE (CouchbaseProperties)spring.couchbase.bootstrap-hosts= # Couchbase nodes (host or IP address) to bootstrap from.spring.couchbase.bucket.name=default # Name of the bucket to connect to.spring.couchbase.bucket.password= # Password of the bucket.spring.couchbase.env.endpoints.key-value=1 # Number of sockets per node against the key/value service.spring.couchbase.env.endpoints.queryservice.min-endpoints=1 # Minimum number of sockets per node.spring.couchbase.env.endpoints.queryservice.max-endpoints=1 # Maximum number of sockets per node.spring.couchbase.env.endpoints.viewservice.min-endpoints=1 # Minimum number of sockets per node.spring.couchbase.env.endpoints.viewservice.max-endpoints=1 # Maximum number of sockets per node.spring.couchbase.env.ssl.enabled= # Whether to enable SSL support. Enabled automatically if a "keyStore" is provided unless specified otherwise.spring.couchbase.env.ssl.key-store= # Path to the JVM key store that holds the certificates.spring.couchbase.env.ssl.key-store-password= # Password used to access the key store.spring.couchbase.env.timeouts.connect=5000ms # Bucket connections timeouts.spring.couchbase.env.timeouts.key-value=2500ms # Blocking operations performed on a specific key timeout.spring.couchbase.env.timeouts.query=7500ms # N1QL query operations timeout.spring.couchbase.env.timeouts.socket-connect=1000ms # Socket connect connections timeout.spring.couchbase.env.timeouts.view=7500ms # Regular and geospatial view operations timeout.# DAO (PersistenceExceptionTranslationAutoConfiguration)spring.dao.exceptiontranslation.enabled=true # Whether to enable the PersistenceExceptionTranslationPostProcessor.# CASSANDRA (CassandraProperties)spring.data.cassandra.cluster-name= # Name of the Cassandra cluster.spring.data.cassandra.compression=none # Compression supported by the Cassandra binary protocol.spring.data.cassandra.connect-timeout= # Socket option: connection time out.spring.data.cassandra.consistency-level= # Queries consistency level.spring.data.cassandra.contact-points=localhost # Cluster node addresses.spring.data.cassandra.fetch-size= # Queries default fetch size.spring.data.cassandra.keyspace-name= # Keyspace name to use.spring.data.cassandra.load-balancing-policy= # Class name of the load balancing policy.spring.data.cassandra.port= # Port of the Cassandra server.spring.data.cassandra.password= # Login password of the server.spring.data.cassandra.pool.heartbeat-interval=30s # Heartbeat interval after which a message is sent on an idle connection to make sure it's still alive. If a duration suffix is not specified, seconds will be used.spring.data.cassandra.pool.idle-timeout=120s # Idle timeout before an idle connection is removed. If a duration suffix is not specified, seconds will be used.spring.data.cassandra.pool.max-queue-size=256 # Maximum number of requests that get queued if no connection is available.spring.data.cassandra.pool.pool-timeout=5000ms # Pool timeout when trying to acquire a connection from a host's pool.spring.data.cassandra.read-timeout= # Socket option: read time out.spring.data.cassandra.reconnection-policy= # Reconnection policy class.spring.data.cassandra.repositories.type=auto # Type of Cassandra repositories to enable.spring.data.cassandra.retry-policy= # Class name of the retry policy.spring.data.cassandra.serial-consistency-level= # Queries serial consistency level.spring.data.cassandra.schema-action=none # Schema action to take at startup.spring.data.cassandra.ssl=false # Enable SSL support.spring.data.cassandra.username= # Login user of the server.# DATA COUCHBASE (CouchbaseDataProperties)spring.data.couchbase.auto-index=false # Automatically create views and indexes.spring.data.couchbase.consistency=read-your-own-writes # Consistency to apply by default on generated queries.spring.data.couchbase.repositories.type=auto # Type of Couchbase repositories to enable.# ELASTICSEARCH (ElasticsearchProperties)spring.data.elasticsearch.cluster-name=elasticsearch # Elasticsearch cluster name.spring.data.elasticsearch.cluster-nodes= # Comma-separated list of cluster node addresses.spring.data.elasticsearch.properties.*= # Additional properties used to configure the client.spring.data.elasticsearch.repositories.enabled=true # Whether to enable Elasticsearch repositories.# DATA LDAPspring.data.ldap.repositories.enabled=true # Whether to enable LDAP repositories.# MONGODB (MongoProperties)spring.data.mongodb.authentication-database= # Authentication database name.spring.data.mongodb.database= # Database name.spring.data.mongodb.field-naming-strategy= # Fully qualified name of the FieldNamingStrategy to use.spring.data.mongodb.grid-fs-database= # GridFS database name.spring.data.mongodb.host= # Mongo server host. Cannot be set with URI.spring.data.mongodb.password= # Login password of the mongo server. Cannot be set with URI.spring.data.mongodb.port= # Mongo server port. Cannot be set with URI.spring.data.mongodb.repositories.type=auto # Type of Mongo repositories to enable.spring.data.mongodb.uri=mongodb://localhost/test # Mongo database URI. Cannot be set with host, port and credentials.spring.data.mongodb.username= # Login user of the mongo server. Cannot be set with URI.# DATA REDISspring.data.redis.repositories.enabled=true # Whether to enable Redis repositories.# NEO4J (Neo4jProperties)spring.data.neo4j.auto-index=none # Auto index mode.spring.data.neo4j.embedded.enabled=true # Whether to enable embedded mode if the embedded driver is available.spring.data.neo4j.open-in-view=true # Register OpenSessionInViewInterceptor. Binds a Neo4j Session to the thread for the entire processing of the request.spring.data.neo4j.password= # Login password of the server.spring.data.neo4j.repositories.enabled=true # Whether to enable Neo4j repositories.spring.data.neo4j.uri= # URI used by the driver. Auto-detected by default.spring.data.neo4j.username= # Login user of the server.# DATA REST (RepositoryRestProperties)spring.data.rest.base-path= # Base path to be used by Spring Data REST to expose repository resources.spring.data.rest.default-media-type= # Content type to use as a default when none is specified.spring.data.rest.default-page-size= # Default size of pages.spring.data.rest.detection-strategy=default # Strategy to use to determine which repositories get exposed.spring.data.rest.enable-enum-translation= # Whether to enable enum value translation through the Spring Data REST default resource bundle.spring.data.rest.limit-param-name= # Name of the URL query string parameter that indicates how many results to return at once.spring.data.rest.max-page-size= # Maximum size of pages.spring.data.rest.page-param-name= # Name of the URL query string parameter that indicates what page to return.spring.data.rest.return-body-on-create= # Whether to return a response body after creating an entity.spring.data.rest.return-body-on-update= # Whether to return a response body after updating an entity.spring.data.rest.sort-param-name= # Name of the URL query string parameter that indicates what direction to sort results.# SOLR (SolrProperties)spring.data.solr.host=http://127.0.0.1:8983/solr # Solr host. Ignored if "zk-host" is set.spring.data.solr.repositories.enabled=true # Whether to enable Solr repositories.spring.data.solr.zk-host= # ZooKeeper host address in the form HOST:PORT.# DATA WEB (SpringDataWebProperties)spring.data.web.pageable.default-page-size=20 # Default page size.spring.data.web.pageable.max-page-size=2000 # Maximum page size to be accepted.spring.data.web.pageable.one-indexed-parameters=false # Whether to expose and assume 1-based page number indexes.spring.data.web.pageable.page-parameter=page # Page index parameter name.spring.data.web.pageable.prefix= # General prefix to be prepended to the page number and page size parameters.spring.data.web.pageable.qualifier-delimiter=_ # Delimiter to be used between the qualifier and the actual page number and size properties.spring.data.web.pageable.size-parameter=size # Page size parameter name.spring.data.web.sort.sort-parameter=sort # Sort parameter name.# DATASOURCE (DataSourceAutoConfiguration &amp; DataSourceProperties)spring.datasource.continue-on-error=false # Whether to stop if an error occurs while initializing the database.spring.datasource.data= # Data (DML) script resource references.spring.datasource.data-username= # Username of the database to execute DML scripts (if different).spring.datasource.data-password= # Password of the database to execute DML scripts (if different).spring.datasource.dbcp2.*= # Commons DBCP2 specific settingsspring.datasource.driver-class-name= # Fully qualified name of the JDBC driver. Auto-detected based on the URL by default.spring.datasource.generate-unique-name=false # Whether to generate a random datasource name.spring.datasource.hikari.*= # Hikari specific settingsspring.datasource.initialization-mode=embedded # Initialize the datasource with available DDL and DML scripts.spring.datasource.jmx-enabled=false # Whether to enable JMX support (if provided by the underlying pool).spring.datasource.jndi-name= # JNDI location of the datasource. Class, url, username &amp; password are ignored when set.spring.datasource.name= # Name of the datasource. Default to "testdb" when using an embedded database.spring.datasource.password= # Login password of the database.spring.datasource.platform=all # Platform to use in the DDL or DML scripts (such as schema-$&#123;platform&#125;.sql or data-$&#123;platform&#125;.sql).spring.datasource.schema= # Schema (DDL) script resource references.spring.datasource.schema-username= # Username of the database to execute DDL scripts (if different).spring.datasource.schema-password= # Password of the database to execute DDL scripts (if different).spring.datasource.separator=; # Statement separator in SQL initialization scripts.spring.datasource.sql-script-encoding= # SQL scripts encoding.spring.datasource.tomcat.*= # Tomcat datasource specific settingsspring.datasource.type= # Fully qualified name of the connection pool implementation to use. By default, it is auto-detected from the classpath.spring.datasource.url= # JDBC URL of the database.spring.datasource.username= # Login username of the database.spring.datasource.xa.data-source-class-name= # XA datasource fully qualified name.spring.datasource.xa.properties= # Properties to pass to the XA data source.# JEST (Elasticsearch HTTP client) (JestProperties)spring.elasticsearch.jest.connection-timeout=3s # Connection timeout.spring.elasticsearch.jest.multi-threaded=true # Whether to enable connection requests from multiple execution threads.spring.elasticsearch.jest.password= # Login password.spring.elasticsearch.jest.proxy.host= # Proxy host the HTTP client should use.spring.elasticsearch.jest.proxy.port= # Proxy port the HTTP client should use.spring.elasticsearch.jest.read-timeout=3s # Read timeout.spring.elasticsearch.jest.uris=http://localhost:9200 # Comma-separated list of the Elasticsearch instances to use.spring.elasticsearch.jest.username= # Login username.# Elasticsearch REST clients (RestClientProperties)spring.elasticsearch.rest.password= # Credentials username. spring.elasticsearch.rest.uris=http://localhost:9200 # Comma-separated list of the Elasticsearch instances to use. spring.elasticsearch.rest.username= # Credentials password.# H2 Web Console (H2ConsoleProperties)spring.h2.console.enabled=false # Whether to enable the console.spring.h2.console.path=/h2-console # Path at which the console is available.spring.h2.console.settings.trace=false # Whether to enable trace output.spring.h2.console.settings.web-allow-others=false # Whether to enable remote access.# InfluxDB (InfluxDbProperties)spring.influx.password= # Login password.spring.influx.url= # URL of the InfluxDB instance to which to connect.spring.influx.user= # Login user.# JOOQ (JooqProperties)spring.jooq.sql-dialect= # SQL dialect to use. Auto-detected by default.# JDBC (JdbcProperties)spring.jdbc.template.fetch-size=-1 # Number of rows that should be fetched from the database when more rows are needed.spring.jdbc.template.max-rows=-1 # Maximum number of rows.spring.jdbc.template.query-timeout= # Query timeout. Default is to use the JDBC driver's default configuration. If a duration suffix is not specified, seconds will be used.# JPA (JpaBaseConfiguration, HibernateJpaAutoConfiguration)spring.data.jpa.repositories.enabled=true # Whether to enable JPA repositories.spring.jpa.database= # Target database to operate on, auto-detected by default. Can be alternatively set using the "databasePlatform" property.spring.jpa.database-platform= # Name of the target database to operate on, auto-detected by default. Can be alternatively set using the "Database" enum.spring.jpa.generate-ddl=false # Whether to initialize the schema on startup.spring.jpa.hibernate.ddl-auto= # DDL mode. This is actually a shortcut for the "hibernate.hbm2ddl.auto" property. Defaults to "create-drop" when using an embedded database and no schema manager was detected. Otherwise, defaults to "none".spring.jpa.hibernate.naming.implicit-strategy= # Fully qualified name of the implicit naming strategy.spring.jpa.hibernate.naming.physical-strategy= # Fully qualified name of the physical naming strategy.spring.jpa.hibernate.use-new-id-generator-mappings= # Whether to use Hibernate's newer IdentifierGenerator for AUTO, TABLE and SEQUENCE.spring.jpa.mapping-resources= # Mapping resources (equivalent to "mapping-file" entries in persistence.xml).spring.jpa.open-in-view=true # Register OpenEntityManagerInViewInterceptor. Binds a JPA EntityManager to the thread for the entire processing of the request.spring.jpa.properties.*= # Additional native properties to set on the JPA provider.spring.jpa.show-sql=false # Whether to enable logging of SQL statements.# JTA (JtaAutoConfiguration)spring.jta.enabled=true # Whether to enable JTA support.spring.jta.log-dir= # Transaction logs directory.spring.jta.transaction-manager-id= # Transaction manager unique identifier.# ATOMIKOS (AtomikosProperties)spring.jta.atomikos.connectionfactory.borrow-connection-timeout=30 # Timeout, in seconds, for borrowing connections from the pool.spring.jta.atomikos.connectionfactory.ignore-session-transacted-flag=true # Whether to ignore the transacted flag when creating session.spring.jta.atomikos.connectionfactory.local-transaction-mode=false # Whether local transactions are desired.spring.jta.atomikos.connectionfactory.maintenance-interval=60 # The time, in seconds, between runs of the pool's maintenance thread.spring.jta.atomikos.connectionfactory.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.atomikos.connectionfactory.max-lifetime=0 # The time, in seconds, that a connection can be pooled for before being destroyed. 0 denotes no limit.spring.jta.atomikos.connectionfactory.max-pool-size=1 # The maximum size of the pool.spring.jta.atomikos.connectionfactory.min-pool-size=1 # The minimum size of the pool.spring.jta.atomikos.connectionfactory.reap-timeout=0 # The reap timeout, in seconds, for borrowed connections. 0 denotes no limit.spring.jta.atomikos.connectionfactory.unique-resource-name=jmsConnectionFactory # The unique name used to identify the resource during recovery.spring.jta.atomikos.connectionfactory.xa-connection-factory-class-name= # Vendor-specific implementation of XAConnectionFactory.spring.jta.atomikos.connectionfactory.xa-properties= # Vendor-specific XA properties.spring.jta.atomikos.datasource.borrow-connection-timeout=30 # Timeout, in seconds, for borrowing connections from the pool.spring.jta.atomikos.datasource.concurrent-connection-validation= # Whether to use concurrent connection validation.spring.jta.atomikos.datasource.default-isolation-level= # Default isolation level of connections provided by the pool.spring.jta.atomikos.datasource.login-timeout= # Timeout, in seconds, for establishing a database connection.spring.jta.atomikos.datasource.maintenance-interval=60 # The time, in seconds, between runs of the pool's maintenance thread.spring.jta.atomikos.datasource.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.atomikos.datasource.max-lifetime=0 # The time, in seconds, that a connection can be pooled for before being destroyed. 0 denotes no limit.spring.jta.atomikos.datasource.max-pool-size=1 # The maximum size of the pool.spring.jta.atomikos.datasource.min-pool-size=1 # The minimum size of the pool.spring.jta.atomikos.datasource.reap-timeout=0 # The reap timeout, in seconds, for borrowed connections. 0 denotes no limit.spring.jta.atomikos.datasource.test-query= # SQL query or statement used to validate a connection before returning it.spring.jta.atomikos.datasource.unique-resource-name=dataSource # The unique name used to identify the resource during recovery.spring.jta.atomikos.datasource.xa-data-source-class-name= # Vendor-specific implementation of XAConnectionFactory.spring.jta.atomikos.datasource.xa-properties= # Vendor-specific XA properties.spring.jta.atomikos.properties.allow-sub-transactions=true # Specify whether sub-transactions are allowed.spring.jta.atomikos.properties.checkpoint-interval=500 # Interval between checkpoints, expressed as the number of log writes between two checkpoints.spring.jta.atomikos.properties.default-jta-timeout=10000ms # Default timeout for JTA transactions.spring.jta.atomikos.properties.default-max-wait-time-on-shutdown=9223372036854775807 # How long should normal shutdown (no-force) wait for transactions to complete.spring.jta.atomikos.properties.enable-logging=true # Whether to enable disk logging.spring.jta.atomikos.properties.force-shutdown-on-vm-exit=false # Whether a VM shutdown should trigger forced shutdown of the transaction core.spring.jta.atomikos.properties.log-base-dir= # Directory in which the log files should be stored.spring.jta.atomikos.properties.log-base-name=tmlog # Transactions log file base name.spring.jta.atomikos.properties.max-actives=50 # Maximum number of active transactions.spring.jta.atomikos.properties.max-timeout=300000ms # Maximum timeout that can be allowed for transactions.spring.jta.atomikos.properties.recovery.delay=10000ms # Delay between two recovery scans.spring.jta.atomikos.properties.recovery.forget-orphaned-log-entries-delay=86400000ms # Delay after which recovery can cleanup pending ('orphaned') log entries.spring.jta.atomikos.properties.recovery.max-retries=5 # Number of retry attempts to commit the transaction before throwing an exception.spring.jta.atomikos.properties.recovery.retry-interval=10000ms # Delay between retry attempts.spring.jta.atomikos.properties.serial-jta-transactions=true # Whether sub-transactions should be joined when possible.spring.jta.atomikos.properties.service= # Transaction manager implementation that should be started.spring.jta.atomikos.properties.threaded-two-phase-commit=false # Whether to use different (and concurrent) threads for two-phase commit on the participating resources.spring.jta.atomikos.properties.transaction-manager-unique-name= # The transaction manager's unique name.# BITRONIXspring.jta.bitronix.connectionfactory.acquire-increment=1 # Number of connections to create when growing the pool.spring.jta.bitronix.connectionfactory.acquisition-interval=1 # Time, in seconds, to wait before trying to acquire a connection again after an invalid connection was acquired.spring.jta.bitronix.connectionfactory.acquisition-timeout=30 # Timeout, in seconds, for acquiring connections from the pool.spring.jta.bitronix.connectionfactory.allow-local-transactions=true # Whether the transaction manager should allow mixing XA and non-XA transactions.spring.jta.bitronix.connectionfactory.apply-transaction-timeout=false # Whether the transaction timeout should be set on the XAResource when it is enlisted.spring.jta.bitronix.connectionfactory.automatic-enlisting-enabled=true # Whether resources should be enlisted and delisted automatically.spring.jta.bitronix.connectionfactory.cache-producers-consumers=true # Whether producers and consumers should be cached.spring.jta.bitronix.connectionfactory.class-name= # Underlying implementation class name of the XA resource.spring.jta.bitronix.connectionfactory.defer-connection-release=true # Whether the provider can run many transactions on the same connection and supports transaction interleaving.spring.jta.bitronix.connectionfactory.disabled= # Whether this resource is disabled, meaning it's temporarily forbidden to acquire a connection from its pool.spring.jta.bitronix.connectionfactory.driver-properties= # Properties that should be set on the underlying implementation.spring.jta.bitronix.connectionfactory.failed= # Mark this resource producer as failed.spring.jta.bitronix.connectionfactory.ignore-recovery-failures=false # Whether recovery failures should be ignored.spring.jta.bitronix.connectionfactory.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.bitronix.connectionfactory.max-pool-size=10 # The maximum size of the pool. 0 denotes no limit.spring.jta.bitronix.connectionfactory.min-pool-size=0 # The minimum size of the pool.spring.jta.bitronix.connectionfactory.password= # The password to use to connect to the JMS provider.spring.jta.bitronix.connectionfactory.share-transaction-connections=false # Whether connections in the ACCESSIBLE state can be shared within the context of a transaction.spring.jta.bitronix.connectionfactory.test-connections=true # Whether connections should be tested when acquired from the pool.spring.jta.bitronix.connectionfactory.two-pc-ordering-position=1 # The position that this resource should take during two-phase commit (always first is Integer.MIN_VALUE, always last is Integer.MAX_VALUE).spring.jta.bitronix.connectionfactory.unique-name=jmsConnectionFactory # The unique name used to identify the resource during recovery.spring.jta.bitronix.connectionfactory.use-tm-join=true # Whether TMJOIN should be used when starting XAResources.spring.jta.bitronix.connectionfactory.user= # The user to use to connect to the JMS provider.spring.jta.bitronix.datasource.acquire-increment=1 # Number of connections to create when growing the pool.spring.jta.bitronix.datasource.acquisition-interval=1 # Time, in seconds, to wait before trying to acquire a connection again after an invalid connection was acquired.spring.jta.bitronix.datasource.acquisition-timeout=30 # Timeout, in seconds, for acquiring connections from the pool.spring.jta.bitronix.datasource.allow-local-transactions=true # Whether the transaction manager should allow mixing XA and non-XA transactions.spring.jta.bitronix.datasource.apply-transaction-timeout=false # Whether the transaction timeout should be set on the XAResource when it is enlisted.spring.jta.bitronix.datasource.automatic-enlisting-enabled=true # Whether resources should be enlisted and delisted automatically.spring.jta.bitronix.datasource.class-name= # Underlying implementation class name of the XA resource.spring.jta.bitronix.datasource.cursor-holdability= # The default cursor holdability for connections.spring.jta.bitronix.datasource.defer-connection-release=true # Whether the database can run many transactions on the same connection and supports transaction interleaving.spring.jta.bitronix.datasource.disabled= # Whether this resource is disabled, meaning it's temporarily forbidden to acquire a connection from its pool.spring.jta.bitronix.datasource.driver-properties= # Properties that should be set on the underlying implementation.spring.jta.bitronix.datasource.enable-jdbc4-connection-test= # Whether Connection.isValid() is called when acquiring a connection from the pool.spring.jta.bitronix.datasource.failed= # Mark this resource producer as failed.spring.jta.bitronix.datasource.ignore-recovery-failures=false # Whether recovery failures should be ignored.spring.jta.bitronix.datasource.isolation-level= # The default isolation level for connections.spring.jta.bitronix.datasource.local-auto-commit= # The default auto-commit mode for local transactions.spring.jta.bitronix.datasource.login-timeout= # Timeout, in seconds, for establishing a database connection.spring.jta.bitronix.datasource.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.bitronix.datasource.max-pool-size=10 # The maximum size of the pool. 0 denotes no limit.spring.jta.bitronix.datasource.min-pool-size=0 # The minimum size of the pool.spring.jta.bitronix.datasource.prepared-statement-cache-size=0 # The target size of the prepared statement cache. 0 disables the cache.spring.jta.bitronix.datasource.share-transaction-connections=false # Whether connections in the ACCESSIBLE state can be shared within the context of a transaction.spring.jta.bitronix.datasource.test-query= # SQL query or statement used to validate a connection before returning it.spring.jta.bitronix.datasource.two-pc-ordering-position=1 # The position that this resource should take during two-phase commit (always first is Integer.MIN_VALUE, and always last is Integer.MAX_VALUE).spring.jta.bitronix.datasource.unique-name=dataSource # The unique name used to identify the resource during recovery.spring.jta.bitronix.datasource.use-tm-join=true # Whether TMJOIN should be used when starting XAResources.spring.jta.bitronix.properties.allow-multiple-lrc=false # Whether to allow multiple LRC resources to be enlisted into the same transaction.spring.jta.bitronix.properties.asynchronous2-pc=false # Whether to enable asynchronously execution of two phase commit.spring.jta.bitronix.properties.background-recovery-interval-seconds=60 # Interval in seconds at which to run the recovery process in the background.spring.jta.bitronix.properties.current-node-only-recovery=true # Whether to recover only the current node.spring.jta.bitronix.properties.debug-zero-resource-transaction=false # Whether to log the creation and commit call stacks of transactions executed without a single enlisted resource.spring.jta.bitronix.properties.default-transaction-timeout=60 # Default transaction timeout, in seconds.spring.jta.bitronix.properties.disable-jmx=false # Whether to enable JMX support.spring.jta.bitronix.properties.exception-analyzer= # Set the fully qualified name of the exception analyzer implementation to use.spring.jta.bitronix.properties.filter-log-status=false # Whether to enable filtering of logs so that only mandatory logs are written.spring.jta.bitronix.properties.force-batching-enabled=true # Whether disk forces are batched.spring.jta.bitronix.properties.forced-write-enabled=true # Whether logs are forced to disk.spring.jta.bitronix.properties.graceful-shutdown-interval=60 # Maximum amount of seconds the TM waits for transactions to get done before aborting them at shutdown time.spring.jta.bitronix.properties.jndi-transaction-synchronization-registry-name= # JNDI name of the TransactionSynchronizationRegistry.spring.jta.bitronix.properties.jndi-user-transaction-name= # JNDI name of the UserTransaction.spring.jta.bitronix.properties.journal=disk # Name of the journal. Can be 'disk', 'null', or a class name.spring.jta.bitronix.properties.log-part1-filename=btm1.tlog # Name of the first fragment of the journal.spring.jta.bitronix.properties.log-part2-filename=btm2.tlog # Name of the second fragment of the journal.spring.jta.bitronix.properties.max-log-size-in-mb=2 # Maximum size in megabytes of the journal fragments.spring.jta.bitronix.properties.resource-configuration-filename= # ResourceLoader configuration file name.spring.jta.bitronix.properties.server-id= # ASCII ID that must uniquely identify this TM instance. Defaults to the machine's IP address.spring.jta.bitronix.properties.skip-corrupted-logs=false # Skip corrupted transactions log entries.spring.jta.bitronix.properties.warn-about-zero-resource-transaction=true # Whether to log a warning for transactions executed without a single enlisted resource.# NARAYANA (NarayanaProperties)spring.jta.narayana.default-timeout=60s # Transaction timeout. If a duration suffix is not specified, seconds will be used.spring.jta.narayana.expiry-scanners=com.arjuna.ats.internal.arjuna.recovery.ExpiredTransactionStatusManagerScanner # Comma-separated list of expiry scanners.spring.jta.narayana.log-dir= # Transaction object store directory.spring.jta.narayana.one-phase-commit=true # Whether to enable one phase commit optimization.spring.jta.narayana.periodic-recovery-period=120s # Interval in which periodic recovery scans are performed. If a duration suffix is not specified, seconds will be used.spring.jta.narayana.recovery-backoff-period=10s # Back off period between first and second phases of the recovery scan. If a duration suffix is not specified, seconds will be used.spring.jta.narayana.recovery-db-pass= # Database password to be used by the recovery manager.spring.jta.narayana.recovery-db-user= # Database username to be used by the recovery manager.spring.jta.narayana.recovery-jms-pass= # JMS password to be used by the recovery manager.spring.jta.narayana.recovery-jms-user= # JMS username to be used by the recovery manager.spring.jta.narayana.recovery-modules= # Comma-separated list of recovery modules.spring.jta.narayana.transaction-manager-id=1 # Unique transaction manager id.spring.jta.narayana.xa-resource-orphan-filters= # Comma-separated list of orphan filters.# EMBEDDED MONGODB (EmbeddedMongoProperties)spring.mongodb.embedded.features=sync_delay # Comma-separated list of features to enable.spring.mongodb.embedded.storage.database-dir= # Directory used for data storage.spring.mongodb.embedded.storage.oplog-size= # Maximum size of the oplog, in megabytes.spring.mongodb.embedded.storage.repl-set-name= # Name of the replica set.spring.mongodb.embedded.version=3.2.2 # Version of Mongo to use.# REDIS (RedisProperties)spring.redis.cluster.max-redirects= # Maximum number of redirects to follow when executing commands across the cluster.spring.redis.cluster.nodes= # Comma-separated list of "host:port" pairs to bootstrap from.spring.redis.database=0 # Database index used by the connection factory.spring.redis.url= # Connection URL. Overrides host, port, and password. User is ignored. Example: redis://user:password@example.com:6379spring.redis.host=localhost # Redis server host.spring.redis.jedis.pool.max-active=8 # Maximum number of connections that can be allocated by the pool at a given time. Use a negative value for no limit.spring.redis.jedis.pool.max-idle=8 # Maximum number of "idle" connections in the pool. Use a negative value to indicate an unlimited number of idle connections.spring.redis.jedis.pool.max-wait=-1ms # Maximum amount of time a connection allocation should block before throwing an exception when the pool is exhausted. Use a negative value to block indefinitely.spring.redis.jedis.pool.min-idle=0 # Target for the minimum number of idle connections to maintain in the pool. This setting only has an effect if it is positive.spring.redis.lettuce.pool.max-active=8 # Maximum number of connections that can be allocated by the pool at a given time. Use a negative value for no limit.spring.redis.lettuce.pool.max-idle=8 # Maximum number of "idle" connections in the pool. Use a negative value to indicate an unlimited number of idle connections.spring.redis.lettuce.pool.max-wait=-1ms # Maximum amount of time a connection allocation should block before throwing an exception when the pool is exhausted. Use a negative value to block indefinitely.spring.redis.lettuce.pool.min-idle=0 # Target for the minimum number of idle connections to maintain in the pool. This setting only has an effect if it is positive.spring.redis.lettuce.shutdown-timeout=100ms # Shutdown timeout.spring.redis.password= # Login password of the redis server.spring.redis.port=6379 # Redis server port.spring.redis.sentinel.master= # Name of the Redis server.spring.redis.sentinel.nodes= # Comma-separated list of "host:port" pairs.spring.redis.ssl=false # Whether to enable SSL support.spring.redis.timeout= # Connection timeout.# TRANSACTION (TransactionProperties)spring.transaction.default-timeout= # Default transaction timeout. If a duration suffix is not specified, seconds will be used.spring.transaction.rollback-on-commit-failure= # Whether to roll back on commit failures.# ----------------------------------------# INTEGRATION PROPERTIES# ----------------------------------------# ACTIVEMQ (ActiveMQProperties)spring.activemq.broker-url= # URL of the ActiveMQ broker. Auto-generated by default.spring.activemq.close-timeout=15s # Time to wait before considering a close complete.spring.activemq.in-memory=true # Whether the default broker URL should be in memory. Ignored if an explicit broker has been specified.spring.activemq.non-blocking-redelivery=false # Whether to stop message delivery before re-delivering messages from a rolled back transaction. This implies that message order is not preserved when this is enabled.spring.activemq.password= # Login password of the broker.spring.activemq.send-timeout=0ms # Time to wait on message sends for a response. Set it to 0 to wait forever.spring.activemq.user= # Login user of the broker.spring.activemq.packages.trust-all= # Whether to trust all packages.spring.activemq.packages.trusted= # Comma-separated list of specific packages to trust (when not trusting all packages).spring.activemq.pool.block-if-full=true # Whether to block when a connection is requested and the pool is full. Set it to false to throw a "JMSException" instead.spring.activemq.pool.block-if-full-timeout=-1ms # Blocking period before throwing an exception if the pool is still full.spring.activemq.pool.create-connection-on-startup=true # Whether to create a connection on startup. Can be used to warm up the pool on startup.spring.activemq.pool.enabled=false # Whether a PooledConnectionFactory should be created, instead of a regular ConnectionFactory.spring.activemq.pool.expiry-timeout=0ms # Connection expiration timeout.spring.activemq.pool.idle-timeout=30s # Connection idle timeout.spring.activemq.pool.max-connections=1 # Maximum number of pooled connections.spring.activemq.pool.maximum-active-session-per-connection=500 # Maximum number of active sessions per connection.spring.activemq.pool.reconnect-on-exception=true # Reset the connection when a "JMSException" occurs.spring.activemq.pool.time-between-expiration-check=-1ms # Time to sleep between runs of the idle connection eviction thread. When negative, no idle connection eviction thread runs.spring.activemq.pool.use-anonymous-producers=true # Whether to use only one anonymous "MessageProducer" instance. Set it to false to create one "MessageProducer" every time one is required.# ARTEMIS (ArtemisProperties)spring.artemis.embedded.cluster-password= # Cluster password. Randomly generated on startup by default.spring.artemis.embedded.data-directory= # Journal file directory. Not necessary if persistence is turned off.spring.artemis.embedded.enabled=true # Whether to enable embedded mode if the Artemis server APIs are available.spring.artemis.embedded.persistent=false # Whether to enable persistent store.spring.artemis.embedded.queues= # Comma-separated list of queues to create on startup.spring.artemis.embedded.server-id= # Server ID. By default, an auto-incremented counter is used.spring.artemis.embedded.topics= # Comma-separated list of topics to create on startup.spring.artemis.host=localhost # Artemis broker host.spring.artemis.mode= # Artemis deployment mode, auto-detected by default.spring.artemis.password= # Login password of the broker.spring.artemis.port=61616 # Artemis broker port.spring.artemis.user= # Login user of the broker.# SPRING BATCH (BatchProperties)spring.batch.initialize-schema=embedded # Database schema initialization mode.spring.batch.job.enabled=true # Execute all Spring Batch jobs in the context on startup.spring.batch.job.names= # Comma-separated list of job names to execute on startup (for instance, `job1,job2`). By default, all Jobs found in the context are executed.spring.batch.schema=classpath:org/springframework/batch/core/schema-@@platform@@.sql # Path to the SQL file to use to initialize the database schema.spring.batch.table-prefix= # Table prefix for all the batch meta-data tables.# SPRING INTEGRATION (IntegrationProperties)spring.integration.jdbc.initialize-schema=embedded # Database schema initialization mode.spring.integration.jdbc.schema=classpath:org/springframework/integration/jdbc/schema-@@platform@@.sql # Path to the SQL file to use to initialize the database schema.# JMS (JmsProperties)spring.jms.jndi-name= # Connection factory JNDI name. When set, takes precedence to others connection factory auto-configurations.spring.jms.listener.acknowledge-mode= # Acknowledge mode of the container. By default, the listener is transacted with automatic acknowledgment.spring.jms.listener.auto-startup=true # Start the container automatically on startup.spring.jms.listener.concurrency= # Minimum number of concurrent consumers.spring.jms.listener.max-concurrency= # Maximum number of concurrent consumers.spring.jms.pub-sub-domain=false # Whether the default destination type is topic.spring.jms.template.default-destination= # Default destination to use on send and receive operations that do not have a destination parameter.spring.jms.template.delivery-delay= # Delivery delay to use for send calls.spring.jms.template.delivery-mode= # Delivery mode. Enables QoS (Quality of Service) when set.spring.jms.template.priority= # Priority of a message when sending. Enables QoS (Quality of Service) when set.spring.jms.template.qos-enabled= # Whether to enable explicit QoS (Quality of Service) when sending a message.spring.jms.template.receive-timeout= # Timeout to use for receive calls.spring.jms.template.time-to-live= # Time-to-live of a message when sending. Enables QoS (Quality of Service) when set.# APACHE KAFKA (KafkaProperties)spring.kafka.admin.client-id= # ID to pass to the server when making requests. Used for server-side logging.spring.kafka.admin.fail-fast=false # Whether to fail fast if the broker is not available on startup.spring.kafka.admin.properties.*= # Additional admin-specific properties used to configure the client.spring.kafka.admin.ssl.key-password= # Password of the private key in the key store file.spring.kafka.admin.ssl.key-store-location= # Location of the key store file.spring.kafka.admin.ssl.key-store-password= # Store password for the key store file.spring.kafka.admin.ssl.key-store-type= # Type of the key store.spring.kafka.admin.ssl.protocol= # SSL protocol to use.spring.kafka.admin.ssl.trust-store-location= # Location of the trust store file.spring.kafka.admin.ssl.trust-store-password= # Store password for the trust store file.spring.kafka.admin.ssl.trust-store-type= # Type of the trust store.spring.kafka.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.spring.kafka.client-id= # ID to pass to the server when making requests. Used for server-side logging.spring.kafka.consumer.auto-commit-interval= # Frequency with which the consumer offsets are auto-committed to Kafka if 'enable.auto.commit' is set to true.spring.kafka.consumer.auto-offset-reset= # What to do when there is no initial offset in Kafka or if the current offset no longer exists on the server.spring.kafka.consumer.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.spring.kafka.consumer.client-id= # ID to pass to the server when making requests. Used for server-side logging.spring.kafka.consumer.enable-auto-commit= # Whether the consumer's offset is periodically committed in the background.spring.kafka.consumer.fetch-max-wait= # Maximum amount of time the server blocks before answering the fetch request if there isn't sufficient data to immediately satisfy the requirement given by "fetch.min.bytes".spring.kafka.consumer.fetch-min-size= # Minimum amount of data, in bytes, the server should return for a fetch request.spring.kafka.consumer.group-id= # Unique string that identifies the consumer group to which this consumer belongs.spring.kafka.consumer.heartbeat-interval= # Expected time between heartbeats to the consumer coordinator.spring.kafka.consumer.key-deserializer= # Deserializer class for keys.spring.kafka.consumer.max-poll-records= # Maximum number of records returned in a single call to poll().spring.kafka.consumer.properties.*= # Additional consumer-specific properties used to configure the client.spring.kafka.consumer.ssl.key-password= # Password of the private key in the key store file.spring.kafka.consumer.ssl.key-store-location= # Location of the key store file.spring.kafka.consumer.ssl.key-store-password= # Store password for the key store file.spring.kafka.consumer.ssl.key-store-type= # Type of the key store.spring.kafka.consumer.ssl.protocol= # SSL protocol to use.spring.kafka.consumer.ssl.trust-store-location= # Location of the trust store file.spring.kafka.consumer.ssl.trust-store-password= # Store password for the trust store file.spring.kafka.consumer.ssl.trust-store-type= # Type of the trust store.spring.kafka.consumer.value-deserializer= # Deserializer class for values.spring.kafka.jaas.control-flag=required # Control flag for login configuration.spring.kafka.jaas.enabled=false # Whether to enable JAAS configuration.spring.kafka.jaas.login-module=com.sun.security.auth.module.Krb5LoginModule # Login module.spring.kafka.jaas.options= # Additional JAAS options.spring.kafka.listener.ack-count= # Number of records between offset commits when ackMode is "COUNT" or "COUNT_TIME".spring.kafka.listener.ack-mode= # Listener AckMode. See the spring-kafka documentation.spring.kafka.listener.ack-time= # Time between offset commits when ackMode is "TIME" or "COUNT_TIME".spring.kafka.listener.client-id= # Prefix for the listener's consumer client.id property.spring.kafka.listener.concurrency= # Number of threads to run in the listener containers.spring.kafka.listener.idle-event-interval= # Time between publishing idle consumer events (no data received).spring.kafka.listener.log-container-config= # Whether to log the container configuration during initialization (INFO level).spring.kafka.listener.monitor-interval= # Time between checks for non-responsive consumers. If a duration suffix is not specified, seconds will be used.spring.kafka.listener.no-poll-threshold= # Multiplier applied to "pollTimeout" to determine if a consumer is non-responsive.spring.kafka.listener.poll-timeout= # Timeout to use when polling the consumer.spring.kafka.listener.type=single # Listener type.spring.kafka.producer.acks= # Number of acknowledgments the producer requires the leader to have received before considering a request complete.spring.kafka.producer.batch-size= # Default batch size in bytes.spring.kafka.producer.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.spring.kafka.producer.buffer-memory= # Total bytes of memory the producer can use to buffer records waiting to be sent to the server.spring.kafka.producer.client-id= # ID to pass to the server when making requests. Used for server-side logging.spring.kafka.producer.compression-type= # Compression type for all data generated by the producer.spring.kafka.producer.key-serializer= # Serializer class for keys.spring.kafka.producer.properties.*= # Additional producer-specific properties used to configure the client.spring.kafka.producer.retries= # When greater than zero, enables retrying of failed sends.spring.kafka.producer.ssl.key-password= # Password of the private key in the key store file.spring.kafka.producer.ssl.key-store-location= # Location of the key store file.spring.kafka.producer.ssl.key-store-password= # Store password for the key store file.spring.kafka.producer.ssl.key-store-type= # Type of the key store.spring.kafka.producer.ssl.protocol= # SSL protocol to use.spring.kafka.producer.ssl.trust-store-location= # Location of the trust store file.spring.kafka.producer.ssl.trust-store-password= # Store password for the trust store file.spring.kafka.producer.ssl.trust-store-type= # Type of the trust store.spring.kafka.producer.transaction-id-prefix= # When non empty, enables transaction support for producer.spring.kafka.producer.value-serializer= # Serializer class for values.spring.kafka.properties.*= # Additional properties, common to producers and consumers, used to configure the client.spring.kafka.ssl.key-password= # Password of the private key in the key store file.spring.kafka.ssl.key-store-location= # Location of the key store file.spring.kafka.ssl.key-store-password= # Store password for the key store file.spring.kafka.ssl.key-store-type= # Type of the key store.spring.kafka.ssl.protocol= # SSL protocol to use.spring.kafka.ssl.trust-store-location= # Location of the trust store file.spring.kafka.ssl.trust-store-password= # Store password for the trust store file.spring.kafka.ssl.trust-store-type= # Type of the trust store.spring.kafka.template.default-topic= # Default topic to which messages are sent.# RABBIT (RabbitProperties)spring.rabbitmq.addresses= # Comma-separated list of addresses to which the client should connect.spring.rabbitmq.cache.channel.checkout-timeout= # Duration to wait to obtain a channel if the cache size has been reached.spring.rabbitmq.cache.channel.size= # Number of channels to retain in the cache.spring.rabbitmq.cache.connection.mode=channel # Connection factory cache mode.spring.rabbitmq.cache.connection.size= # Number of connections to cache.spring.rabbitmq.connection-timeout= # Connection timeout. Set it to zero to wait forever.spring.rabbitmq.dynamic=true # Whether to create an AmqpAdmin bean.spring.rabbitmq.host=localhost # RabbitMQ host.spring.rabbitmq.listener.direct.acknowledge-mode= # Acknowledge mode of container.spring.rabbitmq.listener.direct.auto-startup=true # Whether to start the container automatically on startup.spring.rabbitmq.listener.direct.consumers-per-queue= # Number of consumers per queue.spring.rabbitmq.listener.direct.default-requeue-rejected= # Whether rejected deliveries are re-queued by default.spring.rabbitmq.listener.direct.idle-event-interval= # How often idle container events should be published.spring.rabbitmq.listener.direct.prefetch= # Number of messages to be handled in a single request. It should be greater than or equal to the transaction size (if used).spring.rabbitmq.listener.direct.retry.enabled=false # Whether publishing retries are enabled.spring.rabbitmq.listener.direct.retry.initial-interval=1000ms # Duration between the first and second attempt to deliver a message.spring.rabbitmq.listener.direct.retry.max-attempts=3 # Maximum number of attempts to deliver a message.spring.rabbitmq.listener.direct.retry.max-interval=10000ms # Maximum duration between attempts.spring.rabbitmq.listener.direct.retry.multiplier=1 # Multiplier to apply to the previous retry interval.spring.rabbitmq.listener.direct.retry.stateless=true # Whether retries are stateless or stateful.spring.rabbitmq.listener.simple.acknowledge-mode= # Acknowledge mode of container.spring.rabbitmq.listener.simple.auto-startup=true # Whether to start the container automatically on startup.spring.rabbitmq.listener.simple.concurrency= # Minimum number of listener invoker threads.spring.rabbitmq.listener.simple.default-requeue-rejected= # Whether rejected deliveries are re-queued by default.spring.rabbitmq.listener.simple.idle-event-interval= # How often idle container events should be published.spring.rabbitmq.listener.simple.max-concurrency= # Maximum number of listener invoker threads.spring.rabbitmq.listener.simple.prefetch= # Number of messages to be handled in a single request. It should be greater than or equal to the transaction size (if used).spring.rabbitmq.listener.simple.retry.enabled=false # Whether publishing retries are enabled.spring.rabbitmq.listener.simple.retry.initial-interval=1000ms # Duration between the first and second attempt to deliver a message.spring.rabbitmq.listener.simple.retry.max-attempts=3 # Maximum number of attempts to deliver a message.spring.rabbitmq.listener.simple.retry.max-interval=10000ms # Maximum duration between attempts.spring.rabbitmq.listener.simple.retry.multiplier=1 # Multiplier to apply to the previous retry interval.spring.rabbitmq.listener.simple.retry.stateless=true # Whether retries are stateless or stateful.spring.rabbitmq.listener.simple.transaction-size= # Number of messages to be processed in a transaction. That is, the number of messages between acks. For best results, it should be less than or equal to the prefetch count.spring.rabbitmq.listener.type=simple # Listener container type.spring.rabbitmq.password=guest # Login to authenticate against the broker.spring.rabbitmq.port=5672 # RabbitMQ port.spring.rabbitmq.publisher-confirms=false # Whether to enable publisher confirms.spring.rabbitmq.publisher-returns=false # Whether to enable publisher returns.spring.rabbitmq.requested-heartbeat= # Requested heartbeat timeout; zero for none. If a duration suffix is not specified, seconds will be used.spring.rabbitmq.ssl.enabled=false # Whether to enable SSL support.spring.rabbitmq.ssl.key-store= # Path to the key store that holds the SSL certificate.spring.rabbitmq.ssl.key-store-password= # Password used to access the key store.spring.rabbitmq.ssl.key-store-type=PKCS12 # Key store type.spring.rabbitmq.ssl.trust-store= # Trust store that holds SSL certificates.spring.rabbitmq.ssl.trust-store-password= # Password used to access the trust store.spring.rabbitmq.ssl.trust-store-type=JKS # Trust store type.spring.rabbitmq.ssl.algorithm= # SSL algorithm to use. By default, configured by the Rabbit client library.spring.rabbitmq.template.exchange= # Name of the default exchange to use for send operations.spring.rabbitmq.template.mandatory= # Whether to enable mandatory messages.spring.rabbitmq.template.receive-timeout= # Timeout for `receive()` operations.spring.rabbitmq.template.reply-timeout= # Timeout for `sendAndReceive()` operations.spring.rabbitmq.template.retry.enabled=false # Whether publishing retries are enabled.spring.rabbitmq.template.retry.initial-interval=1000ms # Duration between the first and second attempt to deliver a message.spring.rabbitmq.template.retry.max-attempts=3 # Maximum number of attempts to deliver a message.spring.rabbitmq.template.retry.max-interval=10000ms # Maximum duration between attempts.spring.rabbitmq.template.retry.multiplier=1 # Multiplier to apply to the previous retry interval.spring.rabbitmq.template.routing-key= # Value of a default routing key to use for send operations.spring.rabbitmq.username=guest # Login user to authenticate to the broker.spring.rabbitmq.virtual-host= # Virtual host to use when connecting to the broker.# ----------------------------------------# ACTUATOR PROPERTIES# ----------------------------------------# MANAGEMENT HTTP SERVER (ManagementServerProperties)management.server.add-application-context-header=false # Add the "X-Application-Context" HTTP header in each response.management.server.address= # Network address to which the management endpoints should bind. Requires a custom management.server.port.management.server.port= # Management endpoint HTTP port (uses the same port as the application by default). Configure a different port to use management-specific SSL.management.server.servlet.context-path= # Management endpoint context-path (for instance, `/management`). Requires a custom management.server.port.management.server.ssl.ciphers= # Supported SSL ciphers. Requires a custom management.port.management.server.ssl.client-auth= # Whether client authentication is wanted ("want") or needed ("need"). Requires a trust store. Requires a custom management.server.port.management.server.ssl.enabled= # Whether to enable SSL support. Requires a custom management.server.port.management.server.ssl.enabled-protocols= # Enabled SSL protocols. Requires a custom management.server.port.management.server.ssl.key-alias= # Alias that identifies the key in the key store. Requires a custom management.server.port.management.server.ssl.key-password= # Password used to access the key in the key store. Requires a custom management.server.port.management.server.ssl.key-store= # Path to the key store that holds the SSL certificate (typically a jks file). Requires a custom management.server.port.management.server.ssl.key-store-password= # Password used to access the key store. Requires a custom management.server.port.management.server.ssl.key-store-provider= # Provider for the key store. Requires a custom management.server.port.management.server.ssl.key-store-type= # Type of the key store. Requires a custom management.server.port.management.server.ssl.protocol=TLS # SSL protocol to use. Requires a custom management.server.port.management.server.ssl.trust-store= # Trust store that holds SSL certificates. Requires a custom management.server.port.management.server.ssl.trust-store-password= # Password used to access the trust store. Requires a custom management.server.port.management.server.ssl.trust-store-provider= # Provider for the trust store. Requires a custom management.server.port.management.server.ssl.trust-store-type= # Type of the trust store. Requires a custom management.server.port.# CLOUDFOUNDRYmanagement.cloudfoundry.enabled=true # Whether to enable extended Cloud Foundry actuator endpoints.management.cloudfoundry.skip-ssl-validation=false # Whether to skip SSL verification for Cloud Foundry actuator endpoint security calls.# ENDPOINTS GENERAL CONFIGURATIONmanagement.endpoints.enabled-by-default= # Whether to enable or disable all endpoints by default.# ENDPOINTS JMX CONFIGURATION (JmxEndpointProperties)management.endpoints.jmx.domain=org.springframework.boot # Endpoints JMX domain name. Fallback to 'spring.jmx.default-domain' if set.management.endpoints.jmx.exposure.include=* # Endpoint IDs that should be included or '*' for all.management.endpoints.jmx.exposure.exclude= # Endpoint IDs that should be excluded.management.endpoints.jmx.static-names= # Additional static properties to append to all ObjectNames of MBeans representing Endpoints.management.endpoints.jmx.unique-names=false # Whether to ensure that ObjectNames are modified in case of conflict.# ENDPOINTS WEB CONFIGURATION (WebEndpointProperties)management.endpoints.web.exposure.include=health,info # Endpoint IDs that should be included or '*' for all.management.endpoints.web.exposure.exclude= # Endpoint IDs that should be excluded.management.endpoints.web.base-path=/actuator # Base path for Web endpoints. Relative to server.servlet.context-path or management.server.servlet.context-path if management.server.port is configured.management.endpoints.web.path-mapping= # Mapping between endpoint IDs and the path that should expose them.# ENDPOINTS CORS CONFIGURATION (CorsEndpointProperties)management.endpoints.web.cors.allow-credentials= # Whether credentials are supported. When not set, credentials are not supported.management.endpoints.web.cors.allowed-headers= # Comma-separated list of headers to allow in a request. '*' allows all headers.management.endpoints.web.cors.allowed-methods= # Comma-separated list of methods to allow. '*' allows all methods. When not set, defaults to GET.management.endpoints.web.cors.allowed-origins= # Comma-separated list of origins to allow. '*' allows all origins. When not set, CORS support is disabled.management.endpoints.web.cors.exposed-headers= # Comma-separated list of headers to include in a response.management.endpoints.web.cors.max-age=1800s # How long the response from a pre-flight request can be cached by clients. If a duration suffix is not specified, seconds will be used.# AUDIT EVENTS ENDPOINT (AuditEventsEndpoint)management.endpoint.auditevents.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.auditevents.enabled=true # Whether to enable the auditevents endpoint.# BEANS ENDPOINT (BeansEndpoint)management.endpoint.beans.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.beans.enabled=true # Whether to enable the beans endpoint.# CACHES ENDPOINT (CachesEndpoint)management.endpoint.caches.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.caches.enabled=true # Whether to enable the caches endpoint.# CONDITIONS REPORT ENDPOINT (ConditionsReportEndpoint)management.endpoint.conditions.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.conditions.enabled=true # Whether to enable the conditions endpoint.# CONFIGURATION PROPERTIES REPORT ENDPOINT (ConfigurationPropertiesReportEndpoint, ConfigurationPropertiesReportEndpointProperties)management.endpoint.configprops.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.configprops.enabled=true # Whether to enable the configprops endpoint.management.endpoint.configprops.keys-to-sanitize=password,secret,key,token,.*credentials.*,vcap_services,sun.java.command # Keys that should be sanitized. Keys can be simple strings that the property ends with or regular expressions.# ENVIRONMENT ENDPOINT (EnvironmentEndpoint, EnvironmentEndpointProperties)management.endpoint.env.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.env.enabled=true # Whether to enable the env endpoint.management.endpoint.env.keys-to-sanitize=password,secret,key,token,.*credentials.*,vcap_services,sun.java.command # Keys that should be sanitized. Keys can be simple strings that the property ends with or regular expressions.# FLYWAY ENDPOINT (FlywayEndpoint)management.endpoint.flyway.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.flyway.enabled=true # Whether to enable the flyway endpoint.# HEALTH ENDPOINT (HealthEndpoint, HealthEndpointProperties)management.endpoint.health.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.health.enabled=true # Whether to enable the health endpoint.management.endpoint.health.roles= # Roles used to determine whether or not a user is authorized to be shown details. When empty, all authenticated users are authorized.management.endpoint.health.show-details=never # When to show full health details.# HEAP DUMP ENDPOINT (HeapDumpWebEndpoint)management.endpoint.heapdump.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.heapdump.enabled=true # Whether to enable the heapdump endpoint.# HTTP TRACE ENDPOINT (HttpTraceEndpoint)management.endpoint.httptrace.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.httptrace.enabled=true # Whether to enable the httptrace endpoint.# INFO ENDPOINT (InfoEndpoint)info= # Arbitrary properties to add to the info endpoint.management.endpoint.info.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.info.enabled=true # Whether to enable the info endpoint.# INTEGRATION GRAPH ENDPOINT (IntegrationGraphEndpoint)management.endpoint.integrationgraph.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.integrationgraph.enabled=true # Whether to enable the integrationgraph endpoint.# JOLOKIA ENDPOINT (JolokiaProperties)management.endpoint.jolokia.config.*= # Jolokia settings. Refer to the documentation of Jolokia for more details.management.endpoint.jolokia.enabled=true # Whether to enable the jolokia endpoint.# LIQUIBASE ENDPOINT (LiquibaseEndpoint)management.endpoint.liquibase.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.liquibase.enabled=true # Whether to enable the liquibase endpoint.# LOG FILE ENDPOINT (LogFileWebEndpoint, LogFileWebEndpointProperties)management.endpoint.logfile.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.logfile.enabled=true # Whether to enable the logfile endpoint.management.endpoint.logfile.external-file= # External Logfile to be accessed. Can be used if the logfile is written by output redirect and not by the logging system itself.# LOGGERS ENDPOINT (LoggersEndpoint)management.endpoint.loggers.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.loggers.enabled=true # Whether to enable the loggers endpoint.# REQUEST MAPPING ENDPOINT (MappingsEndpoint)management.endpoint.mappings.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.mappings.enabled=true # Whether to enable the mappings endpoint.# METRICS ENDPOINT (MetricsEndpoint)management.endpoint.metrics.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.metrics.enabled=true # Whether to enable the metrics endpoint.# PROMETHEUS ENDPOINT (PrometheusScrapeEndpoint)management.endpoint.prometheus.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.prometheus.enabled=true # Whether to enable the prometheus endpoint.# SCHEDULED TASKS ENDPOINT (ScheduledTasksEndpoint)management.endpoint.scheduledtasks.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.scheduledtasks.enabled=true # Whether to enable the scheduledtasks endpoint.# SESSIONS ENDPOINT (SessionsEndpoint)management.endpoint.sessions.enabled=true # Whether to enable the sessions endpoint.# SHUTDOWN ENDPOINT (ShutdownEndpoint)management.endpoint.shutdown.enabled=false # Whether to enable the shutdown endpoint.# THREAD DUMP ENDPOINT (ThreadDumpEndpoint)management.endpoint.threaddump.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.threaddump.enabled=true # Whether to enable the threaddump endpoint.# HEALTH INDICATORSmanagement.health.db.enabled=true # Whether to enable database health check.management.health.cassandra.enabled=true # Whether to enable Cassandra health check.management.health.couchbase.enabled=true # Whether to enable Couchbase health check.management.health.defaults.enabled=true # Whether to enable default health indicators.management.health.diskspace.enabled=true # Whether to enable disk space health check.management.health.diskspace.path= # Path used to compute the available disk space.management.health.diskspace.threshold=0 # Minimum disk space, in bytes, that should be available.management.health.elasticsearch.enabled=true # Whether to enable Elasticsearch health check.management.health.elasticsearch.indices= # Comma-separated index names.management.health.elasticsearch.response-timeout=100ms # Time to wait for a response from the cluster.management.health.influxdb.enabled=true # Whether to enable InfluxDB health check.management.health.jms.enabled=true # Whether to enable JMS health check.management.health.ldap.enabled=true # Whether to enable LDAP health check.management.health.mail.enabled=true # Whether to enable Mail health check.management.health.mongo.enabled=true # Whether to enable MongoDB health check.management.health.neo4j.enabled=true # Whether to enable Neo4j health check.management.health.rabbit.enabled=true # Whether to enable RabbitMQ health check.management.health.redis.enabled=true # Whether to enable Redis health check.management.health.solr.enabled=true # Whether to enable Solr health check.management.health.status.http-mapping= # Mapping of health statuses to HTTP status codes. By default, registered health statuses map to sensible defaults (for example, UP maps to 200).management.health.status.order=DOWN,OUT_OF_SERVICE,UP,UNKNOWN # Comma-separated list of health statuses in order of severity.# HTTP TRACING (HttpTraceProperties)management.trace.http.enabled=true # Whether to enable HTTP request-response tracing.management.trace.http.include=request-headers,response-headers,cookies,errors # Items to be included in the trace.# INFO CONTRIBUTORS (InfoContributorProperties)management.info.build.enabled=true # Whether to enable build info.management.info.defaults.enabled=true # Whether to enable default info contributors.management.info.env.enabled=true # Whether to enable environment info.management.info.git.enabled=true # Whether to enable git info.management.info.git.mode=simple # Mode to use to expose git information.# METRICSmanagement.metrics.binders.files.enabled=true # Whether to enable files metrics.management.metrics.binders.integration.enabled=true # Whether to enable Spring Integration metrics.management.metrics.binders.jvm.enabled=true # Whether to enable JVM metrics.management.metrics.binders.logback.enabled=true # Whether to enable Logback metrics.management.metrics.binders.processor.enabled=true # Whether to enable processor metrics.management.metrics.binders.uptime.enabled=true # Whether to enable uptime metrics.management.metrics.distribution.percentiles-histogram.*= # Whether meter IDs starting-with the specified name should be publish percentile histograms.management.metrics.distribution.percentiles.*= # Specific computed non-aggregable percentiles to ship to the backend for meter IDs starting-with the specified name.management.metrics.distribution.sla.*= # Specific SLA boundaries for meter IDs starting-with the specified name. The longest match wins, the key `all` can also be used to configure all meters.management.metrics.enable.*= # Whether meter IDs starting-with the specified name should be enabled. The longest match wins, the key `all` can also be used to configure all meters.management.metrics.export.atlas.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.atlas.config-refresh-frequency=10s # Frequency for refreshing config settings from the LWC service.management.metrics.export.atlas.config-time-to-live=150s # Time to live for subscriptions from the LWC service.management.metrics.export.atlas.config-uri=http://localhost:7101/lwc/api/v1/expressions/local-dev # URI for the Atlas LWC endpoint to retrieve current subscriptions.management.metrics.export.atlas.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.atlas.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.atlas.eval-uri=http://localhost:7101/lwc/api/v1/evaluate # URI for the Atlas LWC endpoint to evaluate the data for a subscription.management.metrics.export.atlas.lwc-enabled=false # Whether to enable streaming to Atlas LWC.management.metrics.export.atlas.meter-time-to-live=15m # Time to live for meters that do not have any activity. After this period the meter will be considered expired and will not get reported.management.metrics.export.atlas.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.atlas.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.atlas.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.atlas.uri=http://localhost:7101/api/v1/publish # URI of the Atlas server.management.metrics.export.datadog.api-key= # Datadog API key.management.metrics.export.datadog.application-key= # Datadog application key. Not strictly required, but improves the Datadog experience by sending meter descriptions, types, and base units to Datadog.management.metrics.export.datadog.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.datadog.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.datadog.descriptions=true # Whether to publish descriptions metadata to Datadog. Turn this off to minimize the amount of metadata sent.management.metrics.export.datadog.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.datadog.host-tag=instance # Tag that will be mapped to "host" when shipping metrics to Datadog.management.metrics.export.datadog.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.datadog.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.datadog.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.datadog.uri=https://app.datadoghq.com # URI to ship metrics to. If you need to publish metrics to an internal proxy en-route to Datadog, you can define the location of the proxy with this.management.metrics.export.ganglia.addressing-mode=multicast # UDP addressing mode, either unicast or multicast.management.metrics.export.ganglia.duration-units=milliseconds # Base time unit used to report durations.management.metrics.export.ganglia.enabled=true # Whether exporting of metrics to Ganglia is enabled.management.metrics.export.ganglia.host=localhost # Host of the Ganglia server to receive exported metrics.management.metrics.export.ganglia.port=8649 # Port of the Ganglia server to receive exported metrics.management.metrics.export.ganglia.protocol-version=3.1 # Ganglia protocol version. Must be either 3.1 or 3.0.management.metrics.export.ganglia.rate-units=seconds # Base time unit used to report rates.management.metrics.export.ganglia.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.ganglia.time-to-live=1 # Time to live for metrics on Ganglia. Set the multi-cast Time-To-Live to be one greater than the number of hops (routers) between the hosts.management.metrics.export.graphite.duration-units=milliseconds # Base time unit used to report durations.management.metrics.export.graphite.enabled=true # Whether exporting of metrics to Graphite is enabled.management.metrics.export.graphite.host=localhost # Host of the Graphite server to receive exported metrics.management.metrics.export.graphite.port=2004 # Port of the Graphite server to receive exported metrics.management.metrics.export.graphite.protocol=pickled # Protocol to use while shipping data to Graphite.management.metrics.export.graphite.rate-units=seconds # Base time unit used to report rates.management.metrics.export.graphite.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.graphite.tags-as-prefix= # For the default naming convention, turn the specified tag keys into part of the metric prefix.management.metrics.export.influx.auto-create-db=true # Whether to create the Influx database if it does not exist before attempting to publish metrics to it.management.metrics.export.influx.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.influx.compressed=true # Whether to enable GZIP compression of metrics batches published to Influx.management.metrics.export.influx.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.influx.consistency=one # Write consistency for each point.management.metrics.export.influx.db=mydb # Tag that will be mapped to "host" when shipping metrics to Influx.management.metrics.export.influx.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.influx.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.influx.password= # Login password of the Influx server.management.metrics.export.influx.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.influx.retention-policy= # Retention policy to use (Influx writes to the DEFAULT retention policy if one is not specified).management.metrics.export.influx.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.influx.uri=http://localhost:8086 # URI of the Influx server.management.metrics.export.influx.user-name= # Login user of the Influx server.management.metrics.export.jmx.enabled=true # Whether exporting of metrics to JMX is enabled.management.metrics.export.jmx.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.newrelic.account-id= # New Relic account ID.management.metrics.export.newrelic.api-key= # New Relic API key.management.metrics.export.newrelic.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.newrelic.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.newrelic.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.newrelic.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.newrelic.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.newrelic.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.newrelic.uri=https://insights-collector.newrelic.com # URI to ship metrics to.management.metrics.export.prometheus.descriptions=true # Whether to enable publishing descriptions as part of the scrape payload to Prometheus. Turn this off to minimize the amount of data sent on each scrape.management.metrics.export.prometheus.enabled=true # Whether exporting of metrics to Prometheus is enabled.management.metrics.export.prometheus.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.signalfx.access-token= # SignalFX access token.management.metrics.export.signalfx.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.signalfx.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.signalfx.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.signalfx.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.signalfx.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.signalfx.source= # Uniquely identifies the app instance that is publishing metrics to SignalFx. Defaults to the local host name.management.metrics.export.signalfx.step=10s # Step size (i.e. reporting frequency) to use.management.metrics.export.signalfx.uri=https://ingest.signalfx.com # URI to ship metrics to.management.metrics.export.simple.enabled=true # Whether, in the absence of any other exporter, exporting of metrics to an in-memory backend is enabled.management.metrics.export.simple.mode=cumulative # Counting mode.management.metrics.export.simple.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.statsd.enabled=true # Whether exporting of metrics to StatsD is enabled.management.metrics.export.statsd.flavor=datadog # StatsD line protocol to use.management.metrics.export.statsd.host=localhost # Host of the StatsD server to receive exported metrics.management.metrics.export.statsd.max-packet-length=1400 # Total length of a single payload should be kept within your network's MTU.management.metrics.export.statsd.polling-frequency=10s # How often gauges will be polled. When a gauge is polled, its value is recalculated and if the value has changed (or publishUnchangedMeters is true), it is sent to the StatsD server.management.metrics.export.statsd.port=8125 # Port of the StatsD server to receive exported metrics.management.metrics.export.statsd.publish-unchanged-meters=true # Whether to send unchanged meters to the StatsD server.management.metrics.export.wavefront.api-token= # API token used when publishing metrics directly to the Wavefront API host.management.metrics.export.wavefront.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.wavefront.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.wavefront.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.wavefront.global-prefix= # Global prefix to separate metrics originating from this app's white box instrumentation from those originating from other Wavefront integrations when viewed in the Wavefront UI.management.metrics.export.wavefront.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.wavefront.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.wavefront.source= # Unique identifier for the app instance that is the source of metrics being published to Wavefront. Defaults to the local host name.management.metrics.export.wavefront.step=10s # Step size (i.e. reporting frequency) to use.management.metrics.export.wavefront.uri=https://longboard.wavefront.com # URI to ship metrics to.management.metrics.use-global-registry=true # Whether auto-configured MeterRegistry implementations should be bound to the global static registry on Metrics.management.metrics.tags.*= # Common tags that are applied to every meter.management.metrics.web.client.max-uri-tags=100 # Maximum number of unique URI tag values allowed. After the max number of tag values is reached, metrics with additional tag values are denied by filter.management.metrics.web.client.requests-metric-name=http.client.requests # Name of the metric for sent requests.management.metrics.web.server.auto-time-requests=true # Whether requests handled by Spring MVC or WebFlux should be automatically timed.management.metrics.web.server.requests-metric-name=http.server.requests # Name of the metric for received requests.# ----------------------------------------# DEVTOOLS PROPERTIES# ----------------------------------------# DEVTOOLS (DevToolsProperties)spring.devtools.livereload.enabled=true # Whether to enable a livereload.com-compatible server.spring.devtools.livereload.port=35729 # Server port.spring.devtools.restart.additional-exclude= # Additional patterns that should be excluded from triggering a full restart.spring.devtools.restart.additional-paths= # Additional paths to watch for changes.spring.devtools.restart.enabled=true # Whether to enable automatic restart.spring.devtools.restart.exclude=META-INF/maven/**,META-INF/resources/**,resources/**,static/**,public/**,templates/**,**/*Test.class,**/*Tests.class,git.properties,META-INF/build-info.properties # Patterns that should be excluded from triggering a full restart.spring.devtools.restart.log-condition-evaluation-delta=true # Whether to log the condition evaluation delta upon restart.spring.devtools.restart.poll-interval=1s # Amount of time to wait between polling for classpath changes.spring.devtools.restart.quiet-period=400ms # Amount of quiet time required without any classpath changes before a restart is triggered.spring.devtools.restart.trigger-file= # Name of a specific file that, when changed, triggers the restart check. If not specified, any classpath file change triggers the restart.# REMOTE DEVTOOLS (RemoteDevToolsProperties)spring.devtools.remote.context-path=/.~~spring-boot!~ # Context path used to handle the remote connection.spring.devtools.remote.proxy.host= # The host of the proxy to use to connect to the remote application.spring.devtools.remote.proxy.port= # The port of the proxy to use to connect to the remote application.spring.devtools.remote.restart.enabled=true # Whether to enable remote restart.spring.devtools.remote.secret= # A shared secret required to establish a connection (required to enable remote support).spring.devtools.remote.secret-header-name=X-AUTH-TOKEN # HTTP header used to transfer the shared secret.# ----------------------------------------# TESTING PROPERTIES# ----------------------------------------spring.test.database.replace=any # Type of existing DataSource to replace.spring.test.mockmvc.print=default # MVC Print option.]]></content>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记]]></title>
    <url>%2F2018%2F06%2F01%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回车和换行]]></title>
    <url>%2F2018%2F04%2F07%2F%E5%9B%9E%E8%BD%A6%E5%92%8C%E6%8D%A2%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[今天在做爬虫的时候,需要匹配下面Title中的内容,发现写的正则表达式question_link(.)&gt;(\n)(.+)(\n*)&lt;竟然匹配不上里面的中文,原来在win系统中文件中的换行其实包含了两个字符, /CR(回车),/LF(换行),这两个”.”都是匹配不上的. 123&lt;h2&gt;&lt;a class="question_link" href="/question/270597366/answer/355546388" data-id="22407872" data-za-element-name="Title"&gt;如何看待星巴克被指含有致癌物质（丙烯酰胺Acrylamide）？&lt;/a&gt;&lt;/h2&gt; 修改成下面,成功匹配 1question_link(.*)&gt;(\r)(\n)(.*) 完整代码为: 1234567891011121314// 其中这段是从文件中摘录的,文件中查看特殊符号显示了换行包含两个字符 一个回车一个换行String s = "&lt;h2&gt;&lt;a class="question_link" href="/question/270597366/answer/355546388" data-id="22407872" data-za-element-name="Title"&gt;如何看待星巴克被指含有致癌物质（丙烯酰胺Acrylamide）？&lt;/a&gt;&lt;/h2&gt;" String regex = "question_link(.*)&gt;(\\r)(\\n)(.*)";Pattern pattern = Pattern.compile(regex);Matcher matcher = pattern.matcher(sb.toString());matcher.find();String group = matcher.group(4);System.out.println(group);// 输出:// 如何看待星巴克被指含有致癌物质（丙烯酰胺Acrylamide）？ 小示例: 123456789String s1 = "\r1234\r567";String s2 = "\n12345";System.out.println(s1);System.out.println(s2);// 输出:56712345 再次强调,回车和换行,”.”都不能匹配 1234567String s1 = "\r1234\r567";String regex = ".*";String regex1 = "\\r.*";Pattern pattern = Pattern.compile(regex1); // 换成regex则下面的输出为空,也就是不能匹配Matcher matcher = pattern.matcher(s1);matcher.find();System.out.println(matcher.group()); 更多知识请参考: 终于搞懂了回车与换行的区别]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro安全框架之与web集成（2）]]></title>
    <url>%2F2017%2F06%2F07%2FShiro%E5%AE%89%E5%85%A8%E6%A1%86%E6%9E%B6%E4%B9%8B%E4%B8%8Eweb%E9%9B%86%E6%88%90%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[为了深入理解Shiro与web项目集成的工作原理,我们搭建一个普通的web项目 1. 导入相关依赖pom.xml: shiro-core和shiro-web 1234567891011121314151617181920&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;shiro.version&gt;1.2.2&lt;/shiro.version&gt; &lt;/properties&gt;...&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;$&#123;shiro.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--因为是合web项目集成,因此需要导入shiro-web这个jar包--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-web&lt;/artifactId&gt; &lt;version&gt;$&#123;shiro.version&#125;&lt;/version&gt;&lt;/dependency&gt;... 2.在web.xml中配置shiro的过滤器shiroFilter12345678910111213141516171819202122232425262728293031323334&lt;web-app...&gt;&lt;!--初始化securityManager对象所需要的环境配置--&gt; &lt;!--主要是为了加载ini文件,如果将shiro.ini放在WEB-INF下或者classpath根目录下,这个也不用配置,EnvironmentLoaderListener会自动读取并且加载--&gt; &lt;!--&lt;context-param&gt;--&gt; &lt;!--&lt;param-name&gt;shiroEnvironmentClass&lt;/param-name&gt;--&gt; &lt;!--&lt;param-value&gt;org.apache.shiro.web.env.IniWebEnvironment&lt;/param-value&gt;--&gt; &lt;!--&lt;/context-param&gt;--&gt; &lt;!--&lt;context-param&gt;--&gt; &lt;!--&lt;param-name&gt;shiroConfigLocations&lt;/param-name&gt;--&gt; &lt;!----&gt; &lt;!--&lt;param-value&gt;classpath:shiro.ini&lt;/param-value&gt;--&gt; &lt;!--&lt;/context-param&gt;--&gt; &lt;!-- 从Shiro1.2开始引入了Environment/WebEnvironment的概念，即由它们的实现提供相应的SecurityManager及其相应的依赖。 ShiroFilter会自动找到Environment然后获取相应的依赖。 底层:返回反射创建shiroEnvironmentClass对象,调用其init方法. shiroEnvironmentClass中的init方法创建SecurityManager实例并绑定到当前运行环境 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.apache.shiro.web.env.EnvironmentLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.shiro.web.servlet.ShiroFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;!-- 拦截所有的请求 --&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 具体可以参考:官方文档 这里简单说下EnvironmentLoaderListener和ShiroFilter的作用: 在容器启动时创建 WebEnvironment 对象，并由该对象来读取 Shiro 配置文件，创建WebSecurityManager 与 FilterChainResolver 对象，它们都在后面将要出现的 ShiroFilter 中起到了重要作用。 从 web.xml 中同样可以得知，ShiroFilter 是整个 Shiro 框架的门面，因为它拦截了所有的请求，后面是需要 Authentication（认证）还是需要 Authorization（授权）都由它说了算。 3. 创建shiro.ini文件123456789101112131415161718192021222324252627282930313233[main]#默认是/login.jsp(登录认证的url,默认是/login.jsp)authc.loginUrl=/login#用户无需要的角色时跳转的页面roles.unauthorizedUrl=/nopermission.jsp#用户无需要的权限时跳转的页面perms.unauthorizedUrl=/nopermission.jsp#登出之后重定向的页面logout.redirectUrl=/login[users]; admin用户拥有admin这个角色admin=666,admin;zhangsan拥有deptMgr这个角色zhangsan=666,deptMgr[roles];admin这个角色拥有employee和department的所有操作权限admin=*:*;admin=employee:*,department:*deptMgr=department:view[urls]#静态资源可以匿名访问/static/**=anon#访问员工列表需要身份认证及需要拥有admin角色/employee=authc,roles[admin]#访问部门列表需要身份认证及需要拥有department:view的权限/department=authc,perms["department:view"]#当请求loginOut,会被logout捕获并清除session/loginOut=logout#所有的请求都需要身份认证(会跳转到authc.loginUrl指定的url)/**=authc 上面配置中的anon,authc,logout..等等都是shiro中的默认过滤器,官方文档:默认过滤器,下面列举了一些常用的默认过滤器: 1234567891011过滤器简称 对应的java类anon org.apache.shiro.web.filter.authc.AnonymousFilterauthc org.apache.shiro.web.filter.authc.FormAuthenticationFilterauthcBasic org.apache.shiro.web.filter.authc.BasicHttpAuthenticationFilterroles org.apache.shiro.web.filter.authz.RolesAuthorizationFilterperms org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilteruser org.apache.shiro.web.filter.authc.UserFilterlogout org.apache.shiro.web.filter.authc.LogoutFilterport org.apache.shiro.web.filter.authz.PortFilterrest org.apache.shiro.web.filter.authz.HttpMethodPermissionFilterssl org.apache.shiro.web.filter.authz.SslFilter 说明: anon:匿名拦截器，即不需要登录即可访问；一般用于静态资源过滤；示例“/static/**=anon” authc:表示需要认证(登录)才能使用;示例“/**=authc”.主要属性：usernameParam：表单提交的用户名参数名（ username）； passwordParam：表单提交的密码参数名（password）； rememberMeParam：表单提交的密码参数名（rememberMe）； loginUrl：登录页面地址（/login.jsp）；successUrl：登录成功后的默认重定向地址； failureKeyAttribute：登录失败后错误信息存储key（shiroLoginFailure）； authcBasic:Basic HTTP身份验证拦截器，主要属性： applicationName：弹出登录框显示的信息（application）； roles:角色授权拦截器，验证用户是否拥有资源角色；示例“/admin/**=roles[admin]” perms:权限授权拦截器，验证用户是否拥有资源权限；示例“/user/create=perms[“user:create”]” user:用户拦截器，用户已经身份验证/记住我登录的都可；示例“/index=user” logout:退出拦截器，主要属性：redirectUrl：退出成功后重定向的地址（/）;示例“/logout=logout” port:端口拦截器，主要属性：port（80）：可以通过的端口；示例“/test= port[80]”，如果用户访问该页面是非80，将自动将请求端口改为80并重定向到该80端口，其他路径/参数等都一样 rest:rest风格拦截器，自动根据请求方法构建权限字符串（GET=read,POST=create,PUT=update,DELETE=delete,HEAD=read,TRACE=read,OPTIONS=read, MKCOL=create）构建权限字符串； 示例“/users=rest[user]”，会自动拼出“user:read,user:create,user:update,user:delete”权限字符串进行权限匹配（所有都得匹配，isPermittedAll）； ssl:SSL拦截器，只有请求协议是https才能通过；否则自动跳转会https端口（443）；其他和port拦截器一样； 注： anon，authcBasic，auchc，user是认证过滤器， perms，roles，ssl，rest，port是授权过滤器 4.拦截器的执行原理 从上图可以看出,排号越前的默认拦截器优先级越高 4.1 authc登录拦截器工作原理authc拦截器有2个作用： 校验是否已经登录 请求进来时，拦截并判断当前用户是否登录了，如果已经登录了放行， 如果没有登录，跳转到authc.loginUrl属性配置的路径，注意：默认是/login.jsp 执行登录认证 请求进来时，如果请求的路径为authc.loginUrl属性配置的路径（没配置，默认是/login.jsp）时，如果当前用户没有登录，authc这个拦截器会尝试获取请求中的账号跟密码值，然后比对ini配置文件或者realm中的用户列表，如果比对正确，直接执行登录操作，反之，抛异常，跳转到authc.loginUrl指定的路径。 注意：请求中账号与密码必须固定为username 跟password， 如果需要改动必须额外指定，authc.usernameParam=xxx authc.passwordParam=xxxx 我们在shiro.ini文件中已经配置了user,shiro的拦截器会自动进行校验,不需要再像传统方式一样在这里获取用户名和密码,然后比对,然后存入session…. 4.2 authc登录成功之后处理逻辑： 4.3 authc登录失败后的异常处理:1234567891011121314151617181920212223242526@WebServlet(name = "LoginServlet", urlPatterns = "/login")public class LoginServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; this.doPost(req, resp); &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; // 如果登录失败,从request中获取认证异常信息,exceptionClassName就是shiro的异常类名 String exceptionClassName = (String) req.getAttribute("shiroLoginFailure"); if (UnknownAccountException.class.getSimpleName().equals(exceptionClassName)) &#123; req.setAttribute("errorMsg", "账号异常!"); &#125; else if (IncorrectCredentialsException.class.getSimpleName().equals(exceptionClassName)) &#123; req.setAttribute("errorMsg", "密码异常!"); &#125; else &#123; req.setAttribute("errorMsg", "其他异常!"); &#125; //不需要再像传统方式一样在这里获取用户名和密码,然后比对,然后存入session.... req.getRequestDispatcher("/WEB-INF/views/login.jsp").forward(req, resp); &#125;&#125; 5.shiro的jsp标签123456789101112标签名称 标签条件（均是显示标签内容）&lt;shiro:authenticated&gt; 登录之后&lt;shiro:notAuthenticated&gt; 不在登录状态时&lt;shiro:guest&gt; 用户在没有RememberMe时&lt;shiro:user&gt; 用户在RememberMe时&lt;shiro:hasAnyRoles name="abc,123" &gt; 在有abc或者123角色时&lt;shiro:hasRole name="abc"&gt; 拥有角色abc&lt;shiro:lacksRole name="abc"&gt; 没有角色abc&lt;shiro:hasPermission name="abc"&gt; 拥有权限资源abc&lt;shiro:lacksPermission name="abc"&gt; 没有abc权限资源&lt;shiro:principal&gt; 显示用户身份名称&lt;shiro:principal property="username"/&gt; 显示用户身份中的属性值 当具有对department资源的add权限的时候,才显示新增标签 123&lt;shiro:hasPermission name="department:add"&gt; &lt;a href="/department?cmd=input"&gt;新增&lt;/a&gt;&lt;/shiro:hasPermission&gt; 上面就是shiro和web矿建的简单集成… 欢迎访问我的博客网站]]></content>
      <categories>
        <category>shiro安全框架</category>
      </categories>
      <tags>
        <tag>shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro安全框架之入门（1）]]></title>
    <url>%2F2017%2F06%2F06%2FShiro%E5%AE%89%E5%85%A8%E6%A1%86%E6%9E%B6%E4%B9%8B%E5%85%A5%E9%97%A8%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.什么是权限管理基本上涉及到用户参与的系统都要进行权限管理，权限管理属于系统安全的范畴，权限管理能实现对用户访问系统的控制，按照安全规则或者安全策略限制用户操作，只允许用户访问被授权的资源。 权限管理包括用户身份认证和授权两部分，简称认证授权。 相关概念: 身份认证 就是判断一个用户是否为合法用户的处理过程.醉常用的简单身份认证方式是系统通过核对用户输入的用户名和口令,看其是否与系统中存储的该用户的用户名和口令一致,来判断用户身份是否正确.对于采用指纹等系统,则出示指纹；对于硬件Key等刷卡系统,则需要刷卡 授权 即访问控制，控制谁能访问哪些资源。主体进行身份认证后需要分配权限方可访问系统的资源，对于某些资源没有权限是无法访问的。 上边的流程图中需 要理解以下关键对象： Subject：主体 user ​ 访问系统的用户，主体可以是用户、程序等，进行认证的都称为主体； Principal：身份信息(username)主体（subject）进行身份认证的标识，标识必须具有唯一性，如用户名、手机号、邮箱地址等，一个主体可以有多个身份，但是必须有一个主身份（Primary Principal）。 credential：凭证信息(password)，只有主体自己知道的安全信息，如密码、证书等。 Apache Shiro安全框架Apache Shiro是Java的一个安全框架。帮助我们完成：认证、授权、加密、会话管理、与Web集成、缓存等。 从功能角度看shiro Authentication：[ɔ:ˌθentɪ’keɪʃn]身份认证/登录，验证用户是不是拥有相应的身份； Authorization：[ˌɔ:θərəˈzeɪʃn] 授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限； Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通JavaSE环境的，也可以是Web环境的； Cryptography：[krɪpˈɑ:grəfi]加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储； Web Support：Web支持，可以非常容易的集成到Web环境； Caching：缓存，比如用户登录后，其用户信息、拥有的角色/权限不必每次去查，这样可以提高效率； Concurrency：shiro支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去； Testing：提供测试支持； Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问； Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。 Shiro架构有三个主要概念 : Subject，SecurityManager，Realms。 Subject 访问系统的用户，主体可以是用户、程序等，进行认证的都称为主体； ​ Subject一词是一个安全术语，其基本意思是“当前的操作用户”。它是一个抽象的概念，可以是人，也可以是第三方进程或其他类似事物，如爬虫，机器人等。 ​ 在程序任意位置：Subject currentUser = SecurityUtils.getSubject(); 获取shiro 一旦获得Subject，你就可以立即获得你希望用Shiro为当前用户做的90%的事情，如登录、登出、访问会话、执行授权检查等 SecurityManager ​ 安全管理器，它是shiro功能实现的核心，负责与后边介绍的其他组件(认证器/授权器/缓存控制器)进行交互，实现subject委托的各种功能。有点类似于spirngmvc中的DispatcherServlet前端控制器。 Realms ​ Realm充当了Shiro与应用安全数据间的“桥梁”或者“连接器”。；可以把Realm看成DataSource，即安全数据源。执行认证（登录）和授权（访问控制）时，Shiro会从应用配置的Realm中查找相关的比对数据。以确认用户是否合法，操作是否合理 从系统结构角度看shiro Subject：主体，可以看到主体可以是任何可以与应用交互的“用户”； SecurityManager：相当于SpringMVC中的DispatcherServlet或者Struts2中的FilterDispatcher；是Shiro的心脏；所有具体的交互都通过SecurityManager进行控制；它管理着所有Subject、且负责进行认证和授权、及会话、缓存的管理。 Authenticator：认证器，负责主体认证的，这是一个扩展点，如果用户觉得Shiro默认的不好，可以自定义实现；其需要认证策略（Authentication Strategy），即什么情况下算用户认证通过了； Authorizer：授权器，或者访问控制器，用来决定主体是否有权限进行相应的操作；即控制着用户能访问应用中的哪些功能； Realm：可以有1个或多个Realm，可以认为是安全实体数据源，即用于获取安全实体的；可以是JDBC实现，也可以是LDAP实现，或者内存实现等等；由用户提供；注意：Shiro不知道你的用户/权限存储在哪及以何种格式存储；所以我们一般在应用中都需要实现自己的Realm； SessionManager：如果写过Servlet就应该知道Session的概念，Session呢需要有人去管理它的生命周期，这个组件就是SessionManager；而Shiro并不仅仅可以用在Web环境，也可以用在如普通的JavaSE环境、EJB等环境；所有呢，Shiro就抽象了一个自己的Session来管理主体与应用之间交互的数据；可以实现分布式的会话管理； SessionDAO：DAO大家都用过，数据访问对象，用于会话的CRUD，比如我们想把Session保存到数据库，那么可以实现自己的SessionDAO，通过如JDBC写到数据库；比如想把Session放到redis中，可以实现自己的redis SessionDAO；另外SessionDAO中可以使用Cache进行缓存，以提高性能； CacheManager：缓存控制器，来管理如用户、角色、权限等的缓存的；因为这些数据基本上很少去改变，放到缓存中后可以提高访问的性能 Cryptography：密码模块，Shiro提高了一些常见的加密组件用于如密码加密/解密的。 入门使用 1.导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt;&lt;/dependency&gt; 2.配置shiro.ini文件 12345[users]; username=password(等号前面是用户名,后面是密码)admin=123zhangsan=123lisi=123 3.测试 写一个简单的测试类,用于登录的业务逻辑 1234567891011121314151617181920212223242526272829@Testpublic void login() throws Exception &#123; String username = "zhangsan"; String password = "123"; // 创建工厂(从本地的shiro.ini文件中获取用户列表) IniSecurityManagerFactory factory = new IniSecurityManagerFactory("classpath:shiro/shiro.ini"); // 创建securityManager实例 SecurityManager securityManager = factory.getInstance(); // 将securityManager绑定到当前运行环境中,让系统可以随时随地的访问securityManager对象 SecurityUtils.setSecurityManager(securityManager); // 创建当前的主体 Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(username, password); try &#123; subject.login(token); &#125;catch (Exception e)&#123; if (e instanceof UnknownAccountException)&#123; throw new Exception("该用户不存在"); &#125; if (e instanceof IncorrectCredentialsException)&#123; throw new Exception("用户密码不正确!"); &#125; &#125; // 是否登录成功 boolean authenticated = subject.isAuthenticated(); System.out.println("是否登录成功"+authenticated); &#125; login.jsp 123456789101112&lt;html&gt;&lt;head&gt; &lt;title&gt;用户登录&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="$&#123;pageContext.request.contextPath&#125;/login.action" method="post"&gt; 用户名:&lt;input type="text" name="username"/&gt; 密码:&lt;input type="text" name="password"/&gt; &lt;input type="submit" value="登录" /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 当在表单中输入用户名:zhangsan,密码:123时,输出:是否登录成功:true 用户登出也很简单:直接调用:subject.logout();方法即可 shiro登录登出流程简单分析 大体流程是: 1、调用subject.login方法进行登录，其会自动委托给securityManager.login方法进行登录； 2、securityManager通过Authenticator(认证器)进行认证; 3、Authenticator的实现ModularRealmAuthenticator调用realm从ini配置文件取用户真实的账号和密码，这里使用的是IniRealm（shiro自带,相当于数据源）； 4、IniRealm先根据token中的账号去ini中找该账号，如果找不到则给ModularRealmAuthenticator返回null，如果找到则匹配密码，匹配密码成功则认证通过。 5、最后调用Subject.logout进行退出操作。 shiro自定义realm,测试认证Realm是安全实体数据源，即用于获取安全实体的；可以是JDBC实现，也可以是LDAP实现，或者内存实现等等；由用户提供；注意：Shiro不知道你的用户/权限存储在哪及以何种格式存储；所以我们一般在应用中都需要实现自己的Realm. 我们直接选择继承AuthorizingRealm 1234567891011121314151617181920212223242526272829303132333435363738394041public class MyRealmForPermission extends AuthorizingRealm &#123; @Override public String getName() &#123; return this.getClass().getSimpleName(); &#125; /** * 认证操作 * * @param authenticationToken * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; // 获取token传入的用户名(页面传入) String usernameForm = (String) authenticationToken.getPrincipal(); // 用户名,密码(根据用户名从数据库中查询得到,这里为模拟数据) String username = "wangle"; String password = "123"; // 如果没有找到相应的用户,则返回null if (!username.equals(usernameForm)) &#123; return null; &#125; // 将从数据库中查询的相关信息,封装成AuthenticationInfo对象,继续交给authenticator(认证器)进行认证 AuthenticationInfo info = new SimpleAuthenticationInfo(username, password, getName()); return info; &#125; /** * 授权操作(授权之前用户必须是登录的) * * @param principals * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; return null; &#125;&#125; 接下来在shiro.ini文件中,指定realms的来源为自定义的realm.(将[users]下定义的用户删除掉,不然不起作用) 123456;自定义realmmyRealm = com.lee.shiro.realm.MyRealm; 给自定义的real添加加密器myRealm.credentialsMatcher=$credentialsMatcher;指定securityManager引用的realmsecurityManager.realms = $myRealm 测试:(跟上面使用ini文件中配置的realm用户密码测试方法一样) 1234567891011121314151617181920212223242526272829@Testpublic void login() throws Exception &#123; String username = "zhangsan"; String password = "123"; // 创建工厂(从本地的shiro.ini文件中获取用户列表) IniSecurityManagerFactory factory = new IniSecurityManagerFactory("classpath:shiro/shiro.ini"); // 创建securityManager实例 SecurityManager securityManager = factory.getInstance(); // 将securityManager绑定到当前运行环境中,让系统可以随时随地的访问securityManager对象 SecurityUtils.setSecurityManager(securityManager); // 创建当前的主体 Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(username, password); try &#123; subject.login(token); &#125;catch (Exception e)&#123; if (e instanceof UnknownAccountException)&#123; throw new Exception("该用户不存在"); &#125; if (e instanceof IncorrectCredentialsException)&#123; throw new Exception("用户密码不正确!"); &#125; &#125; // 是否登录成功 boolean authenticated = subject.isAuthenticated(); System.out.println("是否登录成功"+authenticated); &#125; shiro 加密操作 散列算法一般用于生成数据的摘要信息，是一种不可逆的算法，一般适合存储密码之类的数据，常见的散列算法如MD5、SHA等。一般进行散列时最好提供一个salt（盐），比如加密密码“admin”，产生的散列值是“21232f297a57a5a743894a0e4a801fc3”，可以到一些md5解密网站很容易的通过散列值得到密码“admin”，即如果直接对密码进行散列相对来说破解更容易，此时我们可以加一些只有系统知道的干扰数据，如用户名和ID（即盐）；这样散列的对象是“密码+用户名+ID”，这样生成的散列值相对来说更难破解。 1234567@Testpublic void getMD5Str() &#123; String password = "123"; // 参数说明:1.需要加密的字符串;2.盐;3.迭代加密次数 Md5Hash md5Hash = new Md5Hash(password,null, 2); System.out.println(md5Hash);&#125; 在shiro中使用方式很简单: 在shiro.ini中增加 12345678[main]......; 给自定义的real添加加密器myRealm.credentialsMatcher=$credentialsMatcher;散列算法credentialsMatcher.hashAlgorithmName = md5;散列次数(本次散列的结果作为下次散列的源)credentialsMatcher.hashIterations = 2 在插入用户的时候,就使用MD5+盐将密码加密,然后存入数据库.前端传入的用户名、密码（明文）被封装的UsernamePasswordToken对象中,从数据库中查询出用户名、密码（密文）被封装成AuthenticationInfo对象，然后SecurityManager在调用方法进行比对时会自动现将UsernamePasswordToken对象中的密码（明文）先加密（加密的方式应该和存入数据库密码的加密方式一样），然后才进行比对。 授权上面的所有操作都是认证操作，也就是登录操作。接下来看看授权操作是怎么回事儿 1.RBAC 基于角色的权限管理简单理解为：谁扮演什么角色， 被允许做什么操作 用户对象：user： 当前操作用户 角色对象：role：表示权限操作许可权的集合 权限对象：permission: 资源操作许可权 例子：张三（user） 下载（permission）一个高清无码的种子（资源）， 需要VIP权限（role） 张三—&gt;普通用户—&gt;授权—-&gt;VIP用户—–&gt;下载种子 2.授权方式 编程方式 1234567//通过写if/else授权代码块完成Subject subject = SecurityUtils.getSubject(); if(subject.hasRole(“admin”)) &#123; //有权限 &#125; else &#123; //无权限 &#125; 注解方式 123456// 通过在执行的Java方法上放置相应的注解完成@RequiresRoles("admin") @RequiresPermission(“employee:save”)public void hello() &#123; //有权限 &#125; jsp标签方式 1234&lt;!--jsp标签方式：在JSP页面通过相应的标签完成--&gt;&lt;shiro:hasRole name="admin"&gt; &lt;!— 有权限 —&gt; &lt;/shiro:hasRole&gt; 3. 权限表达式在ini文件中用户、角色、权限的配置规则是：“用户名=密码，角色1，角色2…” “角色=权限1，权限2…”，首先根据用户名找角色，再根据角色找权限，角色是权限集合。 权限字符串的规则是：“资源标识符：操作：资源实例标识符”，意思是对哪个资源的哪个实例具有什么操作，“:”是资源/操作/实例的分割符，权限字符串也可以使用*通配符。 例子： 用户创建权限：user:create，或user:create:* 用户修改实例001的权限：user:update:001 用户实例001的所有权限：user：*：001 一般而已，我们操作只需要关注前面两节： 资源：操作 ： *.*: 所有资源的所有操作权限—&gt;admin 4. 使用ini方式判断是否有角色权限步骤: 1：配置ini文件 (shiro/shiro_roles.ini) 12345678910[users]zhangsan=123,role1lisi=123wanglee=123,role2[roles]; role1对上边的user有创建和更新的权限role1=user:create,user:update; role2对上面的user具有所有的权限role2=user:* 2：加载配置文件，测试用户是否拥有角色 123456789101112131415161718@Testpublic void testHasRoles() &#123; Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory("classpath:shiro/shiro_roles.ini"); SecurityManager securityManager = factory.getInstance(); SecurityUtils.setSecurityManager(securityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken("wanglee", "123"); // 在进行授权之前需要先进行登录(实际应用中,只有登录以后才可以进行授权) subject.login(token); // 判断用户wangle是否有role1角色 System.out.println(subject.hasRole("role1")); // 判断wanglee是否具有下面这一堆属性 System.out.println(Arrays.toString(subject.hasRoles(Arrays.asList("role1", "role2")))); // 校验用户是否拥有role1角色,如果没有,则抛出异常,如果有该权限,继续往下执行,什么也不做 subject.checkRole("role1"); // 校验是否具有下述的一堆属性,如果没有其中的一个,则抛出异常 subject.checkRoles("role1", "role2");&#125; 5.自定义Realm完成授权自定义MyRealmForPermission继承 AuthorizingRealm重写3个方法： getName() doGetAuthorizationInfo() doGetAuthenticationInfo() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class MyRealmForPermission extends AuthorizingRealm &#123; @Override public String getName() &#123; return this.getClass().getSimpleName(); &#125; /** * 认证操作 * * @param authenticationToken * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; // 获取token传入的用户名(页面传入) String usernameForm = (String) authenticationToken.getPrincipal(); // 用户名,密码(从数据库中查询得到) String username = "wangle"; String password = "123"; // 如果没有找到相应的用户,则返回null if (!username.equals(usernameForm)) &#123; return null; &#125; // 将从数据库中查询的相关信息,封装成AuthenticationInfo对象,继续交给authenticator(认证器)进行认证 // 加盐// AuthenticationInfo info = new SimpleAuthenticationInfo(username, password, ByteSource.Util.bytes("username"),getName()); // 不加盐 AuthenticationInfo info = new SimpleAuthenticationInfo(username, password, getName()); return info; &#125; /** * 授权操作(授权之前用户必须是登录的) * * @param principals * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; // 当前登录的用户名 String username = (String) principals.getPrimaryPrincipal(); SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); // 添加角色(实际开发中是通过该用户名称查询数据库,得到用户类型,然后查询用户角色表和角色权限表得到该用户的权限) info.addRoles(Arrays.asList("role1", "role2")); info.addStringPermissions(Arrays.asList("user:delete", "user:create")); return info; &#125;&#125; 在shiro/shiro_roles_custom.ini中进行配置: 123456[main]; 自定realm完成授权myRealm2= com.lee.shiro.realm.MyRealmForPermission;指定securityManager引用的realmsecurityManager.realms = $myRealm2 测试: 12345678910111213141516171819202122232425262728/** * 自定义Realm,实现用户的认证和授权 * &lt;p&gt; * 用户必须通过认证以后,才可以实现 */@Testpublic void testAuthen() &#123; Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory("classpath:shiro/shiro_roles_custom.ini"); SecurityManager securityManager = factory.getInstance(); SecurityUtils.setSecurityManager(securityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken("wangle", "123"); // 登录认证 subject.login(token); boolean[] booleans = subject.hasRoles(Arrays.asList("role1", "role2", "role3")); System.out.println(Arrays.toString(booleans)); // 用户是否被授予关于user的所有的权限(类似于admin管理员权限) boolean permitted = subject.isPermitted("user:*"); System.out.println(permitted); //用户是否被授予delete权限 boolean permitted1 = subject.isPermitted("user:delete"); System.out.println(permitted1);&#125; 关于shiro的基本使用原理就是这样的,实际应用是结合web项目来应用的,请关注我的下一篇博客: Shiro安全框架之与web集成（2） 欢迎访问我的博客网站]]></content>
      <categories>
        <category>shiro安全框架</category>
      </categories>
      <tags>
        <tag>shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate学习笔记4]]></title>
    <url>%2F2017%2F05%2F12%2FHibernate%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%2F</url>
    <content type="text"><![CDATA[Hibernate–4JPA(Java Persistence API)：Java持久化API,用于规范ORM接口的一系列规范。 Hibernate中实现了JPA规范 配置 项目引入jpa配置（persistence.xml） 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;persistence xmlns="http://xmlns.jcp.org/xml/ns/persistence" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/persistence http://xmlns.jcp.org/xml/ns/persistence/persistence_2_1.xsd" version="2.1"&gt; &lt;!-- name : 用于指定持久化单元的名称(可以为空,必须配) transaction-type : 指定事务类型,取值为JTA(默认)、RESOURCE_LOCAL --&gt; &lt;persistence-unit name="Unit1" transaction-type="RESOURCE_LOCAL"&gt; &lt;!--javax.persistence.PersistenceProvider的一个实现类,用于创建EntityManagerFactory(用于产生实体类管理者工厂)--&gt; &lt;!--在Hibernate中实现了JPA规范,这个类其实也是默认的,可以不配--&gt; &lt;provider&gt;org.hibernate.jpa.HibernatePersistenceProvider&lt;/provider&gt; &lt;!--罗列出需要持久化的类(在JavaEE环境下可以不配)--&gt; &lt;class&gt;com.lee.cfgtest.Student&lt;/class&gt; &lt;class&gt;com.lee.cfgtest.Teacher&lt;/class&gt; &lt;class&gt;com.lee.one2many.Tenant&lt;/class&gt; &lt;class&gt;com.lee.one2many.Landlord&lt;/class&gt; &lt;!--JPA实现者专有配置,不同的JPA规范实现框架,可能配置的property值不一样--&gt; &lt;!--参考hibernate.cfg.xml中的配置--&gt; &lt;properties&gt; &lt;!--DDL生成策略--&gt; &lt;!--其中update表示:检测实体类和表结构是否一致,如果不一致,更新表结构达到一致,如果不存在该表,就创建一张表--&gt; &lt;property name=&quot;hibernate.hbm2ddl.auto&quot; value=&quot;update&quot;/&gt; &lt;!--第一部分:数据库连接配置--&gt; &lt;property name=&quot;hibernate.connection.driver_class&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;hibernate.connection.url&quot; value=&quot;jdbc:mysql://localhost:3306/hibernate2&quot;/&gt; &lt;property name=&quot;hibernate.connection.username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;hibernate.connection.password&quot; value=&quot;123&quot;/&gt; &lt;!--第二部分 :配置数据库连接池:c3p0 (自由选择)--&gt; &lt;property name=&quot;hibernate.connection.provider_class&quot; value=&quot;org.hibernate.connection.C3P0ConnectionProvider&quot;/&gt; &lt;!--配置数据库方言--&gt; &lt;property name=&quot;hibernate.dialect&quot; value=&quot;org.hibernate.dialect.MySQL55Dialect&quot;/&gt; &lt;!--是否在控制台显示生成的sql语句--&gt; &lt;property name=&quot;hibernate.show_sql&quot; value=&quot;true&quot;/&gt; &lt;!--是否将控制台里的sql语句格式化输出--&gt; &lt;!--&lt;property name=&quot;hibernate.format_sql&quot; value=&quot;true&quot;/&gt;--&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; 一对多关系配置 1234567891011121314151617181920212223242526272829303132* 实体类中的配置(包含表之间一对多映射配置) 一对多关系中的"一"的一方实体类配置 @Entity @Table(name = "hb_landlord") public class Landlord &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = "l_id") private Integer lid; @Column(name = "l_name") private String lname; @Column(name = "l_sex") private String lsex; @Column(name = "l_age") private Integer lage; @Column(name = "l_phone") private String lphone; // 参数解释: // targetEntity:表示对应的"多"的一方的字节码文件,也可以不加 // mappedBy:从表中引用的该实体属性名,如果配置了该项,表示放弃维护和从表之间的关联关系.在一对多配置中,一般"一"的一方会配置上该属性;如果没有配置该属性,会生成第三张表(类似于多对多中的中间表)来维护他们之间的关系 // fetch:配置tenants的加载方式, OneToMany中fetch的默认值为LAZY // 还有其他属性:cascade:级联操作 @OneToMany(targetEntity = Tenant.class, fetch = FetchType.LAZY, mappedBy = "landlord") private Set&lt;Tenant&gt; tenants = new HashSet&lt;&gt;(0); // 省略默认构造方法,get/set方法,toString()方法 &#125; 注意:属性级别的注解，都是放在其对应的getter前。 一对多中”多”的一方的实体类配置 1234567891011121314151617181920212223242526@Entity@Table(name = "hb_tenant")public class Tenant &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = "t_id") private Integer tid; @Column(name = "t_name") private String tname; @Column(name = "t_sex") private String tsex; @Column(name = "t_age") private Integer tage; @Column(name = "t_phone") private String tphone; @Column(name = "t_job") private String tjob; // 从事的工作 // 一位租户只能有一个房东,建立关系 @ManyToOne(targetEntity = Landlord.class, fetch = FetchType.LAZY) // 用于配置外键,如果不配置也会默认生成(最好自己配上,生成的外键字段可读性更好) @JoinColumn(name = "land_tenant_fk", referencedColumnName = "l_id") private Landlord landlord; // 省略默认构造方法,get/set方法,toString()方法&#125; 多对多关系配置多对多配置以后会生成一个中间表,中间表维护了两个表之间的关系.但是在配置的时候,要分清楚关系维护端(保留关联关系),任何两个表之间都有主从之分 主表:hb_teacher对应的实体表 1234567891011121314151617181920212223242526@Entity // 指定这是一个实体类.在创建EntityManagerFactory的时候就会读取映射配置@Table(name = "hb_teacher") // 指定该表所在数据库中的表名public class Teacher &#123; @Id // 主键 @GeneratedValue(strategy = GenerationType.IDENTITY) // 主键生成策略 @Column(name = "t_id") // 主键在数据库中对应的字段名 private Long tid; @Column(name = "t_name") private String tname; @Column(name = "t_age") private String tage; // targetEntity:映射的另一方实体的类 // mappedBy : 被对方维护关联关系(也就是说放弃了维护关联关系的权利) @ManyToMany(targetEntity = Student.class,mappedBy = "teachers") private Set&lt;Student&gt; students = new HashSet&lt;&gt;(0); public Teacher() &#123; &#125; // 省略get/set方法,省略toString方法&#125; 从表:hb_student表对应的实: 123456789101112131415161718192021222324252627282930313233@Entity@Table(name = "hb_student")public class Student &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = "s_id") private Long sid; @Column(name = "s_name") private String sname; @Column(name = "s_age") private String sage; @ManyToMany(targetEntity = Teacher.class) @JoinTable( name = "stu_tea_ref", // 中间表的表名 joinColumns = &#123; // 指定自己一方在表中维护的字段.name:字段名;referencedColumnName:关联的字段名称 @JoinColumn(name = "stu_id", referencedColumnName = "s_id") &#125;, inverseJoinColumns = &#123; // 指定对方在表中维护的字段.name:字段名;referencedColumnName:关联的字段的名称 @JoinColumn(name = "tea_id", referencedColumnName = "t_id") &#125; ) private Set&lt;Teacher&gt; teachers = new HashSet&lt;&gt;(0); public Student() &#123; &#125; // 省略get/set方法,省略toString()方法&#125; 在执行删除操作时:主控方(维护了关联关系的表): 可以同时将记录删除,并且删除中间表中的记录 从方(放弃维护关联关系的表): 如果该记录被中间表引用,不能删除 在从方配置了级联删除,会将该记录删除,中间表中的数据也会删除,但,同时会将主控方的表中也删除一条记录,这是不允许的 ​]]></content>
      <tags>
        <tag>学习日记</tag>
        <tag>错误解决</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis的逆向工程]]></title>
    <url>%2F2017%2F05%2F10%2Fmybatis%E7%9A%84%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC和MyBatis整合入门]]></title>
    <url>%2F2017%2F05%2F10%2FSpringMVC%E5%92%8CMyBatis%E6%95%B4%E5%90%88%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[1. 整合思路 表现层 SpringMVC 业务层 service接口 持久层 MyBatis Spring将各层进行整合 通过spring管理持久层的mapper(相当于dao接口) 通过spring管理业务层service，service中可以调用mapper接口。 spring进行事务控制。 通过spring管理表现层Handler，Handler中可以调用service接口。 mapper、service、Handler都是javabean(Java组件)。Spring的IOC和AOP特性很容易做到上面这些 2. 整合思路 第一步：整合dao层 ​ mybatis和spring整合，通过spring管理mapper接口。 ​ 使用mapper的扫描器自动扫描mapper接口在spring中进行注册。 第二步：整合service层 ​ 通过spring管理 service接口。 ​ 使用配置方式将service接口配置在spring配置文件中。 ​ 实现事务控制。 第三步：整合springmvc ​ 由于springmvc是spring的模块，不需要整合。 3. 整合过程,基于maven3.1 整合dao层创建配置文件applicationContext-dao.xml配置文件,里面专门放置跟dao层相关的配置 applicationContext-dao.xml: 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt; &lt;!--加载属性文件--&gt; &lt;context:property-placeholder location="classpath:config.properties"/&gt; &lt;!-- 使用自动扫描:将mybatis的mapper自动装载进来 遵循的规范:mapper.java和mapper.xml映射文件名保持一致,并且要在一个目录中 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.lee.ssm.mapper"/&gt; &lt;/bean&gt; &lt;!--配置数据源--&gt; &lt;!--配置c3p0连接池--&gt; &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;!--数据库连接相关信息--&gt; &lt;property name="driverClass" value="$&#123;jdbc.driverClassName&#125;"/&gt; &lt;property name="jdbcUrl" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="user" value="$&#123;jdbc.username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt; &lt;/bean&gt; &lt;!--使用SqlSessionFactoryBean来代替SqlSessionFactoryBuilder创建SqlSessionFactory，&amp;ndash;&amp;gt;--&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!--加载MyBatis的配置文件--&gt; &lt;property name="configLocation" value="classpath:mybatis/mybatis_cfg.xml"/&gt; &lt;!--配置数据源--&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt;&lt;/beans&gt; 要点: 配置数据源 配置SqlSessionFactoryBean,用于创建SqlSessionFactory 配置mapper扫描器,用于将mapper自动加载出来 可以使用mybatis的逆向工程生成单表的mapper 还需要一个文件,mybatis的配置文件mybatis_cfg.xml,里面用于放置mybatis的运行环境 mybatis_cfg.xml: 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name="logImpl" value="LOG4J"/&gt; &lt;!-- 配置懒加载: lazyLoadingEnabled: 表示是否开启懒加载,true表示开启懒加载,默认为true aggressiveLazyLoading: 当它为true的时候,访问任何一个属性,都会触发查询,懒加载的对象也会被查询 当它为false的时候,你访问了非懒加载对象,他不会执行懒加载语句;直到你访问了懒加载对象,他才会进行加载 默认值为true lazyLoadTriggerMethods: 指定哪些对象的方法会触发一次延迟加载.默认有: equals,clone,hashCode,toString 当执行这些方法的时候,都会触发懒加载 --&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;setting name="aggressiveLazyLoading" value="false"/&gt; &lt;!--将触发懒加载的方法设成空--&gt; &lt;setting name="lazyLoadTriggerMethods" value="/"/&gt; &lt;!--开启二级缓存,默认就是true,可以不配置--&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;/settings&gt; &lt;!--批量设置别名--&gt; &lt;typeAliases&gt; &lt;package name="com.lee.ssm.model"/&gt; &lt;/typeAliases&gt; &lt;!--在Spring中开启组件扫描,所以这里不用配置了 注意:在Spring中自动扫描Mapper.xml和Mapper.java必须要满足文件名一致,并且在同一个目录下--&gt; &lt;!--&lt;mappers&gt;&lt;/mappers&gt;--&gt;&lt;/configuration&gt; 3.2 整合serviceBookService接口: 123public interface BookService &#123; List&lt;Book&gt; findAllBooks() throws Exception;&#125; BookService的实现类: 123456789101112131415161718192021222324252627public class BookServiceImpl implements BookService &#123; private BookMapper mBookMapper; public BookMapper getBookMapper() &#123; return mBookMapper; &#125; // 自动注入BookMapper,Spring会自动装配 @Autowired public void setBookMapper(BookMapper bookMapper) &#123; mBookMapper = bookMapper; &#125; /** * 查询所有的Book信息 * * @return * @throws Exception */ @Override public List&lt;Book&gt; findAllBooks() throws Exception &#123; BookExample bookExample = new BookExample(); List&lt;Book&gt; bookList = mBookMapper.selectByExample(bookExample); return bookList; &#125;&#125; 让spring管理我们的service,因此在applicationContext-service.xml中配置service的bean applicationContext-service.xml: 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt; &lt;!--book的Service--&gt; &lt;bean id="bookService" class="com.lee.ssm2.service.impl.BookServiceImpl"/&gt;&lt;/beans&gt; 3.3 事务控制service层负责事务管理. 为了是xml配置文件分工明确,这里可以另外分离出一个applicationContext-transaction.xml配置文件: applicationContext-transaction.xml: 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/tx/spring-aop.xsd"&gt; &lt;!--配置事务--&gt; &lt;!--第一步:配置事务管理器--&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;!--注意这个dataSource是引用自dao层映射文件中的--&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; &lt;!--第二步:配置事务增强--&gt; &lt;tx:advice id="tx_advice" transaction-manager="transactionManager"&gt; &lt;tx:attributes&gt; &lt;tx:method name="find*" propagation="REQUIRED"/&gt; &lt;tx:method name="insert*" propagation="REQUIRED"/&gt; &lt;tx:method name="select*" propagation="REQUIRED"/&gt; &lt;tx:method name="get*" propagation="REQUIRED"/&gt; &lt;tx:method name="load*" propagation="REQUIRED"/&gt; &lt;tx:method name="update*" propagation="REQUIRED"/&gt; &lt;tx:method name="modify*" propagation="REQUIRED"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!--第三步:配置切面--&gt; &lt;aop:config&gt; &lt;aop:pointcut id="book_pointcut" expression="execution(* com.lee.ssm2.service.*.*(..))"/&gt; &lt;aop:advisor advice-ref="tx_advice" pointcut-ref="book_pointcut"/&gt; &lt;/aop:config&gt;&lt;/beans&gt; 3.4 整合SpringMVC整合思路,一共有四个点: 配置前端控制器(在web.xml中) web.xml: 1234567891011121314151617181920&lt;!--前端控制器配置--&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--加载applicationContext-mvc配置文件--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!--配置文件的地址如果不配置contextConfigLocation，默认查找的配置文件名称是classpath下的:servlet名称+"-servlet.xml"即springmvc-servlet.xml--&gt; &lt;param-value&gt;classpath:spring/applicationContext-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;!-- 可以配置"/"此工程所有的请求全部由springmvc解析，此种方式可以实现RESTful方式，需要特殊处理对静态文件的解析不能由springmvc解析; 可以配置*.do或者*.action,所有请求的url扩展名为.do或.action由springmvc解析，此中方法常用; 不可以配置"/*",如果配置/*,返回jsp也由springmvc解析，这是不对的 --&gt; &lt;url-pattern&gt;*.action&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 配置处理器映射器(在applicationContext-mvc.xml中)(选择注解方式) 配置处理器适配器(在applicationContext-mvc.xml中)(选择注解方式) 配置视图解析器(在applicationContext-mvc.xml中) applicationContext-mvc.xml: 1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt; &lt;!--开启组件自动扫描--&gt; &lt;context:component-scan base-package="com.lee.ssm2.controller"/&gt; &lt;!--配置视图解析器--&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;!--prefix表示jsp路径的前缀，suffix表示jsp路径的后缀--&gt; &lt;!--在实际的controller中路径jsp/index.jsp就可以直接简化成index--&gt; &lt;!--通过该视图解析器的解析,会自动的拼接真正的视图路径--&gt; &lt;property name="prefix" value="/jsp"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt; &lt;!--================================================================================--&gt; &lt;!--使用注解的方式配置Handler以后,需要将处理器映射器和处理器适配器配置为以下的方式--&gt; &lt;!--配置处理器映射器--&gt; &lt;!--&lt;bean class=&quot;org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping&quot;/&gt;--&gt; &lt;!--配置处理器适配器--&gt; &lt;!--&lt;bean class=&quot;org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter&quot;/&gt;--&gt; &lt;!--一句话将处理器映射器和处理器配置器配置进来了,用来取代上面的两行代码--&gt; &lt;mvc:annotation-driven/&gt; 1234567891011121314151617181920212223242526## 3.5 装载Spring容器回顾:上面一共有四个Spring相关的配置文件* `applicationContext-dao.xml`* `applicationContext-service.xml`* `applicationContext-transaction.xml`* `applicationContext-mvc.xml`其中`applicationContext.mvc.xml`是SpringMVC的配置文件,他已经在配置前端控制器的时候作为配置参数传递进去了.而另外三个是Spring容器加载需要的配置文件,因此他们也需要在`web.xml`文件中进行配置,配置如下:​```xml&lt;!--加载Spring容器--&gt;&lt;!--指定Spring配置文件的位置--&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!--使用通配符的方式--&gt; &lt;param-value&gt;classpath:spring/applicationContext-*.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;!--配置Spring监听器--&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; 其中:ContextLoaderListener是Spring上下文加载时的监听器,当它读取到context-param参数的时候,就会在服务器启动的时候创建context-param配置文件中的bean.它和Struts整合的时候也是这么做的!!]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC使用非注解方式和注解方式]]></title>
    <url>%2F2017%2F05%2F09%2FSpring%E4%BD%BF%E7%94%A8%E9%9D%9E%E6%B3%A8%E8%A7%A3%E6%96%B9%E5%BC%8F%E5%92%8C%E6%B3%A8%E8%A7%A3%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Spring:SpringMVC 使用非注解方式和注解方式SpringMVC配置的组件众多,如果单纯的在xml文件中进行配置,需要配置处理器映射器,处理器适配器,处理器,处理器解析器.尤其是处理器的配置,并且还得指定处理器的name,才能完成请求地址到handler之间的映射.相比较于注解方式,注解方式实在是太麻烦了. 但是,我们还是先来看看两种配置方式的具体做法吧! 1.1 使用非注解方式1.1.1 处理器映射器使用BeanNameUrlHandlerMapping: 它能够完成Handler的bean的name和url之间的映射 12345678&lt;!--配置处理器映射器--&gt;&lt;!--根据url查找对应name值的Handler--&gt;&lt;bean class="org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping"/&gt;&lt;!--配置我们自定义的Handler(处理器)--&gt;&lt;!--它会被BeanNameUrlHandlerMapping类型的处理器映射器映射匹配,根据它的name值--&gt;&lt;bean name="/user.action" class="com.lee.ssm.controller.UserController"/&gt;&lt;bean name="/book.action" class="com.lee.ssm.controller.BookController"/&gt; 使用SimpleUrlHandlerMapping: 它可以批量完成Handler和url之间的映射 12345678910111213141516&lt;!--通过Handler的ID值完成url和Handler的映射--&gt;&lt;bean class="org.springframework.web.servlet.handler.SimpleUrlHandlerMapping"&gt; &lt;property name="mappings"&gt; &lt;props&gt; &lt;!--key是地址--&gt; &lt;!--值为Handler的ID--&gt; &lt;prop key="/user.action"&gt;userController&lt;/prop&gt; &lt;prop key="/book.action"&gt;bookController&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt;&lt;!--配置我们自定义的Handler(处理器)--&gt;&lt;!--它会被BeanNameUrlHandlerMapping类型的处理器映射器映射匹配,根据它的name值--&gt;&lt;bean name="/user.action" id="userController" class="com.lee.ssm.controller.UserController"/&gt;&lt;bean name="/book.action" id="bookController" class="com.lee.ssm.controller.BookController"/&gt; 上述两种方式都能完成url到handler的映射 1.1.2 处理器适配器 使用:SimpleControllerHandlerAdapter,它能够调用的Handler必须实现org.springframework.web.servlet.mvc包下的Controller接口 UserController处理器: 123456789101112public class UserController implements Controller &#123; @Override public ModelAndView handleRequest(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws Exception &#123; ModelAndView modelAndView = new ModelAndView(); // 设置模型数据,通过键值对的形式设置,在页面中就像从response中取数据一样取出来 modelAndView.addObject("msg", "Hello World!"); // 设置视图,这里设置了一个链接,相当于转发 modelAndView.setViewName("jsp/helloworld.jsp"); return modelAndView; &#125;&#125; SimpleControllerHanderAdapter的配置: 123&lt;!--配置处理器适配器--&gt;&lt;!--他只能适配Controller的实现类型的Controller--&gt;&lt;bean class="org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter"/&gt; 使用HttpRequestHandlerAdapter,他只能适配HttpRequestHandler实现类型的Controller OrdersController处理器: 123456789public class OrdersController implements HttpRequestHandler &#123; @Override public void handleRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // 接下来的开发像极了使用Servlet的原生开发 response.getWriter().print(getClass().getSimpleName() + ",hello!"); request.getRequestDispatcher("jsp/helloworld.jsp").forward(request, response); &#125;&#125; HttpRequestHandlerAdapter配置: 12&lt;!--他只能适配HttpRequestHandler实现类型的Controller--&gt;&lt;bean class="org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter"/&gt; 上面两种非注解的处理器适配器能够适配不同类型的Handler(也称作Controller) 使用注解的方式在applicationContext.xml中配置: 12345&lt;!--使用注解的方式配置Handler以后,需要将处理器映射器和处理器适配器配置为以下的方式--&gt;&lt;!--配置处理器映射器--&gt;&lt;bean class="org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping"/&gt;&lt;!--配置处理器适配器--&gt;&lt;bean class="org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter"/&gt; 或者使用: 1&lt;mvc:annotation-driven/&gt; 上面这一句就可以在Spring容器中自动的帮我们注册RequestMappingHandlerMapping和RequestMappingHandlerAdapter. 编写Controller类: 12345678910111213141516171819@Controllerpublic class FirstAnnoController &#123; // 可以放回很多中类型的值,这里选择返回ModelAndView,他将返回的结果交给视图解析器进行解析,然后返回给前端控制器 @RequestMapping("/firstanno.action") public ModelAndView request1() &#123; ModelAndView modelAndView = new ModelAndView(); // 设置模型数据,通过键值对的形式设置,在页面中就像从response中取数据一样取出来 modelAndView.addObject("msg", "Hello World!"); // 设置视图,这里设置了一个链接,相当于转发 modelAndView.setViewName("jsp/helloworld.jsp"); return modelAndView; &#125; @RequestMapping("/secondanno.action") public String request2() &#123; // redirect:表示重定向 return "redirect:/index.jsp";&#125; RequestMappingHandlerMapping能够完成url到该方法的映射.另外,FirstAnnoController中也可以配置多个方法,只要他们的@RequestMapping注解中value不一样就可以,这样一个Controller中可以实现多种功能. 另外:在applicationContext.xml中开启组件扫描,@Controller就能被自动扫描到并被Spring容器管理 测试:在浏览器中输入地址:http://localhost:8080/ssm/firstanno.action就能自动跳转到jsp/helloworld.jsp页面]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC入门(基本配置)]]></title>
    <url>%2F2017%2F05%2F09%2FSpringMVC%E5%85%A5%E9%97%A8(%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE)%2F</url>
    <content type="text"><![CDATA[Spring MVC 框架入门1.1 Spring MVC介绍SpringMVC和Struts2都属于表现层的框架，它是Spring框架的一个模块，提供web层解决方案，我们可以从Spring的整体结构中看得出来: 1.2 MVC在b/s系统的应用mvc是一个设计模式，在b/s系统的应用如图: 解释如下: 1.用户发起request请求至控制器(Controller),控制接收用户请求的数据，委托给模型(Model)进行处理。 2.控制器通过模型(Model)处理数据并得到处理结果，模型通常是指业务逻辑(jsp、dao、service)。 3.模型处理结果返回给控制器。 4.控制器将模型数据在视图(View)中展示，web中模型无法将数据直接在视图上显示，需要通过控制器完成。如果在C/S应用中模型是可以将数据在视图中展示的。 5.控制器将视图response响应给用户，通过视图展示给用户要的数据或处理结果。 1.3 Spring MVC 架构1.3.1 架构图 1.3.2 架构流程 用户发送请求至前端控制器DispatcherServlet DispatcherServlet收到请求调用HandlerMapping处理器映射器。 处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。 DispatcherServlet通过HandlerAdapter处理器适配器调用处理器 执行处理器(Controller，也叫后端控制器)。 Controller执行完成返回ModelAndView HandlerAdapter将controller执行结果ModelAndView返回 DispatcherServlet将ModelAndView传给ViewReslover视图解析器 ViewReslover解析后返回具体View DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中）。 DispatcherServlet响应用户 1.3.3架构中涉及的组件说明 DispatcherServlet：前端控制器。用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性。由框架实现 HandlerMapping：处理器映射器。HandlerMapping负责根据用户请求找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。由框架实现 Handler：处理器。Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。由于Handler涉及到具体的用户业务请求，所以一般情况需要程序员根据业务需求开发Handler。 HandlAdapter：处理器适配器。通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。由框架实现。 ViewResolver：视图解析器。ViewResolver负责将处理结果生成View视图，ViewResolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 springmvc框架提供了很多的View视图类型，包括：jstlView、freemarkerView、pdfView等。一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开发具体的页面。 1.4 入门程序(使用maven构建)需求 : 请求一个简单的静态页面 导入相关的jar包,Spring版本4.3.16.RELEASE 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;dependencies&gt; &lt;!-- Junit依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 导入java ee jar 包 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax&lt;/groupId&gt; &lt;artifactId&gt;javaee-api&lt;/artifactId&gt; &lt;version&gt;7.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--=================================================================--&gt; &lt;!--Spring核心依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--测试模块,能使用SpringJUnit4ClassRunner快速的实现单元测试--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--如果要整合mybatis,要加入orm和tx模块,并且mybatis的版本和mybatis-spring版本也要匹配--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--事务控制--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--web模块必须的包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringMVC模块--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 1.4.1 前端控制器配置(web.xml)1234567891011121314151617181920212223&lt;!--====================================前端控制器配置=====================================--&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--加载springmvc配置文件--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!--配置文件的地址 如果不配置contextConfigLocation，默认查找的配置文件名称是classpath下的:servlet名称+"-servlet.xml" 即springmvc-servlet.xml--&gt; &lt;param-value&gt;classpath:spring/applicationContext.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;!--可以配置"/"此工程所有的请求全部由springmvc解析，此种方式可以实现RESTful方式， 需要特殊处理对静态文件的解析不能由springmvc解析; 可以配置*.do或者*.action,所有请求的url扩展名为.do或.action由springmvc解析，此中方法常用; 不可以配置"/*",如果配置/*,返回jsp也由springmvc解析，这是不对的--&gt; &lt;url-pattern&gt;*.action&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 1.4.2 配置SpringMVC三大组件 –处理器映射器、处理器适配器、视图解析器简介： 处理器映射器：根据前端传来的url匹配正确的处理器，并返回给前端控制器 处理器适配器：能够调用不同类别的处理器来执行任务 视图解析器：视图解析 1.4.2.1 处理器映射器对于用户发起的request请求，前端控制器首先会请求HandlerMapping处理器映射器来查找Handler 在applicationContext.xml配置文件中: 123&lt;!--配置处理器映射器--&gt;&lt;!--根据url查找对应id值的Handler--&gt;&lt;bean class="org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping"/&gt; 1.4.2.2 处理器适配器处理器适配器有不同类型的,他们可以去调用不同类别的Handler来完成任务,如下方的,让Handler去实现Controller接口,这样,SimpleControllerHandlerAdapter会调用这个类别的处理器去执行任务 123&lt;!--配置处理器适配器--&gt; &lt;!--他只能适配Controller的实现类型的Controller--&gt; &lt;bean class="org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter"/&gt; 1.4.2.3 视图解析器12&lt;!--配置视图解析器--&gt;&lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"/&gt; 1.4.2.4 处理器编写与配置处理器是根据你的业务需求需要我们自己来编写的,你可以选择实现不同类型的处理器,他们做了不同程度的封装. 这里我们实现Controller接口,这样他就能被SimpleControllerHandlerAdapter适配器适配,同时又能根据它的name值被BeanNameUrlHandlerMapping映射器找到,从而将相应的请求传入对应的Handler中 123456789101112public class UserController implements Controller &#123; @Override public ModelAndView handleRequest(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws Exception &#123; ModelAndView modelAndView = new ModelAndView(); // 设置模型数据,通过键值对的形式设置,在页面中就像从response中取数据一样取出来 modelAndView.addObject("msg", "Hello World!"); // 设置视图,这里设置了一个链接,相当于转发 modelAndView.setViewName("jsp/helloworld.jsp"); return modelAndView; &#125;&#125; 处理器也作为一个组件,需要在applicationContext.xml进行配置 123&lt;!--配置我们自定义的Handler(处理器)--&gt;&lt;!--它会被BeanNameUrlHandlerMapping类型的处理器映射器映射匹配,根据它的name值--&gt;&lt;bean name="/helloworld.action" class="com.lee.ssm.controller.UserController"/&gt; 至此配置完毕,当在浏览器的地址栏中输入:http://localhost:8080/ssm/helloworld.action的时候,最终会显示jsp/helloworld.jsp页面中的内容(在我们的处理器UserController中设置了modelAndView.setViewName(&quot;jsp/helloworld.jsp&quot;);) 流程是这样的: http://localhost:8080/ssm/helloworld.action 处理器映射器查找name名称为helloworld.action的处理器,并且返回给前端控制器,也就是返回了UserController 前端控制器将UserController交给处理器适配器 处理器适配器判断UserController的类型,看自己能不能调用执行(我们配置的处理器适配器有SimpleControllerHandlerAdapter,所以他能执行,SimpleControllerHandlerAdapter是专门执行调用Controller接口实现类型的Controller) 处理器适配器执行Handler Handler返回ModelAndView给前端控制器 前端控制器调用InternalResourceViewResolver视图解析器进行解析,并将解析后的view返回给前端控制器 前端控制器渲染视图,响应给客户端(浏览器) 在上面的配置过程中我们分别配置了处理器映射器,处理器适配器,视图解析器,当我们把这三个注释掉,他依然能够完成请求的响应,也就是说,依然能能够完成请求的映射执行,这是为什么呢? 对于前端控制器DispatcherServlet,我有必要多说几句，在spring-webmvc.jar包中有一个DispatcherServlet.properties文件，内容如下: 里面包含一些默认的组件例如处理器映射器、处理器适配器等，当程序启动时，DispatcherServlet会自动加载DispatcherServlet.properties配置文件，从而默认加载各个组件，所以如果我们在springmvc.xml中配置了处理器映射器和处理器适配器，那程序就以springmvc.xml中的配置信息为主。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH项目搭建记录(基于Maven)]]></title>
    <url>%2F2017%2F04%2F26%2FSSH%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[框架版本选择 spring:4.3.16 struts2:2.5.16 hibernate:5.2.16]]></content>
      <tags>
        <tag>学习日记</tag>
        <tag>Hibernate</tag>
        <tag>Struts2</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring实战》（第四版）读书笔记]]></title>
    <url>%2F2017%2F04%2F21%2F%E3%80%8ASpring%E5%AE%9E%E6%88%98%E3%80%8B%EF%BC%88%E7%AC%AC%E5%9B%9B%E7%89%88%EF%BC%89%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第1章 Spring之旅两大核心 依赖注入(Dependency injection,DI) 面向切面编程(aspect-oriented-programming,AOP) 发展历程: 创建Spring的主要目的是用来替代更加重量级的企业级Java技术，尤其是EJB。相对于EJB说,Spring提供了更加轻量级和简单的编程模型。它增强了简单老式Java对象（Plain Old Java object，POJO）的功能，使其具备了之前只有EJB和其他企业级Java规范才具有的功能。 随着时间的推移，EJB以及Java 2企业版（Java 2 Enterprise Edition，J2EE）在不断演化。EJB自身也提供了面向简单POJO的编程模型。现在，EJB也采用了依赖注入（Dependency Injection，DI）和面向切面编程（Aspect-Oriented Programming，AOP）的理念，这毫无疑问是受到Spring成功的启发。 尽管J2EE（现在称之为JEE）能够赶上Spring的步伐，但Spring也没有停止前进。Spring继续在其他领域发展，而JEE则刚刚开始涉及这些领域，或者还完全没有开始在这些领域的创新。移动开发、社交API集成、NoSQL数据库、云计算以及大数据都是Spring正在涉足和创新的领域。Spring的前景依然会很美好。 1.1 简化Java开发为了降低Java开发的复杂性,Spring采取了下面四种关键性策略 基于POJO的轻量级和最小侵入性编程； 通过依赖注入和面向接口实现松耦合； 基于切面和惯例进行声明式编程； 通过切面和模板减少样板式代码。 POJO:plain old java object,简单老实Java对象。使用POJO名称是为了避免和EJB混淆起来, 而且简称比较直接. 其中有一些属性及其getter setter方法的类,没有业务逻辑，有时可以作为VO(value -object)或dto(Data Transform Object)来使用.当然,如果你有一个简单的运算属性也是可以的,但不允许有业务方法,也不能携带有connection之类的方法。 1.1.1 基于POJO的轻量级和最小侵入性编程侵入式框架：框架通过强迫应用继承它们的类或实现它们的接口从而导致应用与框架绑死。例如：struts框架。 非侵入式框架：不会强迫的让你继承框架提供的类或者接口，你一样可以使用，简而言之，拿来即用，不用去修改你原来的代码。例如：Hibernate框架，Spring框架等等。 1.1.2 通过依赖注入和面向接口实现松耦合Spring通过应用上下文（Application Context）装载bean的定义并把它们组装起来。Spring应用上下文全权负责对象的创建和组装。Spring自带了多种应用上下文的实现，它们之间主要的区别仅仅在于如何加载配置。 1.1.3 基于切面和惯例进行声明式编程（应用切面）面向切面编程（aspect-oriented programming，AOP）允许你把遍布应用各处的功能分离出来形成可重用的组件。 面向切面编程往往被定义为促使软件系统实现关注点的分离一项技术。系统由许多不同的组件组成，每一个组件各负责一块特定功能。除了实现自身核心的功能之外，这些组件还经常承担着额外的职责。诸如日志、事务管理和安全这样的系统服务经常融入到自身具有核心业务逻辑的组件中去，这些系统服务通常被称为横切关注点，因为它们会跨越系统的多个组件。 横切关注点 ：这些系统服务通常被称为横切关注点，因为他们会跨越系统的多个组件 如果将这些关注点分散到多个组件中去，你的代码将会带来双重的复杂性。 实现系统关注点功能的代码将会重复出现在多个组件中。这意味着如果你要改变这些关注点的逻辑，必须修改各个模块中的相关实现。即使你把这些关注点抽象为一个独立的模块，其他模块只是调用它的方法，但方法的调用还是会重复出现在各个模块中。组件会因为那些与自身核心业务无关的代码而变得混乱。一个向地址簿增加地址条目的方法应该只关注如何添加地址，而不应该关注它是不是安全的或者是否需要支持事务。 使用AOP的好处： 借助AOP，可以使用各种功能层去包裹核心业务层。这些层以声明的方式灵活地应用到系统中，你的核心应用甚至根本不知道它们的存在。这是一个非常强大的理念，可以将安全、事务和日志关注点与核心业务逻辑相分离。 1.1.4 使用模板消除样板式代码Spring旨在通过模板封装来消除样板式代码。例如：Spring的JdbcTemplate使得执行数据库操作时，避免传统的JDBC样板代码成为了可能。（例如：在使用JDBC操作数据库的时候，需要关闭数据库连接，关闭Statement，关闭ResultSet等等这些都是重复性的代码，使用模板将这些重复性的代码封装到了模板中） 1.2 Spring容器简单来说就是装JavaBean的容器，统一管理，按需装配（使用依赖注入的方式）。 它是Spring框架的核心。Spring容器使用DI管理构成应用的组件，它会创建相互协作的组件之间的关联。毫无疑问，这些对象更简单干净，更易于理解，更易于重用并且更易于进行单元测试。 Spring容器分为两种类型： Bean工厂 实现org.springframework. beans.factory.BeanFactory接口，是最简单的容器，提供基本的DI支持. 应用上下文 (ApplicationContext) 实现org.springframework.context.ApplicationContext接口,它是基于Bean工厂实现的,并提供应用框架级别的服务，例如从属性文件解析文本信息以及发布应用事件给感兴趣的事件监听者。 Bean工厂功能态单一,所以大多数选用ApplicationContext 1.2.1 使用应用上下文常用的应用上下文: AnnotationConfigApplicationContext：从一个或多个基于Java的配置类中加载Spring应用上下文。 AnnotationConfigWebApplicationContext：从一个或多个基于Java的配置类中加载Spring Web应用上下文。 ClassPathXmlApplicationContext：从类路径下的一个或多个XML配置文件中加载上下文定义，把应用上下文的定义文件作为类资源。 FileSystemXmlapplicationcontext：从文件系统下的一个或多个XML配置文件中加载上下文定义。 XmlWebApplicationContext：从Web应用下的一个或多个XML配置文件中加载上下文定义。 使用FileSystemXmlApplicationContext和使用ClassPathXmlApp-licationContext的区别在于：FileSystemXmlApplicationContext在指定的文件系统路径下查找bean.xml文件；而ClassPathXmlApplicationContext是在所有的类路径（包含JAR文件）下查找 bean.xml文件。 这里需要注意的是:使用 “classpath*:”和”classpath:”的区别 1.2.2 Bean的生命周期 1．Spring对bean进行实例化； 2．Spring将值和bean的引用注入到bean对应的属性中； 3．如果bean实现了BeanNameAware接口，Spring将bean的ID传递给setBean-Name()方法； 4．如果bean实现了BeanFactoryAware接口，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入； 5．如果bean实现了ApplicationContextAware接口，Spring将调用setApplicationContext()方法，将bean所在的应用上下文的引用传入进来； 6．如果bean实现了BeanPostProcessor接口，Spring将调用它们的post-ProcessBeforeInitialization()方法； 7．如果bean实现了InitializingBean接口，Spring将调用它们的after-PropertiesSet()方法。类似地，如果bean使用initmethod声明了初始化方法，该方法也会被调用； 8．如果bean实现了BeanPostProcessor接口，Spring将调用它们的post-ProcessAfterInitialization()方法； 9．此时，bean已经准备就绪，可以被应用程序使用了，它们将一直驻留在应用上下文中，直到该应用上下文被销毁； 10．如果bean实现了DisposableBean接口，Spring将调用它的destroy()接口方法。同样，如果bean使用destroy-method声明了销毁方法，该方法也会被调用。 1.3 Spring模块1.4 Spring新方向 Spring Boot 1.5 小节 Spring致力于简化开发,方便维护,其核心是依赖注入和面向切面编程 依赖注入,也叫作控制反转。正常情况下类中需要用到的组件都是需要使用自己去new，相当于控制正转。但是它的耦合性太高，不利于维护和测试。而控制反转是我们需要什么组件外界使用我们的时候自己传进来，例如可以通过set方法或者构造器传入。这样，依赖的对象可以有使用者自己去扩展，实现了松耦合。而依赖注入正是控制反转的一种实现。另一方面，使用Spring的依赖注入核心功能使得对象的管理更加清晰。 面向切面编程（AOP），是将散落的逻辑，例如日志（在Spring中称作关注点），事务等等，这些功能也不得不使用，将这些逻辑汇聚在一起，形成一个面，也就是一个独立的模块，这样讲这些与核心业务逻辑类分离。一方面能够减少业务逻辑类中的代码量，使其专注自己的逻辑。 AOP可以帮助应用将散落在各处的逻辑汇集于一处——切面。当Spring装配bean的时候，这些切面能够在运行期编织起来，这样就能非常有效地赋予bean新的行为。 第2章 装配Bean（Bean的配置与获取） 在Spring中，对象无需自己查找或创建与其所关联的其他对象。相反，容器负责把需要相互协作的对象引用赋予各个对象。例如，一个订单管理组件需要信用卡认证组件，但它不需要自己创建信用卡认证组件。订单管理组件只需要表明自己两手空空，容器就会主动赋予它一个信用卡认证组件。 创建应用对象之间协作关系的行为通常称为装配（wiring），这也是依赖注入（DI）的本质。 2.1 Spring容器的配置方式 在XML中进行显式配置。 在Java中进行显式配置。 隐式的bean发现机制和自动装配。 关于三种配置方式的选择问题: 选择自己喜欢的或者项目适合的配置方式。 搭配配置也是可以的 我的建议是尽可能地使用自动配置的机制。显式配置越少越好。当你必须要显式配置bean的时候（比如，有些源码不是由你来维护的，而当你需要为这些代码配置bean的时候），我推荐使用类型安全并且比XML更加强大的JavaConfig。最后，只有当你想要使用便利的XML命名空间，并且在JavaConfig中没有同样的实现时，才应该使用XML。 未完待续… 第4章 面向切面的Spring(Spring中的AOP) 软件系统中的一些功能就像我们家里的电表一样。这些功能需要用到应用程序的多个地方，但是我们又不想在每个点都明确调用它们。日志、安全和事务管理的确都很重要，但它们是否为应用对象主动参与的行为呢？如果让应用对象只关注于自己所针对的业务领域问题，而其他方面的问题由其他应用对象来处理，这会不会更好呢？ 在软件开发中，散布于应用中多处的功能被称为横切关注点（crosscuttingconcern）。通常来讲，这些横切关注点从概念上是与应用的业务逻辑相分离的（但是往往会直接嵌入到应用的业务逻辑之中）。把这些横切关注点与业务逻辑相分离正是面向切面编程（AOP）所要解决的问题。 理解：各司其职，例如日志功能呢，虽然我们希望日志系统能够很好的帮我们记日志，但是日志系统的主要工作范畴。他就像财务，是替我们记账的。横切关注点串联起来，可以形成一个完整的面，该面相当于一个分布于应用中的微型系统。例如，日志，错误处理，事务管理等等。 DI有助于应用对象之间的解耦，而AOP可以实现横切关注点与它们所影响的对象之间的解耦。 4.1 什么是面向切面编程Spring切面的实现原理 切面提供了取代继承和委托的另一种可选方案，而且在很多场景下更清晰简洁。在使用面向切面编程时，我们仍然在一个地方定义通用功能，但是可以通过声明的方式定义这个功能要以何种方式在何处应用，而无需修改受影响的类。**横切关注点可以被模块化为特殊的类，这些类被称为切面（aspect）。 这样做有两个好处：首先，现在每个关注点都集中于一个地方，而不是分散到多处代码中；其次，服务模块更简洁，因为它们只包含主要关注点（或核心功能）的代码，而次要关注点的代码被转移到切面中了。 4.1.1 AOP相关术语 通知（Advice）–也叫增强 通知定义了切面是什么以及何时使用。除了描述切面要完成的工作，通知还解决了何时执行这个工作的问题。它应该应用在某个方法被调用之前？之后？之前和之后都调用？还是只在方法抛出异常时调用？ Spring切面可以应用5种类型的通知： 前置通知（Before）：在目标方法被调用之前调用通知功能； 后置通知（After）：在目标方法完成之后调用通知，此时不会关心方法的输出是什么； 连接点（Join point） 我们的应用可能也有数以千计的时机应用通知。这些时机被称为连接点。连接点是在应用执行过程中能够插入切面的一个点。这个点可以是调用方法时、抛出异常时、甚至修改一个字段时。切面代码可以利用这些点插入到应用的正常流程之中，并添加新的行为。 简单理解就是:所有可以被增强的方法 ​ 切点（Poincut） 如果说通知定义了切面的“什么”和“何时”的话，那么切点就定义了“何处”。切点的定义会匹配通知所要织入的一个或多个连接点。我们通常使用明确的类和方法名称，或是利用正则表达式定义所匹配的类和方法名称来指定这些切点。有些AOP框架允许我们创建动态的切点，可以根据运行时的决策（比如方法的参数值）来决定是否应用通知。 简单理解:可以被增强的方法有很多个,但是并不是所有的方法都需要被增强,从连接点中选取一部分必要的方法来增强.切点是连接点的子集。 切面（Aspect） 切面是通知和切点的结合。通知和切点共同定义了切面的全部内容——它是什么，在何时和何处完成其功能。 简单理解：切面就是通知（增强）和切点编织在一起。他知道在哪里应用增强以及增强的内容。例如：在管理员往数据库中插入一条记录的时候就将插入记录的相关细节记录到日志中去。 引入（Introduction） 引入允许我们向现有的类添加新方法或属性。例如，我们可以创建一个Auditable通知类，该类记录了对象最后一次修改时的状态。这很简单，只需一个方法，setLastModified(Date)，和一个实例变量来保存这个状态。然后，这个新方法和实例变量就可以被引入到现有的类中，从而可以在无需修改这些现有的类的情况下，让它们具有新的行为和状态。 织入（Weaving） 织入是把切面应用到目标对象并创建新的代理对象的过程。切面在指定的连接点被织入到目标对象中。在目标对象的生命周期里有多个点可以进行织入： 编译期：切面在目标类编译时被织入。这种方式需要特殊的编译器。AspectJ的织入编译器就是以这种方式织入切面的。 类加载期：切面在目标类加载到JVM时被织入。这种方式需要特殊的类加载器（ClassLoader），它可以在目标类被引入应用之前增强该目标类的字节码。AspectJ 5的加载时织入（load-timeweaving，LTW）就支持以这种方式织入切面。 运行期：切面在应用运行的某个时刻被织入。一般情况下，在织入切面时，AOP容器会为目标对象动态地创建一个代理对象。Spring AOP就是以这种方式织入切面的。 简单理解：创建切面的过程 4.1.2 Spring对AOP的支持Spring提供了4种类型的AOP支持： 基于代理的经典Spring AOP； 纯POJO切面； @AspectJ注解驱动的切面； 注入式AspectJ切面（适用于Spring各版本）。 前三种都是Spring AOP实现的变体，Spring AOP构建在动态代理基础之上，因此，Spring对AOP的支持局限于方法拦截。 Spring中AOP的特点: Spring在运行时,也就是说当真正的需要被代理的对象时,才创建代理对象.即运行时织入. Spring只支持方法级别的连接点.不支持字段和构造器接入点. 但是方法拦截可以满足绝大部分的需求。如果需要方法拦截之外的连接点拦截功能，那么我们可以利用Aspect来补充Spring AOP的功能。 在Spring AOP中，要使用AspectJ的切点表达式语言来定义切点。 关于Spring AOP的AspectJ切点，最重要的一点就是Spring仅支持AspectJ切点指示器（pointcut designator）的一个子集 4.2 编写切点例如: execution(* com.lee.aop.LeeDao.*(..)) 说明: 第一个*代表返回任意类型 第二个*代表匹配LeeDao类中的所有的方法 (..)代表任意的参数 除了execution之外还有以下这些AspectJ指示器 arg() 限制连接点匹配参数为指定类型的执行方法 @args()限制连接点匹配参数由指定注解标注的执行方法 例如: execution(* com.lee.aop.LeeDao.findById(int)) &amp;&amp; args(num)表示当调用findById的时候传入的参数同时会传入到通知方法中去,此时通知方法可以在方法参数列表中指定一个参数用来接收这个参数,必须要保证通知方法参数列表中的参数名称和num名称一致 execution() 用于匹配是连接点的执行方法 this()限制连接点匹配AOP代理的bean引用为指定类型的类 target 限制连接点匹配目标对象为指定类型的类 @target() 限制连接点匹配特定的执行对象，这些对象对应的类要具有指定类型的注解 within() 限制连接点匹配指定的类型 @within() 限制连接点匹配指定注解所标注的类型（当使用Spring AOP时，方法定义在由指定的注解所标注的类里） @annotation 限定匹配带有指定注解的连接点 Spring还引入了一个新的bean()指示器，它允许我们在切点表达式中使用bean的ID来标识bean。bean()使用bean ID或bean名称作为参数来限制切点只匹配特定的bean。 例如:execution(* com.lee.aop.LeeDao. *(..)) and bean(&quot;leeDao1&quot;)表示限定的bean的ID为leeDao1 使用示例: execution(* com.lee.aop.LeeDao. *(..)) &amp;&amp; within(com.lee.*) 解释:&amp;&amp; 表示逻辑与.还有!,表示非.||表示或.响应的都可以使用and,not,or来代替 ​ within表示限制切点仅仅匹配com.lee包下的 4.3 使用注解创建切面在类上进行标注: @Aspect: 代表该类不仅是一个POJO类,还是一个切面 在方法上进行标注:代表他们是通知(增强) @After 通知方法会在目标方法返回或抛出异常后调用 @AfterReturning 通知方法会在目标方法返回后调用 @AfterThrowing 通知方法会在目标方法抛出异常后调用 @Around 通知方法会将目标方法封装起来 @Before 通知方法会在目标方法调用之前执行 @Pointcut 定义一个公用的切点 需要注意的是@Around环绕通知的使用方法 关于这个新的通知方法，你首先注意到的可能是它接受ProceedingJoinPoint作为参数。这个对象是必须要有的，因为你要在通知中通过它来调用被通知的方法。通知方法中可以做任何的事情，当要将控制权交给被通知的方法时，它需要调用ProceedingJoinPoint的proceed()方法。 ​ ** 通过注解引入新的功能: 一些编程语言，例如Ruby和Groovy，有开放类的理念。它们可以不用直接修改对象或类的定义就能够为对象或类增加新的方法。不过，Java并不是动态语言。一旦类编译完成了，我们就很难再为该类添加新的功了。 实现方法 12345678@Aspectpublic class FoodFruitAppleAspect &#123; // value代表那种类型的bean需要引入新的接口,这里Fruit的子类将会引入新的接口 // defaultImpl代表引入新的功能的实现类 @DeclareParents(value = "com.lee.aop.aopjoinnewfunction.Fruit+", defaultImpl = FoodImpl.class) public static Food sFood;&#125; 在xml中配置 12345678&lt;bean id="myApple" class="com.lee.aop.aopjoinnewfunction.Apple"/&gt;&lt;!--在FoodFruitAppleAspect类中已经声明它作为一个切面,当Spring发现一个bean使用了@Aspect注解时，Spring就会创建一个代理，然后将调用委托给被代理的bean或被引入的实现，这取决于调用的方法属于被代理的bean还是属于被引入的接口。--&gt;&lt;bean id="foodFruitAppleAspect" class="com.lee.aop.aopjoinnewfunction.FoodFruitAppleAspect"/&gt; 使用: 1234567public void test1() &#123; ApplicationContext context = new ClassPathXmlApplicationContext("com/lee/aop/aopjoinnewfunction/NewApple.xml"); // 虽然MyApple是一个Fruit的实现类,并没有显示的实现了Food接口,但是通过AOP切面的形式创建了代理 类,该代理类在运行时创建了代理对象 // 该代理对象融合了新的功能 Food food = (Food) context.getBean("myApple"); food.canEat();&#125; 4.4 在xml中生命切面略 4.5 注入AspectJ切面上面的切面是Spring AOP的变体. 虽然Spring AOP能够满足许多应用的切面需求，但是与AspectJ相比，Spring AOP 是一个功能比较弱的AOP解决方案。AspectJ提供了SpringAOP所不能支持的许多类型的切点。 例如，当我们需要在创建对象时应用通知，构造器切点就非常方便。不像某些其他面向对象语言中的构造器，Java构造器不同于其他的正常方法。这使得Spring基于代理的AOP无法把通知应用于对象的创建过程。 对于大部分功能来讲，AspectJ切面与Spring是相互独立的。虽然它们可以织入到任意的Java应用中，这也包括了Spring应用，但是在应用AspectJ切面时几乎不会涉及到Spring。 第10章 通过Spring和JDBC征服数据库 SQLException的问题在于捕获到它的时候该如何处理。事实上，能够触发SQLException的问题通常是不能在catch代码块中解决的。大多数抛出SQLException的情况表明发生了致命性错误。如果应用程序不能连接到数据库，这通常意味着应用不能继续使用了。类似地，如果查询时出现了错误，那在运行时基本上也是无能为力。 SQLException并查看其属性才能获知问题根源的更多信息。这是因为SQLException被视为处理数据访问所有问题的通用异常。对于所有的数据访问问题都会抛出SQLException，而不是对每种可能的问题都会有不同的异常类型。 一方面，JDBC的异常体系过于简单了——实际上，它算不上一个体系。另一方面，Hibernate的异常体系是其本身所独有的。我们需要的数据访问异常要具有描述性而且又与特定的持久化框架无关。 Spring所提供的平台无关的持久化异常 Spring JDBC提供的数据访问异常体系解决了以上的两个问题。不同于JDBC，Spring提供了多个数据访问异常，分别描述了它们抛出时所对应的问题。表10.1对比了Spring的部分数据访问异常以及JDBC所提供的异常。 10.2 访问数据源10.2.1 使用JNDI配置数据源(略) 10.2.2 使用数据源连接池常见的有DBCP,c3p0等,配置上大体相同 10.2.5 使用profile选择数据源 实际上，我们很可能面临这样一种需求，那就是在某种环境下需要其中一种数据源，而在另外的环境中需要不同的数据源。 例如，对于开发期来说，jdbc:embedded-database元素是很合适的，而在QA环境中，你可能希望使用DBCP的BasicDataSource，在生产部署环境下，可能需要使用jee:jndi-lookup。 借助Spring的profile特性能够在运行时选择数据源 10.3 在Spring中使用JDBC JDBC不要求我们掌握其他框架的查询语言。它是建立在SQL之上的，而SQL本身就是数据访问语言。此外，与其他的技术相比，使用JDBC能够更好地对数据访问的性能进行调优。JDBC允许你使用数据库的所有特性，而这是其他框架不鼓励甚至禁止的。 再者，相对于持久层框架，JDBC能够让我们在更低的层次上处理数据，我们可以完全控制应用程序如何读取和管理数据，包括访问和管理数据库中单独的列。这种细粒度的数据访问方式在很多应用程序中是很方便的。例如在报表应用中，如果将数据组织为对象，而接下来唯一要做的就是将其解包为原始数据，那就没有太大意义了。 理解:很多时候我们先将基本的功能实现了,再考虑优化问题,提高性能等.而使用持久层框架,它们帮我们做了很多封装,会隐藏很多细节,这样有针对性的优化就会付出很多成本. 首先使代码正确的运行,然后再提高代码的速度. 摘自《Java并发编程实战》]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring加载resource时classpath*:与classpath:的区别]]></title>
    <url>%2F2017%2F04%2F21%2FSpring%E5%8A%A0%E8%BD%BDresource%E6%97%B6classpath%2F</url>
    <content type="text"><![CDATA[Spring加载context配置文件是从classpath加载进来的。 What is classpath? 就是.java文件存放的根路径,在intellij中是src目录 我们也可以将配置文件单独放在一个文件夹下,例如resources文件夹,该文件夹和src目录是同级的. 怎么创建这个文件夹呢? 现在项目中创建一个和src同级的directory,名为resources 右键该resources,然后make Directory As,然后选择Source Root 此时你会发现该文件夹变颜色了,和src是一样的颜色 同时你也可以查看项目的配置问价yourproject.xml,例如,我的是这样的: 12345678910111213141516171819202122232425262728&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;module type="JAVA_MODULE" version="4"&gt; &lt;component name="FacetManager"&gt; &lt;facet type="Spring" name="Spring"&gt; &lt;configuration /&gt; &lt;/facet&gt; &lt;/component&gt; &lt;component name="NewModuleRootManager" inherit-compiler-output="true"&gt; &lt;exclude-output /&gt; &lt;content url="file://$MODULE_DIR$"&gt; &lt;sourceFolder url="file://$MODULE_DIR$/src" isTestSource="false" /&gt; &lt;sourceFolder url="file://$MODULE_DIR$/sources" isTestSource="false" /&gt; &lt;/content&gt; &lt;orderEntry type="inheritedJdk" /&gt; &lt;orderEntry type="sourceFolder" forTests="false" /&gt; &lt;orderEntry type="library" name="Spring-4.3.16.RELEASE" level="project" /&gt; &lt;orderEntry type="module-library"&gt; &lt;library name="JUnit4"&gt; &lt;CLASSES&gt; &lt;root url="jar://$APPLICATION_HOME_DIR$/lib/junit-4.12.jar!/" /&gt; &lt;root url="jar://$APPLICATION_HOME_DIR$/lib/hamcrest-core-1.3.jar!/" /&gt; &lt;/CLASSES&gt; &lt;JAVADOC /&gt; &lt;SOURCES /&gt; &lt;/library&gt; &lt;/orderEntry&gt; &lt;/component&gt;&lt;/module&gt; 其中可以清楚的看到src目录和sources都是sourceFolder classpath*:和classpath:到底有什么区别呢? 你先想想*通常用来是干嘛用的? 是不是通配符? classpath*: 就是从多个jar文件,包括你自己的项目src目录下(src目录作为sourceroot)加载指定的问价,比如: 12ApplicationContext context = new ClassPathXmlApplicationContext("classpath*:/bean.xml");// 其中斜杠表示sourceroot的根目录(也可以不写), 它从所有的classpath中查找这个bean.xml文件,所有符合条件的bean.xml文件都被加载进来了 classpath: 如果存在多个满足条件的,第一个加载到了,就不管了 参考: Spring加载resource时classpath*:与classpath:的区别 更多内容请点开上面的链接]]></content>
      <categories>
        <category>JavaEE</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JPA概念解析-关联关系的维护]]></title>
    <url>%2F2017%2F04%2F13%2FJPA%E6%A6%82%E5%BF%B5%E8%A7%A3%E6%9E%90-%E5%85%B3%E8%81%94%E5%85%B3%E7%B3%BB%E7%9A%84%E7%BB%B4%E6%8A%A4%2F</url>
    <content type="text"><![CDATA[JPA中的关联关系的维护数据库中的表之间一般有三种关系:一对一、一对多、多对多。 上面的三种关系都有主从表之分:例如 一对一 客户表(cst_customer)和客户详情表(cst_info)：是先有的客户表，再有的客户详情表,因此客户表是主表，详情表是从表 一对多 房东表（landlord）和租户表（tenant）：是先有的房东表然后才有的租户表，房东表是主表，租户表是从表 多对多 老师表（teacher）和学生表（student）：是先有的老师表，才有的学生，所以老师表是主表，学生表是从表 上面的分析只是从生活实际出发，因为从生活实际出发，这样就更好理解主表和从表之间的关系了。 从上面三种表关系的举例中，不知道大家有没有发现一个共同特点：主表相当于一个leader，二从表就是一个follower，似乎follower更关心它和leader之间的关系。 而在使用JPA时，把维护表之间关系的权利交给谁呢? 肯定是交给follower啦!! 举例:(teacher和student,多对多关系) 老师表实体类: 1234567891011121314151617181920212223242526@Entity // 指定这是一个实体类.在创建EntityManagerFactory的时候就会读取映射配置@Table(name = "hb_teacher") // 指定该表所在数据库中的表名public class Teacher &#123; @Id // 主键 @GeneratedValue(strategy = GenerationType.IDENTITY) // 主键生成策略 @Column(name = "t_id") // 主键在数据库中对应的字段名 private Long tid; @Column(name = "t_name") private String tname; @Column(name = "t_age") private String tage; // targetEntity:映射的另一方实体的类 // mappedBy : 生命关系的维护方(也就是说放弃了维护关联关系的权利) @ManyToMany(targetEntity = Student.class,mappedBy = "teachers") private Set&lt;Student&gt; students = new HashSet&lt;&gt;(0); public Teacher() &#123; &#125; // 省略get/set方法,省略toString方法&#125; 老师放弃了维护表之间关系的权利,通过设定mappedBy = &quot;teachers&quot; 学生表实体类: 1234567891011121314151617181920212223242526272829303132@Entity@Table(name = "hb_student")public class Student &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = "s_id") private Long sid; @Column(name = "s_name") private String sname; @Column(name = "s_age") private String sage; @ManyToMany(targetEntity = Teacher.class,cascade = CascadeType.ALL) @JoinTable( name = "stu_tea_ref", // 中间表的表名 joinColumns = &#123; // 指定自己一方在表中维护的字段.name:字段名;referencedColumnName:关联的字段名称 @JoinColumn(name = "stu_id", referencedColumnName = "s_id") &#125;, inverseJoinColumns = &#123; // 指定对方在表中维护的字段.name:字段名;referencedColumnName:关联的字段的名称 @JoinColumn(name = "tea_id", referencedColumnName = "t_id") &#125; ) private Set&lt;Teacher&gt; teachers = new HashSet&lt;&gt;(0); public Student() &#123; &#125; // 省略get/set方法,省略toString方法&#125; 学生表维护了和老师表之间的关联关系,你看看它设置了那么多的字段,自己和老师在中间表中的字段都是自己负责设置的,通过设置字段joinColumns和inverseJoinColumns来指定。 实际上本应该就是这样，老师比少，学生比较多，让一个老师记住他教的所有的学生是很困难的，而把这个任务交个学生就相对简单多啦。 接下来，看看这样几种场景： 删除teacher表中的一条记录，如果该记录被中间表引用，能不能删除呢？ 答案是：如果没有设置级联删除，这个记录是不能删除的。试想他能删除，它删除以后，中间表中的数据怎么办，因为它是没有权利维护表关系的。 删除student表中的一条记录，如果该记录被中间表引用，能不能删除呢？ 答案是：是可以删除的。他删除以后，会连同中间表中和自己相关的数据也删除掉。因为它负责维护量表之间的关系！！ 针对第一种情况，能不能删除呢，答案是可以的，但是，不但要在Teacher中设置@ManyToMany(targetEntity = Student.class, mappedBy = &quot;teachers&quot;)标签中设置cascade = CascadeType.REMOVE),因为仅仅只这样设置的话,级联关系是整个表的字段,仅仅这样设置是很危险的。还应该应该给中间表与teacher表相关联的联合主键tea_id加上级联删除 ALTER TABLE stu_tea_ref ADD CONSTRAINT tea_id FOREIGN KEY (tea_id) REFERENCES hb_teacher(t_id) ON DELETE CASCADE ; 说明:stu_tea_ref是中间表,tea_id是引用teacher表主键的联合主键 当删除teacher时,因为应用了级联删除,在中间表将与其主键值相同的相关记录也删除了,没有级联到其他的字段,student表不受影响. 不严谨之处,敬请指出,请关注我的博客: Lee个人博客]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JPA概念解析-CascadeType详解]]></title>
    <url>%2F2017%2F04%2F13%2FJPA%E6%A6%82%E5%BF%B5%E8%A7%A3%E6%9E%90-CascadeType%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[CascadeType.REMOVE Cascade remove operation，级联删除操作。删除当前实体时，与它有映射关系的实体也会跟着被删除。 CascadeType.MERGE Cascade merge operation，级联更新（合并）操作。当Student中的数据改变，会相应地更新Course中的数据。 CascadeType.DETACH Cascade detach operation，级联脱管/游离操作。如果你要删除一个实体，但是它有外键无法删除，你就需要这个级联权限了。它会撤销所有相关的外键关联。 CascadeType.REFRESH Cascade refresh operation，级联刷新操作。假设场景 有一个订单,订单里面关联了许多商品,这个订单可以被很多人操作,那么这个时候A对此订单和关联的商品进行了修改,与此同时,B也进行了相同的操作,但是B先一步比A保存了数据,那么当A保存数据的时候,就需要先刷新订单信息及关联的商品信息后,再将订单及商品保存。 CascadeType.ALL Cascade all operations，清晰明确，拥有以上所有级联操作权限。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库引擎MyISAM和InnoDB及简单的源码分析]]></title>
    <url>%2F2017%2F04%2F12%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%95%E6%93%8EMyISAM%E5%92%8CInnoDB%2F</url>
    <content type="text"><![CDATA[问题描述: 今天在使用Hibernate框架(版本为5.2.16),建立多表关联映射关系时,发现从表中没有创建关联外键约束,进而导致:从表中应用了主表的主键作为外键,此时删除主表中相关联的数据依然行得通,也就是说从表中的外键在主表中找不到对应的记录与之对应了. 检查了关联关系配置文件中没有问题 最后在这个地方找到了答案:发现数据库的 engine 是MyISAM类型的 MyISAM不支持外键!!!! 在配置文件中发现: 123&lt;property name="hibernate.dialect.storage_engine"&gt; org.hibernate.dialect.MySQL5Dialect&lt;/property&gt; 跟到源码中发现:配置了这一项默认使用的就是MyISAM引擎(源码在后面) 好啦,接下来对比下MyISAM和InnoDB:** 区别: InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务； InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败； InnoDB是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快； Innodb不支持全文索引，而MyISAM支持全文索引，查询效率上MyISAM要高； 如何选择: 是否要支持事务，如果要请选择innodb，如果不需要可以考虑MyISAM； 如果表中绝大多数都只是读查询，可以考虑MyISAM，如果既有读写也挺频繁，请使用InnoDB。 系统奔溃后，MyISAM恢复起来更困难，能否接受； MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的，如果你不知道用什么，那就用InnoDB，至少不会差。 另外:mysql5.7的innodb已支持全文索引 为了保证支持事务、外键，在Hibernate的hibernate.cfg.xml中的hibernate.dialect.storage_engine配置中，应该这么配置: 1234&lt;property name="hibernate.dialect.storage_engine"&gt; org.hibernate.dialect.MySQL55Dialect&lt;/property&gt;&lt;!--我的MySQL版本是5.5,而5.5默认的engine是InnoDB--&gt; 而且注意:org.hibernate.dialect.MySQLDialect在MySQL5.5以上已经不能再使用了. 源码分析: MySQL5Dialect继承自MySQLDialect,没有重载构造方法 123public class MySQL5Dialect extends MySQLDialect &#123; ...&#125; 进入到MySQLDialect中 1234567891011121314151617181920/** * Constructs a MySQLDialect */public MySQLDialect() &#123; super(); String storageEngine = Environment.getProperties().getProperty( Environment.STORAGE_ENGINE ); // null if(storageEngine == null) &#123; storageEngine = System.getProperty( Environment.STORAGE_ENGINE ); &#125; if(storageEngine == null) &#123; this.storageEngine = getDefaultMySQLStorageEngine(); // 进入到此方法 &#125; // ...省略... protected MySQLStorageEngine getDefaultMySQLStorageEngine() &#123; return MyISAMStorageEngine.INSTANCE; // 返回MyISAM引擎 &#125;&#125;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>错误解决</tag>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Struts2使用重点笔记]]></title>
    <url>%2F2017%2F04%2F10%2FStruts2%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Struts2使用笔记 配置文件的加载顺序 struts.xml -&gt; struts.properties -&gt; web.xml 这三个文件都是可以修改 struts2常量的值，但是后面的重复的值会覆盖前面的值 在上面三个文件中都是可以配置常量值的 通常在struts.xml中配置常量或者其他的Action,项目比较大时,难免臃肿,此时可以使用include标签来引入其他的xml配置文件,其格式遵循struts.xml文件的格式 在struts.xml中配置action的三种方式: 指定method 通过通配符”*”匹配 动态方法访问,注意:struts2.5以后默认关闭,需要配置打开,同时在package中配置 1&lt;global-allowed-methods&gt;regex:.*&lt;/global-allowed-methods&gt; ​ ​ 结果页面配置 局部结果页面配置 12345678&lt;action name="user_*" class="com.lee.struts2test.UserController" method="&#123;1&#125;"&gt; &lt;result name="login_success"&gt; /index.jsp &lt;/result&gt; &lt;result name="regist_success"&gt; /login.jsp &lt;/result&gt;&lt;/action&gt; 是在action中配置 全局结果页面配置 全局结果页面展示必须放在局部的action标签之前 result标签中的type属性 dispatcher:转发,默认 redirect:重定向 ​ Action中常用的两个类 ActionContext ServletActionContext ServletRequestAware接口,在方法中获取HttpServletRequest对象 表单数据的封装 原始方法,得到request中的参数 属性封装 提供Entity中的属性和get/set方法,Action会自动调用给属性赋值(获取表单数据到成员变量里面,不能把数据直接封装到实体类里面) 表达式封装,在页面通过使用user.userName分方式来设置表单的name属性(在Action中必须提供get方法,返回user为属性名的一个实体) 模型驱动封装 可以直接把表单数据封装到实体类里面,一个Action类中只能有一个实体类对象 使用表达式封装,可以将数据封装到List或者Map中 ​ ​ ​ ​ 1.配置的时候,Intellij自动生成了全局过滤器12345678&lt;filter&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 其中 1org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter 爆红,原来如果jar包确认没问题的话,检查你的Struts2版本,如果是2.5版本以上的话,将.ng去掉,我的是2.5.14.1,修改成 1234&lt;filter&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.struts2.dispatcher.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt; &lt;/filter&gt; 2.使用通配符”*”配置struts.xml中的action访问路径的时候,运行时出现异常,action映射的方法没有找到,解决办法:**123456789101112131415&lt;action name="customer_*" class="com.lee.crm.customer.action.CustomerAction" method="&#123;1&#125;"&gt; &lt;!--添加客户--&gt; &lt;result name="add_success"&gt;/jsp/success.jsp&lt;/result&gt; &lt;result name="add_error"&gt;/jsp/customer/add.jsp&lt;/result&gt; &lt;!--客户列表--&gt; &lt;result name="list_success"&gt;/jsp/customer/list.jsp&lt;/result&gt; &lt;result name="list_error"&gt;/jsp/error.jsp&lt;/result&gt; &lt;!--更新客户--&gt; &lt;result name="update_success"&gt;/jsp/customer/add.jsp&lt;/result&gt; &lt;result name="update_error"&gt;/jsp/error.jsp&lt;/result&gt; &lt;!--使用通配符匹配的时候,加上这一句--&gt; &lt;allowed-methods&gt;add,list,update&lt;/allowed-methods&gt;&lt;/action&gt; 加上&lt;allowed-methods&gt;add,list,update&lt;/allowed-methods&gt; 3.使用模型驱动封装表单数据,在需要对表单对应的实体进行更新的时候**123456789101112131415161718public class CustomerAction extends ActionSupport implements ModelDriven&lt;Customer&gt; &#123; private Customer customer = new Customer(); @Override public Customer getModel() &#123; return customer; &#125; public String preUpdate() &#123; // 获取custid String custId = ServletActionContext.getRequest().getParameter("custId"); Customer customer = mCustomerService.findCustomerById(Long.parseLong(custId)); // 将customer对象设置到值栈中,更新model对象,回显 this.customer = customer;// ActionContext.getContext().getValueStack().push(this.customer); return "pre_update_success"; &#125;&#125; 发现从ValueStack中获取的值依然是更新之前的值.这是由于action中的customer的确是更新了,但是valuestack中的值依然是旧值,而在页面中通过&lt;s:property value=&#39;custId&#39; /&gt;获取的也是旧值 解决办法有多种,这里介绍两种常用的方法: 第一种: ActionContext.getContext().getValueStack().push(this.customer); 将新的值压入栈顶,页面获取的就是新的对象的值了 第二种: 在相应的action标签中加入 12345678&lt;action name="customer_*" class="com.lee.crm.customer.action.CustomerAction" method="&#123;1&#125;"&gt; &lt;interceptor-ref name="defaultStack"&gt; &lt;!-- 渲染页面前刷新model在ValueStack的root的引用 --&gt; &lt;!--这样在valuestack中会自动压入一个新的值,跟手动调用push方法是一样的--&gt; &lt;param name="modelDriven.refreshModelBeforeResult"&gt;true&lt;/param&gt; &lt;/interceptor-ref&gt; &lt;/action&gt; 同时在action中给对象赋上新的值 1this.customer = customer; 4.ValueStack压入的对象是以对象的属性名作为key,属性值作为value存贮在map中的,所以在页面中取值的时候直接通过Property Name取值,具体可以多用用&lt;s:debug&gt;&lt;s:debug&gt;标签看看Value Stack Contents中值的存放形式 在使用struts.xml文件时，经常因为格式导致不必要的错误。例： 12345&lt;package name="default" extends="struts-default" namespace="/namespace1"&gt; &lt;action name="initFStree" class="InitFStree"&gt; &lt;result name="success"&gt;pages/initFStree.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt; ​ 5.struts2中% 、# 的使用方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172%和$符号在OGNL表达式中经常出现.1．#符号的用途一般有三种。1) 访问非根对象属性，例如示例中的#session.msg表达式，由于Struts 2中值栈被视为根对象，所以访问其他非根对象时，需要加#前缀。实际上，#相当于ActionContext. getContext()；#session.msg表达式相当于ActionContext.getContext().getSession(). getAttribute(”msg”).2) 用于过滤和投影（projecting）集合，如示例中的persons.&#123;?#this.age&gt;20&#125;。3) 用来构造Map，例如示例中的#&#123;’foo1′:’bar1′, ’foo2′:’bar2′&#125;。2.%符号1. %符号的用途是在标志的属性为字符串类型时，计算OGNL表达式的值。如下面的代码所示：构造Map&lt;s:set name=”foobar” value=”#&#123;’foo1′:’bar1′, ‘foo2′:’bar2′&#125;” /&gt;The value of key “foo1″ is &lt;s:property value=”#foobar['foo1']” /&gt;不使用％：&lt;s:url value=”#foobar['foo1']” /&gt;使用％：&lt;s:url value=”%&#123;#foobar['foo1']&#125;” /&gt;说明:"在标志的属性为字符串类型时":如标志:s:url的属性value,其类型是字符串类型.如标志:s:property的属性value,其类型是对象.所以:&lt;s:url value=”%&#123;#foobar['foo1']&#125;” /&gt; --&gt;要使用%否则,会直接显示成:#foobar['foo1']在&lt;s:property value="#foobar['foo1']" /&gt; --&gt;不用使用% (3)1. $符号:$符号主要有两个方面的用途。2.1在国际化资源文件中，引用OGNL表达式.在资源文件的国际化字符串中使用OGNL，格式为$&#123;表达式&#125;，例如：validation.require=$&#123;getText(fileName)&#125; is required在显示这些国际化字符时，同样有两种方法设置参数的值：1. 使用标志的value0、value1...valueN的属性，如： &lt;s:text name="validation.required" value0="User Name"/&gt;2. 使用param子元素，这些param将按先后顺序，代入到国际化字符串的参数中，例如： &lt;s:text name="validation.required"&gt; &lt;s:param value="User Name"/&gt; /s:text2.2 在Struts 2框架的各种配置文件(validation.xml或struts.xml)中引用OGNL表达式，例如下面的代码片断所示：&lt;validators&gt; &lt;field name=”intb”&gt; &lt;field-validator type=”int”&gt; &lt;param name=”min”&gt;10&lt;/param&gt; &lt;param name=”max”&gt;100&lt;/param&gt; &lt;message&gt;BAction-test校验：数字必须为&#123;min&#125;为&#123;max&#125;之间！&lt;/message&gt; //其值则上面的参数 &lt;/field-validator&gt; &lt;/field&gt; &lt;/validators&gt; (4) &lt;h2&gt;&lt;s:text name="HelloWorld"/&gt;&lt;/h2&gt; &lt;h2&gt;&lt;s:property value="%&#123;getText('HelloWorld')&#125;"/&gt;&lt;/h2&gt; 上面的例子用了两种方法来显示国际化字符串，其输出是相同的。其实，这就是Struts 2.0的一个优势，因为它默认支持EL，所示我们可以用getText方法来简洁地取得国际化字符串。另外更普遍的情况——在使用UI表单标志时， getText可以用来设置label属性，例如： &lt;s:textfield name="name" label="%&#123;getText('UserName')&#125;"/&gt; 即:&lt;s:text name="HelloWorld"/&gt;相当于:%&#123;getText('UserName')&#125;]]></content>
      <tags>
        <tag>学习日记</tag>
        <tag>错误解决</tag>
        <tag>Struts2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate学习笔记3]]></title>
    <url>%2F2017%2F04%2F10%2FHibernate%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%2F</url>
    <content type="text"><![CDATA[Hibernate–3学习大纲: 数据库中表的关系 一对一 一对多 多对多 注意:不管是哪种关系,在逻辑上都有主表和从表之分 外键 : 从表中的一列来源于主表的主键,或者为null,默认情况下外键是可以重复的 如何确立和实现表之间的关系 确立:看表的外键90%的情况下能确立表之间的关系 实现: 一对一 (A表和B表): B表中的外键是A表的主键,且此外键设置唯一约束,非空约束 B表的外键是A表的主键,同时又是主键 一对多(A表和B表): 其中A表示主表,B表示从表,主表一般指的是一,从表指的是多 B表的外键是A表的主键,也可以为null 多对多(A表和B表) 维护一个第三表,该表只有两个字段,且都为主键,引用自A,B两个表的主键 任何一个多表和第三表之间的关系都是一对多的关系 使用Hibernate多表映射配置的步骤 第一步:确立两张表之间的关系 第二步:在数据库中创建出这两张表,并实现两张表之间的关系 第三步:在实体类中描述出两个实体之间的关系 第四步:在映射配置文件中配置两张表之间的关系 情景一:建立房东(landlord)数据表和租户(tenant)数据表 第一步:确立两张表之间的关系 一个房东可以有多个租户 一个租户只能有一个房东 所以房东和租户之间是一对多的关系 第二步:在数据库中创建出这两张表,并实现两张表之间的关系 123456789101112131415161718/*房东信息表*/CREATE TABLE hb_landlord( l_id INT PRIMARY KEY AUTO_INCREMENT, l_name VARCHAR(10), l_sex CHAR(1), l_age INT(3), l_phone VARCHAR(15))/*租户信息表*/CREATE TABLE hb_tenant( t_id INT PRIMARY KEY AUTO_INCREMENT, t_name VARCHAR(10), t_sex CHAR(1), t_age INT(3), t_phone VARCHAR(15), t_job VARCHAR(10)) 只要在Hibernate中配置好表的映射配置文件以后,获取Session的时候,会自动加载配置文件,Hibernate检查表是否已经创建,如果没有创建就替我们创建表 第三步:在实体类中描述出两个实体之间的关系 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// 房东 表public class Landlord &#123; private Integer lid; private String lname; private String lsex; private Integer lage; private String lphone; // 一位房东可以包含多位租客,建立一对多关系 // 注意这里的处理方式:防止后面调用添加租客的时候报空指针异常(set还没有创建),提前将其创建出来 // 如果数据众多的时候,会有多个tenants创建,会很占用内存,所以初始化的时候现将其初始容量设置成0 private Set&lt;Tenant&gt; tenants = new HashSet&lt;&gt;(0); public Landlord() &#123; &#125; public Set&lt;Tenant&gt; getTenants() &#123; return tenants; &#125; public void setTenants(Set&lt;Tenant&gt; tenants) &#123; this.tenants = tenants; &#125; public Integer getLid() &#123; return lid; &#125; public void setLid(Integer lid) &#123; this.lid = lid; &#125; public String getLname() &#123; return lname; &#125; public void setLname(String lname) &#123; this.lname = lname; &#125; public String getLsex() &#123; return lsex; &#125; public void setLsex(String lsex) &#123; this.lsex = lsex; &#125; public Integer getLage() &#123; return lage; &#125; public void setLage(Integer lage) &#123; this.lage = lage; &#125; public String getLphone() &#123; return lphone; &#125; public void setLphone(String lphone) &#123; this.lphone = lphone; &#125; @Override public String toString() &#123; return "Landlord&#123;" + "lid=" + lid + ", lname='" + lname + '\'' + ", lsex='" + lsex + '\'' + ", lage=" + lage + ", lphone='" + lphone + '\'' + '&#125;'; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475//租户 表public class Tenant &#123; private Integer tid; private String tname; private String tsex; private Integer tage; private String tphone; private String tjob; // 从事的工作 // 一位租户只能有一个房东,建立关系 private Landlord landlord; public Tenant() &#123; &#125; public Integer getTid() &#123; return tid; &#125; public void setTid(Integer tid) &#123; this.tid = tid; &#125; public String getTname() &#123; return tname; &#125; public void setTname(String tname) &#123; this.tname = tname; &#125; public String getTsex() &#123; return tsex; &#125; public void setTsex(String tsex) &#123; this.tsex = tsex; &#125; public Integer getTage() &#123; return tage; &#125; public void setTage(Integer tage) &#123; this.tage = tage; &#125; public String getTphone() &#123; return tphone; &#125; public void setTphone(String tphone) &#123; this.tphone = tphone; &#125; public String getTjob() &#123; return tjob; &#125; public void setTjob(String tjob) &#123; this.tjob = tjob; &#125; @Override public String toString() &#123; return "Tenant&#123;" + "tid=" + tid + ", tname='" + tname + '\'' + ", tsex='" + tsex + '\'' + ", tage=" + tage + ", tphone='" + tphone + '\'' + ", tjob='" + tjob + '\'' + '&#125;'; &#125;&#125; ​ 第四步:在映射配置文件中配置两张表之间的关系 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!--指定命名空间,从hibernate-core-5.2.16.Final包中找--&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;&lt;hibernate-mapping package="com.lee.one2many"&gt; &lt;class name="Landlord" table="hb_landlord"&gt; &lt;id name="lid" column="l_id"&gt; &lt;!--主键自增长,使用数据库本地的自增长能力--&gt; &lt;generator class="native"&gt;&lt;/generator&gt; &lt;/id&gt; &lt;property name="lname" column="l_name"&gt;&lt;/property&gt; &lt;property name="lsex" column="l_sex"&gt;&lt;/property&gt; &lt;property name="lage" column="l_age"&gt;&lt;/property&gt; &lt;property name="lphone" column="l_phone"&gt;&lt;/property&gt; &lt;!-- set:配置set集合属性 name:一对多关系中,维护的"多"对应的集合set的成员属性名:private Set&lt;Tenant&gt; tenants = new HashSet&lt;&gt;(0); table:对应的从表的表名(在一对多的配置中可以不写) key:用于映射从表的外键字段 column:指定从表中外键的字段名称 one-to-many:从表对应的实体类 其他字段: lazy:是否懒加载,true:懒加载(延迟加载)-指的是是否延迟加载关联的从表记录 inverse:true,代表放弃了外键的维护权,表示它不关心外键是否正确或null(默认为false) cascade : save-update:级联保存或者更新 delete:级联删除(慎用) cascade="save-update,delete" --&gt; &lt;set name="tenants" table="hb_tenant" cascade="save-update" lazy="false"&gt; &lt;key column="ten_land_fk_id"&gt;&lt;/key&gt; &lt;one-to-many class="Tenant"&gt;&lt;/one-to-many&gt; &lt;/set&gt; &lt;!-- 理解 : 因为维护了多的一方的集合,肯定要知道多的一方对应的实体类(!!必须配置实体类名) : 多的一方怎么跟我建立起关系的呢?因为它引用了我的主键作为它的外键(!!必须要知道外键对应的字段) : 因为已经指定了实体类,而实体类已经通过映射配置文件为其配置了对应的表名,因此表名可有可无 --&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 123456789101112131415161718192021222324252627282930&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!--指定命名空间,从hibernate-core-5.2.16.Final包中找--&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;&lt;hibernate-mapping package="com.lee.one2many"&gt; &lt;class name="Tenant" table="hb_tenant" lazy="false"&gt; &lt;id name="tid" column="t_id"&gt; &lt;!--主键自增长,使用数据库本地的自增长能力--&gt; &lt;generator class="native"&gt;&lt;/generator&gt; &lt;/id&gt; &lt;property name="tname" column="t_name"&gt;&lt;/property&gt; &lt;property name="tsex" column="t_sex"&gt;&lt;/property&gt; &lt;property name="tage" column="t_age"&gt;&lt;/property&gt; &lt;property name="tphone" column="t_phone"&gt;&lt;/property&gt; &lt;property name="tjob" column="t_job"&gt;&lt;/property&gt; &lt;!-- name : 多对一中,"一"对应的属性字段 class : "一"对应的实体类 column : 映射的外键 lazy: proxy:代理,依赖主表实体类的加载模式(在主表映射配置文件的&lt;class&gt;标签中进行配置) false:立即加载 no-proxy: 默认为proxy --&gt; &lt;many-to-one name="landlord" class="Landlord" column="ten_land_fk_id" lazy="proxy"/&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 情景二:学生和老师的信息 第一步:确立两张表之间的关系 一位学生可以拥有多个老师 一位老师可以拥有多个学生 所以学生表和老师表是多对多的关系 第二步:在数据库中创建出这两张表,并实现两张表之间的关系 只要配置文件中没有出错,Hibernate就会创建出正确的表来 第三步:在实体类中描述出两个实体之间的关系 互相持有对方的一个Set集合引用 第四步:在映射配置文件中配置两张表之间的关系 Student实体对应的数据库表 1234567891011121314&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!--指定命名空间,从hibernate-core-5.2.16.Final包中找--&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;&lt;hibernate-mapping package="com.lee.many2many"&gt; &lt;class name="Student" table="hb_student"&gt; &lt;id name="sid" column="s_id"&gt; &lt;!--主键自增长,使用数据库本地的自增长能力--&gt; &lt;generator class="native"&gt;&lt;/generator&gt; &lt;/id&gt; &lt;property name="sname" column="s_name"&gt;&lt;/property&gt; &lt;property name="sage" column="s_age"&gt;&lt;/property&gt; &lt;!-- set:用于配置映射的集合属性 name:指定当前映射实体类中对应集合属性的属性名称 table:指定生成中间表的表名 column:当前映射文件对应实体在中间表中的联合主键字段 class:指定集合属性所装的实体类型 column:指定对方在表中对应的字段名称 --&gt; &lt;!--注意:多对多情况下慎用级联删除,可能会出现删除不需要删除的对象--&gt; &lt;set name=&quot;teachers&quot; table=&quot;tea_stu_ref&quot; cascade=&quot;save-update,delete&quot;&gt; &lt;key column=&quot;stu_id&quot;&gt;&lt;/key&gt; &lt;many-to-many class=&quot;Teacher&quot; column=&quot;tea_id&quot;&gt;&lt;/many-to-many&gt; &lt;/set&gt; &lt;!-- 理解 : 因为维护了多的一方的集合,肯定要知道多的一方对应的实体类(!!必须配置实体类名) : 多的一方怎么跟我建立起关系的呢?因为它引用了我的主键作为它的外键(!!必须要知道外键对应的字段) : 因为已经指定了实体类,而实体类已经通过映射配置文件为其配置了对应的表名,因此表名可有可无 --&gt; &lt;/class&gt; 12345678910111213141516171819202122232425262728293031Teacher实体对应的数据库表```xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC &quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot; &quot;http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd&quot;&gt;&lt;hibernate-mapping package=&quot;com.lee.many2many&quot;&gt; &lt;class name=&quot;Teacher&quot; table=&quot;hb_teacher&quot;&gt; &lt;id name=&quot;tid&quot; column=&quot;t_id&quot;&gt; &lt;generator class=&quot;native&quot;&gt;&lt;/generator&gt; &lt;/id&gt; &lt;property name=&quot;tname&quot; column=&quot;t_name&quot;&gt;&lt;/property&gt; &lt;property name=&quot;tage&quot; column=&quot;t_sex&quot;&gt;&lt;/property&gt; &lt;!--注意:多对多情况下慎用级联删除,可能会出现删除不需要删除的对象--&gt; &lt;set name=&quot;students&quot; table=&quot;tea_stu_ref&quot;&gt; &lt;key column=&quot;tea_id&quot;&gt;&lt;/key&gt; &lt;many-to-many class=&quot;Student&quot; column=&quot;stu_id&quot;&gt;&lt;/many-to-many&gt; &lt;/set&gt; &lt;!-- 理解 : 因为维护了多的一方的集合,肯定要知道多的一方对应的实体类(!!必须配置实体类名) : 多的一方怎么跟我建立起关系的呢?因为它引用了我的主键作为它的外键(!!必须要知道外键对应的字段) : 因为已经指定了实体类,而实体类已经通过映射配置文件为其配置了对应的表名,因此表名可有可无 --&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; ​ 延迟加载思想 导航查询思想 load方法和get方法的区别,get方法立即查询.get方法取决于当前实体类映射配置文件中&lt;calss&gt;标签中的lazy属性,true表示延迟加载.]]></content>
      <tags>
        <tag>学习日记</tag>
        <tag>错误解决</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea中Mark Directory As里的Sources Root、ReSources Root等的区别]]></title>
    <url>%2F2017%2F04%2F10%2Fidea%E4%B8%ADMark%20Directory%20As%E9%87%8C%E7%9A%84Sources%20Root%E3%80%81ReSources%20Root%E7%AD%89%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[1.Source roots (or source folders)通过这个类指定一个文件夹，你告诉IntelliJ IDEA，这个文件夹及其子文件夹中包含的源代码，可以编译为构建过程的一部分。 2.Test source roots (or test source folders; shown as rootTest)这些根类似于源根，但用于用于测试的代码（例如用于单元测试）。测试源文件夹允许您将与测试相关的代码与生产代码分开。 通常，源和测试源的编译结果被放置在不同的文件夹中。 3.Resource roots用于应用程序中的资源文件（图像、各种配置XML和属性文件等）。 在构建过程中，资源文件夹的所有内容都复制到输出文件夹中。 类似于源，您可以指定生成资源。您还可以指定输出文件夹中的文件夹，您的资源应该复制到。 4. Test resource roots（或测试资源文件夹；如roottestresourceij；只有在java模块）是资源文件与您的测试源有关。在所有其他方面，这些文件夹类似于资源文件夹。]]></content>
      <tags>
        <tag>Intellij工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate学习笔记2]]></title>
    <url>%2F2017%2F04%2F09%2FHibernate%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%2F</url>
    <content type="text"><![CDATA[Hibernate–2学习内容: 实体类的编写规范(也称作为持久化类) 实体类的编写规范 类的成员变量声明为private 有默认的无参构造方法 可生成具有唯一标志oid的实例 提供get和set方法(也可以只设置只读方法或者只写方法) 用包装型数据类型替代基本类型,比如id类型应该用Long类型替代long类型 不要用final关键字修饰(否则延迟加载机制会失效) JavaBean 指的是用Java语言编写的可重用 hibernate中的对象标识符 Hibernate中oid的:指的是表字段中的主键,这个主键交给数据库底层或者Hibernate去生成,这样能够保证oid的一致性,同时对于持久化类,应该将id对应的set方法设置成private类型的(反射能够访问private类型的成员) hibernate中主键的生成方式 Hibernate的主键生成方式 自然主键和代理主键的区别 自然主键:区分记录,参与业务逻辑 代理主键:区分记录,不参与业务逻辑 hibernate的一级缓存和快照机制 调用Session的update(),save(),saveOrUpdate()方法时,如果Session缓存中没有相应的对象,Hibernate会自动的将刚刚添加进(更新)的数据添加到Session缓存中,以防临近时机调用不用再重复访问数据库 注意:如果设置了主键自动增长,此时再给对象设置主键字段是无效的 快照区其实相当于数据库的一部分数据的拷贝,他保存了数据库真实的数据,每次commit时,都会检查缓存和快照区的数据时候一致,如果不一致,更新数据库,同时更新快照去 hibernate中的对象状态(三种状态/四种状态) 瞬时状态:没有OID,没有和Session建立关系 持久状态:有OID,有缓存,并且对应的Session也没有关闭,在数据库中有对应的记录,每条记录对应一个唯一的持久态对象,注意它是在事务未提交之前形成的持久态的 脱管状态:某个持久态的实例与其相关联的Session被关闭时就形成了脱管状态,此时他就是一条独立于Hibernate的数据,它的改变与数据库没有什么关系 hibernate中的事务控制 解决的问题:让Session对象也符合使用原则(即一个线程只有一个Session对象) hibernate中的查询方式 查询多条记录的方式 共5种查询方式 OID查询 使用session的get(),load()方法进行查询 SQL查询 第一种:SQLQuery方式(使用的很少) 第二种:Session通过doWork()方法,可以拿到Connection对象 HQL查询(官方推荐的查询方式) Hibernate Query Language,使用Query对象查询 QBC查询 Query By Criteria,使用Criteria对象执行查询 对象导航查询 …… hibernate中的Query对象(重点) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135/** * @CreateAuthor: KingIsHappy * @CreateDate: 2018/4/10 * @Description: 使用Session中的Query进行查询 * SQL:select * from cst_customer * HQL:select * from Customer * 将SQL中的表名换成映射的实体的类名,将将查询的字段名换成实体中对应的属性名 * &lt;p&gt; * 基本查询 * 条件查询 * 分页查询 * 排序查询 * 统计查询 * 投影查询 */public class Demo2 &#123; /* 基本查询 */ @Test public void test1() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction();// Query query = session.createQuery("from Customer"); // 查询Customer实体对应的表中的所有的数据 Query query1 = session.createQuery("select cname,cage from Customer"); // 查询两个指定字段 List&lt;Object[]&gt; list = query1.getResultList(); for (Object[] ol : list) &#123; for (Object o : ol) &#123; System.out.println(o); &#125; &#125; transaction.commit(); &#125; /** * 条件查询 */ @Test public void test2() &#123; Session session = HibernateUtils.openSession(); Transaction ts = session.beginTransaction(); Query query = session.createQuery("from Customer where cname = ?"); query.setParameter(0, "马云"); // 从0开始(0代表第一个替换位置)// Query query = session.createQuery("from Customer where cname like ?");// query.setString(0,"%马%"); // 在HQL中将参数设置别名,然后再给参数赋值// Query query = session.createQuery("from Customer where cname like :likename");// query.setString("likename", "%马%"); List&lt;Customer&gt; list = query.list(); for (Customer c : list) &#123; System.out.println(c); &#125; ts.commit(); &#125; /** * 分页查询 */ @Test public void test3() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction(); Query query = session.createQuery("select cid,cname from Customer "); query.setFirstResult(5);// 从索引为5的位置开始查 // 假如数据库中有1000条记录,你以此想把这1000条记录查出来,设置了setFetchSize(100) // 数据库每次回返回100条记录,当你需要下面的100条记录的时候,数据库才会加载下面的100条记录// query.setFetchSize(2); query.setMaxResults(2);// 每次查询返回的条数 List&lt;Object[]&gt; list = query.getResultList(); for (Object[] ol : list) &#123; for (Object o : ol) &#123; System.out.println(o); &#125; &#125; transaction.commit(); &#125; /** * 排序查询 */ @Test public void test4() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction(); Query query = session.createQuery("from Customer order by cid desc "); List&lt;Customer&gt; list = query.list(); for (Customer c : list) &#123; System.out.println(c); &#125; transaction.commit(); &#125; /** * 统计查询 */ @Test public void test5() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction();// Query query = session.createQuery("select count (*) from Customer "); Query query = session.createQuery("select avg (cage) from Customer "); // getSingleResult()只能接收一个结果,当结果超过1一个时就会报错 Object result = query.getSingleResult(); Object o = query.uniqueResult();// 效果和getSingleResult一样 System.out.println(result); transaction.commit(); &#125; /** * 投影查询 */ @Test public void test6() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction(); // 给HQL传参的时候,创建一个新的对象,指定要查询的字段的名称,执行查询以后,默认返回一个封装好了的实体 Query query = session.createQuery("select new Customer (cname,cage) from Customer where cid = ?"); query.setParameter(0, 1L); Object result = query.getSingleResult(); System.out.println(result); transaction.commit(); &#125;&#125; ​ hibernate中的Criteria(标准、准则)对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185/** * @CreateAuthor: KingIsHappy * @CreateDate: 2018/4/10 * @Description: 使用Session创建的Criteria进行查询(QBC查询) * Criteria是一个完全面向对象,可扩展的条件查询API,他完全不用考虑数据库底层是如何实现,以及SQL如何编写 * &lt;p&gt; * 基本查询 * 条件查询 * 分页查询 * 排序查询 * 统计查询 * 离线查询(不依赖Session产生一个DetachedCriteria对象(new得到),然后设置查询参数及条件) */public class Demo3 &#123; // * 基本查询(查询所有) @Test public void test1() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction(); // 查询所有 Criteria criteria = session.createCriteria(Customer.class); List&lt;Customer&gt; list = criteria.list(); for (Customer c : list) &#123; System.out.println(c); &#125; transaction.commit(); session.close(); &#125; /** * 基本查询(session的createCriteria()方法已经过时的解决办法),官方建议使用Query,这相当于一个折中的方案,CriteriaQuery可以向Criteria一样 * 不用关心SQL怎么写,它可以像Criteria一样进行设置查询条件 */ @Test public void test11() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction(); // 查询所有 CriteriaQuery&lt;Customer&gt; cquery = session.getCriteriaBuilder().createQuery(Customer.class); cquery.from(Customer.class); cquery.where();// cquery.where(); Query&lt;Customer&gt; query = session.createQuery(cquery); List&lt;Customer&gt; list = query.list(); for (Customer c : list) &#123; System.out.println(c); &#125; transaction.commit(); session.close(); &#125; // * 条件查询 @Test public void test2() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction(); Criteria criteria = session.createCriteria(Customer.class); criteria.add(Restrictions.eq("cname", "马云")); List&lt;Customer&gt; list = criteria.list(); for (Customer c : list) &#123; System.out.println(c); &#125; transaction.commit(); session.close(); &#125; // * 分页查询 @Test public void test3() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction(); Criteria criteria = session.createCriteria(Customer.class); criteria.setFirstResult(0); criteria.setMaxResults(5); List&lt;Customer&gt; list = criteria.list(); for (Customer c : list) &#123; System.out.println(c); &#125; transaction.commit(); session.close(); &#125; // * 排序查询 @Test public void test4() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction(); Criteria criteria = session.createCriteria(Customer.class); criteria.addOrder(Order.desc("cid")); // 降序查询 List&lt;Customer&gt; list = criteria.list(); for (Customer c : list) &#123; System.out.println(c); &#125; transaction.commit(); session.close(); &#125; // * 统计查询(投影查询) @Test public void test5() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction(); Criteria criteria = session.createCriteria(Customer.class); // 使用投影查询指定条目的个数 criteria.setProjection(Projections.count("cname")); Object o = criteria.uniqueResult(); System.out.println(o); transaction.commit(); session.close(); &#125; /** * 使用投影查询,查询指定的列 */ @Test public void test55() &#123; Session session = HibernateUtils.openSession(); Transaction transaction = session.beginTransaction(); Criteria criteria = session.createCriteria(Customer.class); criteria.setProjection(Projections.property("cname")); List list = criteria.list(); for (Object o : list) &#123; System.out.println(o); &#125; transaction.commit(); session.close(); &#125; // * 离线查询 /** * 思路:在表现层封装一个DetachedCriteria,将要封装的查询数据到其中 * 传递给服务层,服务层再传递给DAO层,DAO层将DetachedCriteria激活,编程Criteria对象,然后执行查询 */ @Test public void test6() &#123; List list = testServlet(); for (Object o : list) &#123; System.out.println(o); &#125; &#125; // 模拟Servlet public List testServlet() &#123; DetachedCriteria detachedCriteria = DetachedCriteria.forClass(Customer.class); detachedCriteria.add(Restrictions.eq("cname", "马云")); List list = null; try &#123; list = testService(detachedCriteria); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return list; &#125; // 模拟Service // 在服务中开启事务,事务的处理在业务层 public List testService(DetachedCriteria detachedCriteria) throws Exception &#123; Session session = HibernateUtils.getCurrentSession(); Transaction transaction = null; try &#123; transaction = session.beginTransaction(); List list = testDao(detachedCriteria); transaction.commit(); return list; &#125; catch (HibernateException e) &#123; transaction.rollback(); throw new Exception(e); &#125; &#125; // 模拟DAO private List testDao(DetachedCriteria detachedCriteria) &#123; Session session = HibernateUtils.getCurrentSession(); Criteria executableCriteria = detachedCriteria.getExecutableCriteria(session); return executableCriteria.list(); &#125;&#125; ​ ​ ​ ​ ​]]></content>
      <tags>
        <tag>学习日记</tag>
        <tag>错误解决</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate学习笔记1]]></title>
    <url>%2F2017%2F04%2F08%2FHibernate%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%2F</url>
    <content type="text"><![CDATA[Hibernate–1学习内容: Hibernate相关jar包的依赖 创建表和实体之间的映射配置文件Student.hbm.xml 1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!--指定命名空间,从hibernate-core-5.2.16.Final包中找--&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;&lt;hibernate-mapping package="com.lee.hibernate1.domain"&gt; &lt;class name="Student" table="student"&gt; &lt;id name="sid" column="sid"&gt; &lt;!--主键自增长,使用数据库本地的自增长能力--&gt; &lt;generator class="native"&gt;&lt;/generator&gt; &lt;/id&gt; &lt;property name="name" column="sname"&gt;&lt;/property&gt; &lt;property name="sex" column="ssex"&gt;&lt;/property&gt; &lt;property name="age" column="sage"&gt;&lt;/property&gt; &lt;property name="address" column="saddress"&gt;&lt;/property&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; ​ 创建hibernate.cfg.xml配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!--导入约束文件文件 ,从从hibernate-core-5.2.16.Final包中找到--&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC "-//Hibernate/Hibernate Configuration DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd"&gt;&lt;hibernate-configuration&gt; &lt;!--配置SessionFactory,它是数据库连接的会话对象,它是执行CRUD的对象--&gt; &lt;!--创建SessionFactory对象的三部分必须配置: 1.第一部分: 连接数据库的信息 2.第二部分 hibernate的可选配置 3.第三部分 映射配置文件的位置 --&gt; &lt;session-factory&gt; &lt;!--第一部分--&gt; &lt;!--JDBC驱动--&gt; &lt;property name="hibernate.connection.driver_class"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;!--连接数据库的url--&gt; &lt;property name="hibernate.connection.url"&gt;jdbc:mysql://localhost:3306/hibernate&lt;/property&gt; &lt;!--数据库的用户名--&gt; &lt;property name="hibernate.connection.username"&gt;root&lt;/property&gt; &lt;!--登录数据库的密码--&gt; &lt;property name="hibernate.connection.password"&gt;123&lt;/property&gt; &lt;!--#hibernate.dialect org.hibernate.dialect.MySQLDialect--&gt; &lt;!--&amp;lt;!&amp;ndash;配置数据库方言&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;property name="hibernate.dialect"&gt;org.hibernate.dialect.MySQL55Dialect&lt;/property&gt;--&gt; &lt;!--第二部分--&gt; &lt;!--是否在控制台显示生成的sql语句--&gt; &lt;property name="hibernate.show_sql"&gt;true&lt;/property&gt; &lt;!--是否将控制台里的sql语句格式化输出--&gt; &lt;property name="hibernate.format_sql"&gt;true&lt;/property&gt; &lt;!--采用何种方式生成DDL语句--&gt; &lt;!--其中update表示:检测实体类和表结构是否一致,如果不一致,更新表结构达到一致,如果不存在该表,就创建一张表--&gt; &lt;property name="hibernate.hbm2ddl.auto"&gt;update&lt;/property&gt; &lt;!--第三部分--&gt; &lt;!--指定映射的bean配置文件的位置--&gt; &lt;!--如果有多个,就配置多个--&gt; &lt;mapping resource="com/lee/hibernate1/Student.hbm.xml"/&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; ​ 使用hibernate向数据库中插入数据的小练习 1234567891011121314151617181920212223public void test1() &#123; Student student = new Student(); student.setName("Lee"); student.setAddress("安康市"); student.setSex("男");// 1. 解析主配置文件 Configuration configuration = new Configuration(); configuration.configure(); // 配置默认的配置文件,即为根目录下的hibernate.cfg.xml文件// 2.根据主配置文件,创建SessionFaction对象 SessionFactory factory = configuration.buildSessionFactory();// 3.创建Session Session session = factory.openSession();// 4.开启事务 Transaction transaction = session.beginTransaction();// 5.执行插入 session.save(student);// 6.提交事务 transaction.commit();// 7.释放资源 session.close(); factory.close(); &#125; Configuration配置配置文件 一般在hibernate.cfg.xml中配置的东西,在该对象中都是可以配置的,但是不推荐这么做,硬编码,后期维护升级很费事 SessionFactory 该对象在服务器启动(应用启动)的时候创建,在服务器关闭(应用卸载)的时候销毁,一个应用只存在一个实例 它是线程安全的 在创建SessionFactory以后对配置文件进行更改,将不会影响到该factory Session 一个线程只有一个对象 TransactionHibernate工具类Hibernate中CRUD操作Hibernate中的异常处理HibernateException继承了RuntimeException,这个异常可以不用捕获 Hibernate中配置c3p0连接池F:\java资料\SSH框架\hibernate-release-5.2.16.Final\project\etc/hibernate.properties文件中查找配置格式(搜索c3p0) Hibernate中查询的get和load方法的区别查询时机不同,返回查询的结果不一样 get:立即加载 load:延迟加载(懒加载,惰性加载),返回的对象是增强对象(动态代理),增强了toString()方法;他也可以通过配置的方式改为立即加载 学习中遇到的问题及其结局方案: 使用的MySQL版本为5.5,使用Hibernate的版本为5.2.16,在配置hibernate.cfg.xml的时候12&lt;!--配置数据库方言--&gt;&lt;property name="hibernate.dialect"&gt;org.hibernate.dialect.MySQL5Dialect&lt;/property&gt; 在MySQL版本为5.5及以上时,如果配置数据库方言,将org.hibernate.dialect.MySQLDialect改为上面的 org.hibernate.dialect.MySQL5Dialect 不然在hibernate创建表格的时候会报错. 或者这个配置项直接不配置也是可以的]]></content>
      <tags>
        <tag>学习日记</tag>
        <tag>错误解决</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo主题之next主题的配置]]></title>
    <url>%2F2017%2F04%2F06%2Fhexo%E4%B8%BB%E9%A2%98%E4%B9%8Bnext%E4%B8%BB%E9%A2%98%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[关于 hexo 主题之next主题 GiuHub地址 Next主题配置官网文档 hexo的next主题个性化教程:打造炫酷网站 另外附上大致的使用GitHub Pages建站的流程: 注册GitHub账号 创建 YourName.github.io库,GitHub默认把它当做静态html托管仓库(我们实际上也仅仅是在它上面托管我们的静态网页,它还能够识别解析css和js文件) 在GitHub上生成 SSH Keys (后面使用的hexo在本地拥有了一个SSH Keys的拷贝,这样就可以实现快速部署到pages仓库) 安装hexo,推荐参考 hexo官方文档 这样可以少走很多弯路,遇到问题了再去查解决方法 然后就可以找一款自己喜欢的主题啦 hexo官网,这上面有很全的plug插件和theme主题,也可以参考别人的推荐,我就用的是GitHub上star数醉的的一款next]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>hexo主题配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的Pattern、Matcher、常用的正则表达式]]></title>
    <url>%2F2017%2F04%2F06%2FJava%E4%B8%AD%E7%9A%84Pattern%E3%80%81Matcher%E3%80%81%E5%B8%B8%E7%94%A8%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Java中的Pattern、Matcher、常用的正则表达式Java中的字符串已经有了直接调用简单匹配方法,matches方法(内部也是使用了Pattern.matches()方法) 123456String s = "Java12Java34";// 精确匹配,返回regex和s串是否完全匹配boolean isMatch = s.matches("Java"); // 这里返回false// 在一定的范围内进行匹配// 参数的含义: 是否忽略大小写,s串的起始位置(offset),regex字符串,regex字符串的起始位置,取regex串的长度boolean isMatch2 = s.regionMatches(true, 6, "Java", 0, "Java".length()); // 返回true 但是很多时候String自带的这些方法不足于我们使用,此时Java中提供了Pattern和Matcher两个与正则表达式相关的类供我们使用 Pattern类12String regex = "Java";Pattern pattern = Pattern.compile(regex); Pattern.matches()静态方法123String regex = "Java";String s2 = "Java123Java456Java789";Pattern.matches("Java", s2); // 注意这里也是全串精确匹配 其实这个方法和String中的matches()方法一致,其实String.matches()方法内部就是调用了此方法 split顾名思义就是分割字符串的方法,其中regex就是分割字符串的”刀”,注意当regex和字符串开始或者结尾部分匹配的时候会得到空字符串 123456789101112String regex = "Java";String s2 = "Java123Java456Java789";Pattern pattern = Pattern.compile("Java");// split(input),分割字符串得到String数组String[] split = pattern.split(s2);System.out.println(split.length); // 输出3,[空串,123,456,789]String[] split1 = pattern.split(regex, 2);System.out.println("split1的长度为 : " + split1.length); // 输出2,[空串,123Java456Java789],想想limit设置成3会怎样?// 注意:limit设置成0或者负数,效果默认一样,也就是和pattern.split(s2)一样 关于Pattern只介绍这两个方法,其他的可以自行创建demo试试 Matcher类1234String regex = "Java";String s = "Java123Java456Java789";Pattern pattern = Pattern.compile(regex);Matcher matcher1 = pattern.matcher(s); find()：尝试查找与该模式匹配的输入序列的的下一个子序列。重要,下面重点说 find(int start)：重置此匹配器，然后尝试查找匹配该模式、从指定索引开始的输入序列的下一个子序列。 group()：匹配成功返回的组,重要,下面重点说 start()：返回先前匹配的起始位置的索引。 end()：返回最后匹配字符的索引加一。 matches()：尝试将整个区域与模式匹配。匹配成功返回true lookingAt()：尝试将从区域开头开始的输入序列与该模式匹配。 replaceFirst()：替换掉匹配的第一个子序列 replaceAll()：替换掉匹配的全部子序列 appendReplacement：重要，下面重点说 appendTail(StringBuffer buf)：重要，下面重点说 reset():重置匹配器,从起始位置重新开始 reset(CharSequence input):重置匹配器,放入新的待匹配的串 部分方法解析 find()方法 注意:该方法尝试查找与该模式匹配的输入序列的下一个子序列.此方法从匹配器区域的开头开始，如果该方法的前一次调用成功了,并且从那时开始匹配器没有被重置，则从以前匹配操作没有匹配的第一个字符开始 12345678910111213String regex = "Java.";String s = "Java1Java2";Pattern pattern = Pattern.compile(regex);Matcher matcher1 = pattern.matcher(s);matcher1.find(); // 这里返回true// 其实此时我们可以使用下面的方式来循环获取匹配得到的子串while(matcher.find)&#123; // 循环查找,本次查找结束了,下次如果想获得查找结果应该重新执行find()方法 System.out.println(matcher.group()); // 关于group方法将在下面介绍&#125;// 上面的方法输出:Java1Java2 group()方法 这里介绍下组的概念：组是用括号划分的正则表达式，可以根据组的编号来引用这个组。组号为0表示整个表达式，组号为1表示被第一对括号括起的组，依次类推，例如A(B(C))D，组0是ABCD，组1是BC，组2是C。 Matcher类提供了start()，end()，group()分别用于返回字符串的起始索引，结束索引，以及匹配到到的字符串。 12345678String regex = "(Java).*(Java)";String s = "Java123Java456";Pattern pattern = Pattern.compile(regex);Matcher matcher2 = pattern.matcher(s);matcher2.find(); // 注意,这里需要先执行find方法System.out.println(matcher2.group()); // 如果find()方法执行返回true,则group()或者group(0)代表整个字符串s:Java123Java456System.out.println(matcher2.group(1)); // 输出 Java123System.out.println(matcher2.group(2)); // 输出Java456 appendReplacement(StringBuffer sb,String replacement)方法 先从字符串中执行查找,查找到了,替换成replacement,并从开始匹配的位置处将字符串写入StringBuffer中,示例入下: 12345678910111213141516171819String s = "2018-4-10 15-45-30";String regex = "-";Pattern pattern = Pattern.compile(regex);Matcher matcher = pattern.matcher(s);StringBuffer sb = new StringBuffer();matcher.find();matcher.appendReplacement(sb, ":");System.out.println(sb.toString());matcher.find();matcher.appendReplacement(sb, ":");System.out.println(sb.toString());matcher.find();matcher.appendReplacement(sb, ":");System.out.println(sb.toString());输出入下:2018:2018:4:2018:4:10 15: 可以看到,它比String的replaceAll()或者replace()方法更加灵活 正则表达式语法请参考 Java 正则表达式]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于JDBC的Spring中数据库事务的相关操作]]></title>
    <url>%2F2017%2F04%2F06%2FSpring%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[数据库事务的四大特性(ACID) 原子性（Atomicity）事务是一个原子操作，由一系列动作组成。事务的原子性确保动作要么全部完成，要么完全不起作用。 一致性（Consistency）事务在完成时，必须是所有的数据都保持一致状态。 隔离性（Isolation）并发事务执行之间无影响，在一个事务内部的操作对其他事务是不产生影响，这需要事务隔离级别来指定隔离性。 持久性（Durability）一旦事务完成，数据库的改变必须是持久化的。 并发访问数据库导致的问题在企业级应用中，多用户访问数据库是常见的场景，这就是所谓的事务的并发。事务并发所可能存在的问题： 脏读：一个事务读到另一个事务未提交的更新数据。 不可重复读：一个事务两次读同一行数据，可是这两次读到的数据不一样。 幻读：一个事务执行两次查询，但第二次查询比第一次查询多出了一些数据行。 丢失更新：撤消一个事务时，把其它事务已提交的更新的数据覆盖了。 应对并发访问导致问题的举措上述四种并发访问数据库导致的问题是并发情况下难免会发生的,但是又是不得不解决的问题。在JDBC中，数据库事务有四大隔离级别： SERIALIZABLE（串行化） 不会出现任何并发问题，因为它是对同一数据的访问是串行的，非并发访问的； 性能最差； REPEATABLE READ （可重复读）（MySQL） 防止脏读和不可重复读，不能处理幻读问题； 性能比SERIALIZABLE好 READ COMMITTED （读已提交数据）（Oracle） 防止脏读，没有处理不可重复读，也没有处理幻读； 性能比REPEATABLE READ好 READ UNCOMMITTED （读未提交数据） 可能出现任何事务并发问题 性能最好 理解：例如当数据库事务的隔离级别是读已提交,那么当前事务对数据进行了更改,只要是该事务还没有提交,那么其他事务对数据的更改是看不见的. Spring中对事务的处理Spring事务管理高层抽象主要包括3个接口： PlatformTransactionManager 事务管理器 我们常常使用的DataSourceTransactionManager就是它的一个间接子类 TransactionDefinition 事务定义信息（隔离、传播、超时、只读） 主要定义了它自己的传播行为和隔离级别 TransactionStatus 事务具体运行状态 主要方法： 123456void flush(); //如果适用的话，这个方法用于刷新底层会话中的修改到数据库，例如，所有受影响的Hibernate/JPA会话。boolean hasSavepoint(); // 是否有恢复点boolean isCompleted(); // 是否已完成boolean isNewTransaction(); // 是否是新的事务boolean isRollbackOnly(); // 是否为只回滚void setRollbackOnly(); // 设置为只回滚 声明式事务管理声明式事务管理是非侵入式的 xml方式配置12345678910111213141516171819202122232425&lt;/beans&gt; ......&lt;!--配置事务--&gt; &lt;!--第一步:配置事务管理器--&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="jdbcDatasource"/&gt; &lt;/bean&gt; &lt;!--第二步:配置事务增强--&gt; &lt;tx:advice id="advice" transaction-manager="transactionManager"&gt; &lt;!--做事务操作--&gt; &lt;tx:attributes&gt; &lt;!--设置事务操作的方法匹配规则--&gt; &lt;tx:method name="add*"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!--第三步:配置切面--&gt; &lt;aop:config&gt; &lt;!--com.lee.JDBCTransaction包下的所有的类中的方法都会和事务增强中设置的匹配规则进行匹配--&gt; &lt;aop:pointcut id="tx_pt" expression="execution(* com.lee.JDBCTransaction.*.*(..))"/&gt; &lt;aop:advisor advice-ref="advice" pointcut-ref="tx_pt"/&gt; &lt;/aop:config&gt;......&lt;/beans&gt; 基于注解的配置方式基于注解的方式简单好理解,是常用的方式 在xml配置文件中: 123456789101112&lt;beans&gt;&lt;!--基于注解配置事务--&gt; &lt;!--配置事务管理器--&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;!--配置数据源--&gt; &lt;property name="dataSource" ref="jdbcDatasource"/&gt; &lt;/bean&gt; &lt;!--开启对注解事务管理器的支持--&gt; &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt;&lt;/beans&gt; 然后在业务层中开启事务 1234567891011121314151617public class UserServiceImpl2 implements UserService &#123; private UserDao mUserDao; /** * 模拟逻辑,向数据库中插入条相同的记录,并在第二条记录上打上"--copy"的标记 */ @Override @Transactional // 开启事务 public void addTwoSimpleUser(User user) &#123; mUserDao.add(user); user.setUsername(user.getUsername() + "--copy"); int error = 2 / 0; mUserDao.add(user); &#125;&#125; @Transactional可以标记在方法上,当标记在方法上的时候,代表此方法作为一个事务的原子操作,该方法中的内容是事务中事务体. @Transactional也可以标记在类上,当标记在类上面的时候,代表此类中的所有方法都开启了事务. 编程式事务管理编程式事务管理是侵入性的,用的不多 请参考 Spring事务管理详解]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH框架学习之Struts2--第一天]]></title>
    <url>%2F2017%2F03%2F08%2FSSH%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E4%B9%8BStruts2-%E7%AC%AC%E4%B8%80%E5%A4%A9%2F</url>
    <content type="text"></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Struts2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git版本控制工具的简单使用]]></title>
    <url>%2F2016%2F11%2F07%2FGit%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%B7%A5%E5%85%B7%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[虽然在Windows系统上安装的Git是可以在图形界面上进行操作的,但是我们并不应该这么做,Git的各种命令才是我们应该掌握的,而且将来我们不管换成什么样的操作系统,使用Git命令来操作都是通用的 1. 创建代码仓库初次打开Bash的时候我们应该配置身份 12git confing --global user.name "yourname"git confing --global user.email "your email address" 然后切换到你要上传到github的项目的根目录下,例如下面这个项目: 12cd f:cd android/BroadcastTest/ 然后输入下面的命令: 1git init 这样会在BroadcastTest目录下生成一个 .git 文件夹 2. 提交本地代码123git add AndroidManifest.xml # 将AndroidManifest.xml文件添加进本地仓库git add src # 将src目录添加进本地仓库git add . # 添加所有的文件到本地仓库 上面的添加只是将文件/文件夹添加到本地仓库,并没有提交: 1git commit -m "first commit" # 其中"first commit"是本次提交的描述,建议加上此次提交的描述,将来我们可以很方便的看到提交了什么 3. 忽略文件我们提交的时候,并不是该项目下所有的文件都得提交,例如 .idea 文件夹是不需要提交的,它是IDE自动生成的,那么怎么忽略掉这些文件呢? 第一步: 在BroadcastTest目录下创建 .gitignore文件 注意可能你在创建该文件的时候提示你”必须键入文件名,解决方法是: 在项目根目录下面创建gitignore.txt文件 把你需要排除的文件名保存到gitignore.txt文件 在项目根目录下面按住Shift键并鼠标右键选择“在此处打开命令窗口” 执行命令 ren gitignore.txt .gitignore 第二步:编辑.gitignore文件,将你想要忽略提交的文件或者文件夹加入 例如: 123bin/gen/*.html # 忽略所有的html文件,其中 "*" 为通配符,表示任意多个字符, "?" 代表一个字符, 方括号 [abc]代表可选字符范围 编辑好上面的.gitignore文件以后,执行 git add .就会自动将匹配上的文件或者文件夹忽略,然后执行 git commit -m &quot;Second commit with ignore&quot; 大功告成! 4. 查看修改内容在项目的开发阶段我们经常提交代码到仓库,理想的情况是每当完成了一小块功能的时候,就执行一次提交.当某个功能修改比较多的时候,写到后面可能我们已经忘记了本次到底修改了什么内容了,此时Git在帮你记着. git status 查看本次更改的概况 git diff src/lee/com/broadcasttest/Main.java 查看某个文件具体修改的内容,其中,减号代表删除的内容,加号代表添加的内容 5. 撤销未提交的修改每次完成一个功能以后,都会先执行 add命令添加进本地仓库 本次代码修改以后,只要未提交(也就是未执行add命令),都可以运行 git checkout src/lee/com/broadcasttest/Main.java 来撤销更改 上面的命令只能针对那些没有执行过add命令的文件有效,当某个文件已经add过了,此时需要先对其进行取消添加 git reset HEAD src/lee/com/broadcast/Main.java,然后在执行上面的 git checkout src/lee/com/broadcasttest/Main.java命令 6. 查看提交记录git log 当我们的提交较多的时候,可以指定该记录的id: git log 提交记录的id -1(注意这里要添加上-1) 在命令中添加-p参数,查看该条记录具体修改的内容: git log 提交记录的id -1 -p 7. 分支的用法git branch -a 查看当前的版本库中有哪些分支,版本库创建的时候默认只有一个分支 master git branch version1.0 创建一个名为 version1.0 的分支,虽然此时创建了一个新的分支version1.0,但是当前你所在的分支依然是master,使用下面的命令进行切花分支 git checkout version1.0 切换到version1.0的分支上 当你想把version1.0分支上所做的修改合并到master分支上,使用下面的命令进行 123git checkout master # 先切换到master分支上git merge version1.0 # 合并merge分支上的修改到master分支上,此时version1.0分支上的代码不会受到影响 # 另外,合并分支的时候可能会出现代码冲突的情况,此时应该慢慢查找那些冲突的代码,git 无力帮助我们 git branch -D version1.0 删除version1.0的分支 8. 与远程版本库协作上面的操作都是在本地完成的,只适合个人作为项目版本的控制方法 所有的版本控制工具最重要的一个特点就是可以使用它来进行团队合作开发,每个人的电脑上都会有一份代码,当团队的某个成员在自己的电脑上编写完成了某个功能后,就将代码提交到服务器,其他的成员只需要将服务器上的代码同步到本地,就能保证整个团队所有人的代码都相同.这样的话,每个成员就可以各司其职,完成每个人负责的模块,这样就可以共同完成一个庞大的项目. 现在,项目负责人在Git上创建了一个项目,项目地址为:https://github.com/BlueLeer/Crawler 将代码下载到本地: 1git clone https://github.com/BlueLeer/Crawler.git 之后,当你在这份代码的基础上完成了一些修改,使用下面的命令将本地修改的内容同步到版本库: 1git push origin master # 注意:该命令应该在上面本地代码根目录上执行,origin指的是远程Git地址,master指的是master分支,当然也可以是其他的分支 团队的其他成员对Git版本库中的代码也进行了修改,我们应该要养成经常从版本库中获取最新代码的习惯,那么怎么讲远程版本库中的修改同步到本地呢?使用下面的命令: 123git fetch origin master # fetch意为获取之意,但是注意:同步下来的代码并不会合并到本地的任何分支上,而是会存放在一个 origin/master# 分支上,此时可以先调用 git diff origin/master 查看远程版本库中到底修改了什么内容 之后调用 merge命令将origin/master分支上的修改合并到本地的master分支上即可: 1git merge origin/master 推荐使用上面的方法,当然下面的方法更简单,一步到位,那就是pull命令了,它其实相当于将fetch和merge两个命令放在一起执行了,它从远程的版本苦衷获取罪行的代码并合并到本地: 1git pull origin master 9.上传本地项目到代码仓库步骤: 在待上传的项目根目录下执行(会生成一个.git目录):git init 添加文件到本地仓库:git add . 提交到本地仓库:git commit -m &quot;提交到本地仓库&quot; 建立和远程仓库的联系:git remote add origin git@github.com:BlueLeer/SSHMerge.git 关键的一步,将远程仓库最新的文件pull到本地,并和本地的合并,普通的合并是git pull origin master,但是,注意啦,这里的拉取合并指令为:git pull --rebase origin master 上传:git push origin master 10.其他 git配置账号信息 git config:局部 git config –global:全局 git log:查看操作日志(常用) git status 文件显示红色:未被git管理 文件显示绿色:已被git管理 git命令别名设置(原生命令为主) git版本回退 git reset –hard head^ 回退到上一个版本 git reset –hard 哈希值(前7位) git reflog:查看历史操作记录 git模拟多人开发 有可能存在冲突问题.例如:A操作并且提交代码后,B没有更新,直接操作最后push到远程的版本库(拒绝访问).正确的做法是,提交之前先pull最新的代码到本地并合并,然后解决冲突文件,然后提交到本地版本库,最后再进行提交到远程仓库. 参考:github入门到上传本地项目 注意:此博客中操作步骤可能会导致问题]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在活动中使用菜单Menu和PopupMenu]]></title>
    <url>%2F2016%2F11%2F01%2F%E5%9C%A8%E6%B4%BB%E5%8A%A8%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%8F%9C%E5%8D%95Menu%E5%92%8CPopupMenu%2F</url>
    <content type="text"><![CDATA[在Activity中使用Menu和PopupMenu流程: 点击res目录新建Android resouce file文件,选择resoucetype为menu,然后可以创建如下菜单的布局: 12345678&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;menu xmlns:android="http://schemas.android.com/apk/res/android"&gt; &lt;item android:id="@+id/refresh_item" android:title="刷新"/&gt; &lt;item android:id="@+id/change_city" android:title="选择城市"/&gt;&lt;/menu&gt; 然后在活动中重写onCreateOptionsMenu(Menu menu)方法: 12345public boolean onCreateOptionsMenu(Menu menu) &#123; //R.menu.menu就是menu的布局文件 getMenuInflater().inflate(R.menu.menu,menu); return true;&#125; ​ 然后在手机上点击”菜单”就可以弹出菜单了,该菜单是从屏幕底部弹出的. 当然我们也可以为点击菜单上的项目注册响应事件,通过重写onOptionsItemSelected()方法: 1234567891011public boolean onOptionsItemSelected(MenuItem item) &#123; switch(item.getItemId())&#123; case R.id.refresh_item: //加入逻辑 break; case R.id.change_city: //加入逻辑 break; &#125; return super.onOptionsItemSelected(item);&#125; 有时候我们希望通过点击屏幕上自己定义的一个组件弹出一个菜单来,并且这个菜单就在这个组件的周围,那么可以这么来写(还是使用刚刚我们定义的menu布局文件): 12345678910Button button = (Button)findViewById(R.id.refresh);//点击这个按钮就能弹出一个菜单来button.setOnClickListener(new View.OnClickListener()&#123; @Override public void onClick(View view) &#123; PopupMenu popupMenu = new PopupMenu(MainActivity.this,view); popupMenu.getMenuInflater().inflate(R.menu.menu,popupMenu.getMenu()); popupMenu.show(); &#125;&#125;); ​ ​ 在刷新按钮的周围弹出了一个菜单 ​ 当然我们也可以为PopupMenu响应点击事件: 12345678910popupMenu.setOnMenuItemClickListener(new PopupMenu.OnMenuItemClickListener() &#123; @Override public boolean onMenuItemClick(MenuItem menuItem) &#123; switch(menuItem.getId())&#123; case R.id.refresh_item //加入自己的逻辑(点击以后发生的事件) &#125; return false; &#125;&#125;);]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
</search>
